=== Testing resume with vocabulary size mismatch fix ===
Resuming from run ID: 20250325-195248_d64_l2_n4
2025-03-25 21:01:38,592 - __main__ - INFO - Using device: cuda
2025-03-25 21:01:38,592 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:01:38,592 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:01:38,592 - __main__ - INFO - Attempting to resume from run ID: 20250325-195248_d64_l2_n4
2025-03-25 21:01:38,593 - __main__ - INFO - Found run: 20250325-195248_d64_l2_n4
2025-03-25 21:01:38,593 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 21:01:38,593 - __main__ - INFO - Using d_model=64 from run config (override 768)
2025-03-25 21:01:38,593 - __main__ - INFO - Using num_layers=2 from run config (override 8)
2025-03-25 21:01:38,593 - __main__ - INFO - Using num_latent=4 from run config (override 16)
2025-03-25 21:01:38,593 - __main__ - INFO - Using min_digits=1 from run config (override 3)
2025-03-25 21:01:38,593 - __main__ - INFO - Using max_digits=1 from run config (override 3)
2025-03-25 21:01:38,594 - __main__ - INFO - Using checkpoint paths from run 20250325-195248_d64_l2_n4
2025-03-25 21:01:39,595 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:01:39,595 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 21:01:39,595 - __main__ - INFO - Updating d_model from 64 to 768 to match checkpoint
2025-03-25 21:01:39,595 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:01:39,596 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:01:39,596 - __main__ - INFO - Using vocabulary size: 11
2025-03-25 21:01:40,314 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:01:40,314 - __main__ - INFO - SimpleTransformer: 33,114,635
2025-03-25 21:01:40,314 - __main__ - INFO - LatentTransformer: 39,614,987
2025-03-25 21:01:40,314 - __main__ - INFO - Parameter ratio: 1.20x
2025-03-25 21:01:40,314 - __main__ - INFO - Difference: 6,500,352 parameters (19.6%)
2025-03-25 21:01:40,316 - src.RunManagement - INFO - Registered run: 20250325-210140_d768_l2_n4
2025-03-25 21:01:40,316 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:01:40,319 - src.RunManagement - INFO - Registered run: 20250325-210140_d768_l2_n4
2025-03-25 21:01:40,323 - __main__ - ERROR - Error loading checkpoints: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 
2025-03-25 21:01:40,324 - __main__ - ERROR - Traceback (most recent call last):
  File "/home/h/Devel/latent/main.py", line 551, in main
    simple_transformer.load_state_dict(new_state_dict)
  File "/home/h/.virtualenvs/latent/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 

Using train dataset with range 1-9: 61 problems
Using val dataset with range 1-9: 0 problems
=== Test complete ===
Check the logs above to verify that vocabulary size was correctly extracted and used
