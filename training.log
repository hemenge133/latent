2025-03-24 23:10:11,347 - __main__ - INFO - Using device: cuda
2025-03-24 23:10:11,348 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-24 23:10:11,348 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-24 23:10:11,348 - __main__ - INFO - Using train dataset with range 1-9
2025-03-24 23:10:11,349 - __main__ - INFO - Using val dataset with range 1-9
2025-03-24 23:10:11,535 - __main__ - INFO - 
Model Parameters:
2025-03-24 23:10:11,535 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-24 23:10:11,535 - __main__ - INFO - LatentTransformer: 282,507
2025-03-24 23:10:11,535 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-24 23:10:11,535 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-24 23:10:11,535 - __main__ - INFO - 
Training both models in parallel...
2025-03-24 23:10:11,538 - training_loop - INFO - Using torch.compile to optimize models
2025-03-24 23:10:13,692 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-24 23:10:13,693 - training_loop - INFO - Created 10 evaluation examples
2025-03-24 23:10:30,696 - __main__ - INFO - Using device: cuda
2025-03-24 23:10:30,696 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-24 23:10:30,696 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-24 23:10:30,696 - __main__ - INFO - Using train dataset with range 1-9
2025-03-24 23:10:30,698 - __main__ - INFO - Using val dataset with range 1-9
2025-03-24 23:10:30,857 - __main__ - INFO - 
Model Parameters:
2025-03-24 23:10:30,857 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-24 23:10:30,857 - __main__ - INFO - LatentTransformer: 282,507
2025-03-24 23:10:30,857 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-24 23:10:30,857 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-24 23:10:30,857 - __main__ - INFO - 
Training both models in parallel...
2025-03-24 23:10:30,859 - training_loop - INFO - Using torch.compile to optimize models
2025-03-24 23:10:32,727 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-24 23:10:32,728 - training_loop - INFO - Created 10 evaluation examples
2025-03-24 23:10:32,729 - training_loop - INFO - Starting: Training (steps)
2025-03-24 23:11:15,281 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-24 23:11:15,282 - training_loop - INFO - Steps completed: 2/2
2025-03-24 23:11:15,282 - training_loop - INFO - Best validation loss: inf
2025-03-24 23:11:15,283 - training_loop - INFO - Final validation loss: 0.000000
2025-03-24 23:11:15,283 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-24 23:11:15,283 - training_loop - INFO - Final digit accuracy: 0.00%
2025-03-24 23:11:15,283 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-24 23:11:15,283 - training_loop - INFO - Steps completed: 2/2
2025-03-24 23:11:15,283 - training_loop - INFO - Best validation loss: inf
2025-03-24 23:11:15,284 - training_loop - INFO - Final validation loss: 0.000000
2025-03-24 23:11:15,284 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-24 23:11:15,284 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-24 23:11:15,290 - __main__ - INFO - 
Final Comparison:
2025-03-24 23:11:15,291 - __main__ - INFO - ==================================================
2025-03-24 23:11:15,291 - __main__ - INFO - Training time: 42.55s
2025-03-24 23:11:15,291 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-24 23:11:15,291 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-24 23:11:15,292 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-24 23:11:15,292 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-24 23:11:15,292 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250324-231030_d64_l2_n4
2025-03-24 23:44:17,005 - __main__ - INFO - Using device: cuda
2025-03-24 23:44:17,006 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-24 23:44:17,006 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-24 23:44:17,006 - __main__ - INFO - Using train dataset with range 10-999
2025-03-24 23:44:18,536 - __main__ - INFO - Using val dataset with range 10-999
2025-03-24 23:44:20,532 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-24 23:44:20,535 - __main__ - INFO - 
Model Parameters:
2025-03-24 23:44:20,535 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-24 23:44:20,535 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-24 23:44:20,535 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-24 23:44:20,535 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-24 23:44:20,535 - __main__ - INFO - 
Training both models in parallel...
2025-03-24 23:44:20,535 - __main__ - INFO - Resuming training from checkpoints:
2025-03-24 23:44:20,536 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-24 23:44:20,536 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-24 23:44:23,364 - __main__ - INFO - Resuming from step 0
2025-03-24 23:44:23,367 - training_loop - INFO - Using torch.compile to optimize models
2025-03-24 23:44:26,426 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-24 23:44:26,439 - training_loop - INFO - Loaded SimpleTransformer optimizer state
2025-03-24 23:44:26,439 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-24 23:44:26,451 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-24 23:44:26,454 - training_loop - INFO - Created 26 evaluation examples
2025-03-24 23:44:26,457 - training_loop - INFO - Starting: Training (steps)
2025-03-24 23:46:15,934 - training_loop - INFO - 
SimpleTransformer - Step 3900/10000 - Val Loss: 0.774375 - Seq Acc: 8.30%
2025-03-24 23:47:18,545 - __main__ - INFO - Using device: cuda
2025-03-24 23:47:18,545 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-24 23:47:18,545 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-24 23:47:18,546 - __main__ - INFO - Using train dataset with range 10-999
2025-03-24 23:47:19,932 - __main__ - INFO - Using val dataset with range 10-999
2025-03-24 23:47:21,756 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-24 23:47:21,758 - __main__ - INFO - 
Model Parameters:
2025-03-24 23:47:21,759 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-24 23:47:21,759 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-24 23:47:21,759 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-24 23:47:21,759 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-24 23:47:21,759 - __main__ - INFO - 
Training both models in parallel...
2025-03-24 23:47:21,759 - __main__ - INFO - Resuming training from checkpoints:
2025-03-24 23:47:21,759 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-24 23:47:21,759 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-24 23:47:22,305 - __main__ - INFO - Resuming from step 3889
2025-03-24 23:47:22,309 - training_loop - INFO - Using torch.compile to optimize models
2025-03-24 23:47:24,802 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-24 23:47:24,835 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-24 23:47:24,846 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-24 23:47:24,848 - training_loop - INFO - Created 26 evaluation examples
2025-03-24 23:47:24,851 - training_loop - INFO - Starting: Training (steps)
2025-03-24 23:48:57,426 - __main__ - INFO - Using device: cuda
2025-03-24 23:48:57,426 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-24 23:48:57,426 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-24 23:48:57,426 - __main__ - INFO - Using train dataset with range 10-999
2025-03-24 23:48:58,845 - __main__ - INFO - Using val dataset with range 10-999
2025-03-24 23:49:00,758 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-24 23:49:00,760 - __main__ - INFO - 
Model Parameters:
2025-03-24 23:49:00,760 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-24 23:49:00,760 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-24 23:49:00,760 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-24 23:49:00,760 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-24 23:49:00,761 - __main__ - INFO - 
Training both models in parallel...
2025-03-24 23:49:00,761 - __main__ - INFO - Resuming training from checkpoints:
2025-03-24 23:49:00,761 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-24 23:49:00,761 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-24 23:49:01,360 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 3900, LatentTransformer: 3889
2025-03-24 23:49:01,360 - __main__ - WARNING - Using minimum step 3889 for resuming. This may cause imbalanced training.
2025-03-24 23:49:01,360 - __main__ - INFO - Resuming from step 3889/10000
2025-03-24 23:49:01,363 - training_loop - INFO - Using torch.compile to optimize models
2025-03-24 23:49:03,690 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-24 23:49:03,699 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-24 23:49:03,710 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-24 23:49:03,712 - training_loop - INFO - Created 26 evaluation examples
2025-03-24 23:49:03,714 - training_loop - INFO - Starting: Training (steps)
2025-03-24 23:51:01,619 - training_loop - INFO - 
LatentTransformer - Step 3900/10000 - Val Loss: 1.218197 - Seq Acc: 1.40%
2025-03-24 23:53:12,508 - training_loop - INFO - 
SimpleTransformer - Step 3950/10000 - Val Loss: 0.768834 - Seq Acc: 8.00%
2025-03-24 23:53:32,973 - training_loop - INFO - 
LatentTransformer - Step 3950/10000 - Val Loss: 1.207815 - Seq Acc: 1.50%
2025-03-24 23:54:17,923 - training_loop - INFO - 
SimpleTransformer - Step 4000/10000 - Val Loss: 0.778005 - Seq Acc: 8.15%
2025-03-24 23:54:35,550 - training_loop - INFO - 
LatentTransformer - Step 4000/10000 - Val Loss: 1.199575 - Seq Acc: 1.65%
2025-03-24 23:55:25,680 - training_loop - INFO - 
SimpleTransformer - Step 4050/10000 - Val Loss: 0.754047 - Seq Acc: 8.05%
2025-03-24 23:55:44,708 - training_loop - INFO - 
LatentTransformer - Step 4050/10000 - Val Loss: 1.204982 - Seq Acc: 1.65%
2025-03-24 23:56:32,673 - training_loop - INFO - 
SimpleTransformer - Step 4100/10000 - Val Loss: 0.750125 - Seq Acc: 7.95%
2025-03-24 23:56:50,368 - training_loop - INFO - 
LatentTransformer - Step 4100/10000 - Val Loss: 1.199474 - Seq Acc: 1.45%
2025-03-24 23:57:33,503 - training_loop - INFO - 
SimpleTransformer - Step 4150/10000 - Val Loss: 0.750682 - Seq Acc: 8.40%
2025-03-24 23:57:52,936 - training_loop - INFO - 
LatentTransformer - Step 4150/10000 - Val Loss: 1.195116 - Seq Acc: 1.50%
2025-03-24 23:58:42,854 - training_loop - INFO - 
SimpleTransformer - Step 4200/10000 - Val Loss: 0.763067 - Seq Acc: 7.90%
2025-03-24 23:58:59,025 - training_loop - INFO - 
LatentTransformer - Step 4200/10000 - Val Loss: 1.188326 - Seq Acc: 1.95%
2025-03-24 23:59:46,877 - training_loop - INFO - 
SimpleTransformer - Step 4250/10000 - Val Loss: 0.755832 - Seq Acc: 8.65%
2025-03-25 00:00:05,314 - training_loop - INFO - 
LatentTransformer - Step 4250/10000 - Val Loss: 1.188174 - Seq Acc: 2.00%
2025-03-25 00:00:52,239 - training_loop - INFO - 
SimpleTransformer - Step 4300/10000 - Val Loss: 0.744109 - Seq Acc: 9.25%
2025-03-25 00:01:12,067 - training_loop - INFO - 
LatentTransformer - Step 4300/10000 - Val Loss: 1.175172 - Seq Acc: 1.50%
2025-03-25 00:02:00,610 - training_loop - INFO - 
SimpleTransformer - Step 4350/10000 - Val Loss: 0.753442 - Seq Acc: 9.25%
2025-03-25 00:02:22,659 - training_loop - INFO - 
LatentTransformer - Step 4350/10000 - Val Loss: 1.160575 - Seq Acc: 1.45%
2025-03-25 00:03:11,381 - training_loop - INFO - 
SimpleTransformer - Step 4400/10000 - Val Loss: 0.753139 - Seq Acc: 8.60%
2025-03-25 00:03:27,738 - training_loop - INFO - 
LatentTransformer - Step 4400/10000 - Val Loss: 1.138903 - Seq Acc: 2.25%
2025-03-25 00:04:15,823 - training_loop - INFO - 
SimpleTransformer - Step 4450/10000 - Val Loss: 0.752359 - Seq Acc: 8.70%
2025-03-25 00:04:34,315 - training_loop - INFO - 
LatentTransformer - Step 4450/10000 - Val Loss: 1.140434 - Seq Acc: 2.10%
2025-03-25 00:05:18,978 - training_loop - INFO - 
SimpleTransformer - Step 4500/10000 - Val Loss: 0.766099 - Seq Acc: 8.65%
2025-03-25 00:05:36,799 - training_loop - INFO - 
LatentTransformer - Step 4500/10000 - Val Loss: 1.141665 - Seq Acc: 1.95%
2025-03-25 00:06:20,167 - training_loop - INFO - 
SimpleTransformer - Step 4550/10000 - Val Loss: 0.757086 - Seq Acc: 8.85%
2025-03-25 00:06:39,429 - training_loop - INFO - 
LatentTransformer - Step 4550/10000 - Val Loss: 1.128967 - Seq Acc: 2.00%
2025-03-25 00:07:22,835 - training_loop - INFO - 
SimpleTransformer - Step 4600/10000 - Val Loss: 0.769643 - Seq Acc: 8.55%
2025-03-25 00:07:44,491 - training_loop - INFO - 
LatentTransformer - Step 4600/10000 - Val Loss: 1.107529 - Seq Acc: 2.35%
2025-03-25 00:08:37,735 - training_loop - INFO - 
SimpleTransformer - Step 4650/10000 - Val Loss: 0.766716 - Seq Acc: 9.10%
2025-03-25 00:08:52,892 - training_loop - INFO - 
LatentTransformer - Step 4650/10000 - Val Loss: 1.130502 - Seq Acc: 2.05%
2025-03-25 00:09:45,921 - training_loop - INFO - 
SimpleTransformer - Step 4700/10000 - Val Loss: 0.772157 - Seq Acc: 8.35%
2025-03-25 00:10:07,932 - training_loop - INFO - 
LatentTransformer - Step 4700/10000 - Val Loss: 1.100156 - Seq Acc: 2.35%
2025-03-25 00:10:52,677 - training_loop - INFO - 
SimpleTransformer - Step 4750/10000 - Val Loss: 0.771041 - Seq Acc: 9.30%
2025-03-25 00:11:16,255 - training_loop - INFO - 
LatentTransformer - Step 4750/10000 - Val Loss: 1.099565 - Seq Acc: 2.30%
2025-03-25 00:12:05,477 - training_loop - INFO - 
SimpleTransformer - Step 4800/10000 - Val Loss: 0.768849 - Seq Acc: 9.70%
2025-03-25 00:12:28,140 - training_loop - INFO - 
LatentTransformer - Step 4800/10000 - Val Loss: 1.079653 - Seq Acc: 2.55%
2025-03-25 00:13:14,152 - training_loop - INFO - 
SimpleTransformer - Step 4850/10000 - Val Loss: 0.767367 - Seq Acc: 9.55%
2025-03-25 00:13:29,569 - training_loop - INFO - 
LatentTransformer - Step 4850/10000 - Val Loss: 1.120582 - Seq Acc: 2.40%
2025-03-25 00:14:22,178 - training_loop - INFO - 
SimpleTransformer - Step 4900/10000 - Val Loss: 0.777975 - Seq Acc: 9.10%
2025-03-25 00:14:42,580 - training_loop - INFO - 
LatentTransformer - Step 4900/10000 - Val Loss: 1.057494 - Seq Acc: 2.85%
2025-03-25 00:15:33,246 - training_loop - INFO - 
SimpleTransformer - Step 4950/10000 - Val Loss: 0.773387 - Seq Acc: 10.15%
2025-03-25 00:15:50,732 - training_loop - INFO - 
LatentTransformer - Step 4950/10000 - Val Loss: 1.068653 - Seq Acc: 2.50%
2025-03-25 00:16:40,773 - training_loop - INFO - 
SimpleTransformer - Step 5000/10000 - Val Loss: 0.777331 - Seq Acc: 9.75%
2025-03-25 00:16:59,302 - training_loop - INFO - 
LatentTransformer - Step 5000/10000 - Val Loss: 1.047446 - Seq Acc: 2.85%
2025-03-25 00:17:49,428 - training_loop - INFO - 
SimpleTransformer - Step 5050/10000 - Val Loss: 0.775236 - Seq Acc: 10.55%
2025-03-25 00:18:11,076 - training_loop - INFO - 
LatentTransformer - Step 5050/10000 - Val Loss: 1.040609 - Seq Acc: 3.35%
2025-03-25 00:18:57,448 - training_loop - INFO - 
SimpleTransformer - Step 5100/10000 - Val Loss: 0.805105 - Seq Acc: 9.15%
2025-03-25 00:19:13,719 - training_loop - INFO - 
LatentTransformer - Step 5100/10000 - Val Loss: 1.054064 - Seq Acc: 2.80%
2025-03-25 00:20:05,641 - training_loop - INFO - 
SimpleTransformer - Step 5150/10000 - Val Loss: 0.789217 - Seq Acc: 9.65%
2025-03-25 00:20:22,600 - training_loop - INFO - 
LatentTransformer - Step 5150/10000 - Val Loss: 1.056218 - Seq Acc: 2.70%
2025-03-25 00:21:12,091 - training_loop - INFO - 
SimpleTransformer - Step 5200/10000 - Val Loss: 0.791004 - Seq Acc: 9.50%
2025-03-25 00:21:34,800 - training_loop - INFO - 
LatentTransformer - Step 5200/10000 - Val Loss: 1.071377 - Seq Acc: 2.45%
2025-03-25 00:22:26,802 - training_loop - INFO - 
SimpleTransformer - Step 5250/10000 - Val Loss: 0.783975 - Seq Acc: 9.65%
2025-03-25 00:22:42,739 - training_loop - INFO - 
LatentTransformer - Step 5250/10000 - Val Loss: 1.082638 - Seq Acc: 3.10%
2025-03-25 00:23:33,152 - training_loop - INFO - 
SimpleTransformer - Step 5300/10000 - Val Loss: 0.845383 - Seq Acc: 8.00%
2025-03-25 00:23:49,898 - training_loop - INFO - 
LatentTransformer - Step 5300/10000 - Val Loss: 1.067551 - Seq Acc: 2.45%
2025-03-25 00:24:43,113 - training_loop - INFO - 
SimpleTransformer - Step 5350/10000 - Val Loss: 0.798914 - Seq Acc: 9.35%
2025-03-25 00:25:02,594 - training_loop - INFO - 
LatentTransformer - Step 5350/10000 - Val Loss: 1.101683 - Seq Acc: 2.35%
2025-03-25 00:25:54,428 - training_loop - INFO - 
SimpleTransformer - Step 5400/10000 - Val Loss: 0.813567 - Seq Acc: 9.15%
2025-03-25 00:26:14,067 - training_loop - INFO - 
LatentTransformer - Step 5400/10000 - Val Loss: 1.017581 - Seq Acc: 3.40%
2025-03-25 00:27:05,972 - training_loop - INFO - 
SimpleTransformer - Step 5450/10000 - Val Loss: 0.801369 - Seq Acc: 10.55%
2025-03-25 00:27:23,264 - training_loop - INFO - 
LatentTransformer - Step 5450/10000 - Val Loss: 1.036274 - Seq Acc: 3.65%
2025-03-25 00:28:16,553 - training_loop - INFO - 
SimpleTransformer - Step 5500/10000 - Val Loss: 0.894473 - Seq Acc: 7.90%
2025-03-25 00:28:34,075 - training_loop - INFO - 
LatentTransformer - Step 5500/10000 - Val Loss: 1.069892 - Seq Acc: 2.85%
2025-03-25 00:29:28,860 - training_loop - INFO - 
SimpleTransformer - Step 5550/10000 - Val Loss: 0.812073 - Seq Acc: 9.65%
2025-03-25 00:29:45,775 - training_loop - INFO - 
LatentTransformer - Step 5550/10000 - Val Loss: 1.054255 - Seq Acc: 3.10%
2025-03-25 00:30:36,760 - training_loop - INFO - 
SimpleTransformer - Step 5600/10000 - Val Loss: 0.847682 - Seq Acc: 9.35%
2025-03-25 00:30:52,967 - training_loop - INFO - 
LatentTransformer - Step 5600/10000 - Val Loss: 1.049885 - Seq Acc: 2.75%
2025-03-25 00:31:45,680 - training_loop - INFO - 
SimpleTransformer - Step 5650/10000 - Val Loss: 0.831249 - Seq Acc: 10.25%
2025-03-25 00:32:03,579 - training_loop - INFO - 
LatentTransformer - Step 5650/10000 - Val Loss: 1.025579 - Seq Acc: 3.45%
2025-03-25 00:33:02,631 - training_loop - INFO - 
SimpleTransformer - Step 5700/10000 - Val Loss: 0.851633 - Seq Acc: 9.45%
2025-03-25 00:33:19,948 - training_loop - INFO - 
LatentTransformer - Step 5700/10000 - Val Loss: 1.031655 - Seq Acc: 3.65%
2025-03-25 00:34:14,510 - training_loop - INFO - 
SimpleTransformer - Step 5750/10000 - Val Loss: 0.845752 - Seq Acc: 8.70%
2025-03-25 00:34:37,708 - training_loop - INFO - 
LatentTransformer - Step 5750/10000 - Val Loss: 1.011522 - Seq Acc: 3.50%
2025-03-25 00:35:33,565 - training_loop - INFO - 
SimpleTransformer - Step 5800/10000 - Val Loss: 0.845052 - Seq Acc: 9.40%
2025-03-25 00:35:52,846 - training_loop - INFO - 
LatentTransformer - Step 5800/10000 - Val Loss: 1.059295 - Seq Acc: 3.85%
2025-03-25 00:36:47,031 - training_loop - INFO - 
SimpleTransformer - Step 5850/10000 - Val Loss: 0.875392 - Seq Acc: 9.40%
2025-03-25 00:37:06,234 - training_loop - INFO - 
LatentTransformer - Step 5850/10000 - Val Loss: 1.069459 - Seq Acc: 2.75%
2025-03-25 00:37:58,909 - training_loop - INFO - 
SimpleTransformer - Step 5900/10000 - Val Loss: 0.907565 - Seq Acc: 8.40%
2025-03-25 00:38:16,277 - training_loop - INFO - 
LatentTransformer - Step 5900/10000 - Val Loss: 1.026629 - Seq Acc: 3.45%
2025-03-25 00:39:07,153 - training_loop - INFO - 
SimpleTransformer - Step 5950/10000 - Val Loss: 0.885193 - Seq Acc: 8.30%
2025-03-25 00:39:30,356 - training_loop - INFO - 
LatentTransformer - Step 5950/10000 - Val Loss: 0.992159 - Seq Acc: 3.55%
2025-03-25 00:40:27,584 - training_loop - INFO - 
SimpleTransformer - Step 6000/10000 - Val Loss: 0.884741 - Seq Acc: 9.65%
2025-03-25 00:40:46,097 - training_loop - INFO - 
LatentTransformer - Step 6000/10000 - Val Loss: 0.973015 - Seq Acc: 4.20%
2025-03-25 00:41:39,053 - training_loop - INFO - 
SimpleTransformer - Step 6050/10000 - Val Loss: 0.866551 - Seq Acc: 8.75%
2025-03-25 00:41:58,198 - training_loop - INFO - 
LatentTransformer - Step 6050/10000 - Val Loss: 1.007661 - Seq Acc: 4.00%
2025-03-25 00:42:49,875 - training_loop - INFO - 
SimpleTransformer - Step 6100/10000 - Val Loss: 0.875661 - Seq Acc: 9.20%
2025-03-25 00:43:09,955 - training_loop - INFO - 
LatentTransformer - Step 6100/10000 - Val Loss: 1.032128 - Seq Acc: 3.05%
2025-03-25 00:44:01,363 - training_loop - INFO - 
SimpleTransformer - Step 6150/10000 - Val Loss: 0.866439 - Seq Acc: 9.20%
2025-03-25 00:44:20,828 - training_loop - INFO - 
LatentTransformer - Step 6150/10000 - Val Loss: 1.028586 - Seq Acc: 3.20%
2025-03-25 00:45:14,768 - training_loop - INFO - 
SimpleTransformer - Step 6200/10000 - Val Loss: 0.876287 - Seq Acc: 10.40%
2025-03-25 00:45:35,822 - training_loop - INFO - 
LatentTransformer - Step 6200/10000 - Val Loss: 0.984516 - Seq Acc: 4.45%
2025-03-25 00:46:26,261 - training_loop - INFO - 
SimpleTransformer - Step 6250/10000 - Val Loss: 0.856199 - Seq Acc: 10.95%
2025-03-25 00:46:44,530 - training_loop - INFO - 
LatentTransformer - Step 6250/10000 - Val Loss: 1.053474 - Seq Acc: 3.50%
2025-03-25 00:47:40,770 - training_loop - INFO - 
SimpleTransformer - Step 6300/10000 - Val Loss: 0.870816 - Seq Acc: 10.05%
2025-03-25 00:47:58,656 - training_loop - INFO - 
LatentTransformer - Step 6300/10000 - Val Loss: 0.986368 - Seq Acc: 3.05%
2025-03-25 00:48:59,914 - training_loop - INFO - 
SimpleTransformer - Step 6350/10000 - Val Loss: 0.986137 - Seq Acc: 6.45%
2025-03-25 00:49:20,050 - training_loop - INFO - 
LatentTransformer - Step 6350/10000 - Val Loss: 0.975793 - Seq Acc: 3.70%
2025-03-25 00:50:17,548 - training_loop - INFO - 
SimpleTransformer - Step 6400/10000 - Val Loss: 0.896934 - Seq Acc: 10.05%
2025-03-25 00:50:34,426 - training_loop - INFO - 
LatentTransformer - Step 6400/10000 - Val Loss: 1.013256 - Seq Acc: 3.65%
2025-03-25 00:51:31,589 - training_loop - INFO - 
SimpleTransformer - Step 6450/10000 - Val Loss: 0.925933 - Seq Acc: 9.25%
2025-03-25 00:51:46,259 - training_loop - INFO - 
LatentTransformer - Step 6450/10000 - Val Loss: 1.021112 - Seq Acc: 4.00%
2025-03-25 00:52:49,989 - training_loop - INFO - 
SimpleTransformer - Step 6500/10000 - Val Loss: 0.991802 - Seq Acc: 7.80%
2025-03-25 00:53:09,379 - training_loop - INFO - 
LatentTransformer - Step 6500/10000 - Val Loss: 1.033234 - Seq Acc: 3.80%
2025-03-25 00:53:54,598 - __main__ - INFO - Using device: cuda
2025-03-25 00:53:54,598 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 00:53:54,598 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 00:53:54,598 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 00:53:56,266 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 00:53:58,640 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 00:53:58,642 - __main__ - INFO - 
Model Parameters:
2025-03-25 00:53:58,642 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 00:53:58,643 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 00:53:58,643 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 00:53:58,643 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 00:53:58,643 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 00:53:58,643 - __main__ - INFO - Resuming training from checkpoints:
2025-03-25 00:53:58,643 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 00:53:58,643 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 00:54:00,392 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 6500, LatentTransformer: 3900
2025-03-25 00:54:00,392 - __main__ - WARNING - Using minimum step 3900 for resuming. This may cause imbalanced training.
2025-03-25 00:54:00,392 - __main__ - INFO - Resuming from step 3900/10000
2025-03-25 00:54:00,395 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 00:54:04,228 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 00:54:04,238 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 00:54:04,253 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 00:54:04,253 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 00:54:04,257 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 00:54:04,259 - training_loop - INFO - Starting: Training (steps)
2025-03-25 00:56:46,543 - __main__ - INFO - Using device: cuda
2025-03-25 00:56:46,543 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 00:56:46,543 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 00:56:46,543 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 00:56:48,096 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 00:56:50,051 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 00:56:50,053 - __main__ - INFO - 
Model Parameters:
2025-03-25 00:56:50,054 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 00:56:50,054 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 00:56:50,054 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 00:56:50,054 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 00:56:50,054 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 00:56:50,054 - __main__ - INFO - Resuming training from checkpoints:
2025-03-25 00:56:50,054 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 00:56:50,054 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 00:56:51,884 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 6500, LatentTransformer: 3900
2025-03-25 00:56:51,884 - __main__ - WARNING - Using minimum step 3900 for resuming. This may cause imbalanced training.
2025-03-25 00:56:51,885 - __main__ - INFO - Resuming from step 3900/10000
2025-03-25 00:56:51,885 - training_loop - INFO - Using max_steps from args: 10000
2025-03-25 00:56:51,888 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 00:56:54,315 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 00:56:54,328 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 00:56:54,351 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 00:56:54,351 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 00:56:54,353 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 00:56:54,355 - training_loop - INFO - Starting: Training (steps)
2025-03-25 00:59:51,416 - training_loop - INFO - 
SimpleTransformer - Step 6550/10000 - Val Loss: 0.888919 - Seq Acc: 10.60%
2025-03-25 01:00:03,692 - training_loop - INFO - 
LatentTransformer - Step 3950/10000 - Val Loss: 0.939257 - Seq Acc: 4.65%
2025-03-25 01:01:01,933 - training_loop - INFO - 
SimpleTransformer - Step 6600/10000 - Val Loss: 0.923202 - Seq Acc: 10.70%
2025-03-25 01:01:08,480 - training_loop - INFO - 
LatentTransformer - Step 4000/10000 - Val Loss: 0.928219 - Seq Acc: 5.10%
2025-03-25 01:02:05,757 - training_loop - INFO - 
SimpleTransformer - Step 6650/10000 - Val Loss: 0.939838 - Seq Acc: 10.75%
2025-03-25 01:02:12,058 - training_loop - INFO - 
LatentTransformer - Step 4050/10000 - Val Loss: 0.921027 - Seq Acc: 4.90%
2025-03-25 01:03:12,153 - training_loop - INFO - 
SimpleTransformer - Step 6700/10000 - Val Loss: 0.951448 - Seq Acc: 10.80%
2025-03-25 01:03:19,134 - training_loop - INFO - 
LatentTransformer - Step 4100/10000 - Val Loss: 0.912653 - Seq Acc: 5.15%
2025-03-25 01:04:15,546 - training_loop - INFO - 
SimpleTransformer - Step 6750/10000 - Val Loss: 0.943649 - Seq Acc: 11.80%
2025-03-25 01:04:19,595 - training_loop - INFO - 
LatentTransformer - Step 4150/10000 - Val Loss: 0.921666 - Seq Acc: 5.00%
2025-03-25 01:05:21,157 - training_loop - INFO - 
SimpleTransformer - Step 6800/10000 - Val Loss: 0.966962 - Seq Acc: 11.05%
2025-03-25 01:05:25,863 - training_loop - INFO - 
LatentTransformer - Step 4200/10000 - Val Loss: 0.923962 - Seq Acc: 5.50%
2025-03-25 01:06:22,404 - training_loop - INFO - 
SimpleTransformer - Step 6850/10000 - Val Loss: 0.987363 - Seq Acc: 11.05%
2025-03-25 01:06:27,012 - training_loop - INFO - 
LatentTransformer - Step 4250/10000 - Val Loss: 0.920812 - Seq Acc: 5.65%
2025-03-25 01:07:22,809 - training_loop - INFO - 
SimpleTransformer - Step 6900/10000 - Val Loss: 0.982869 - Seq Acc: 10.80%
2025-03-25 01:07:26,639 - training_loop - INFO - 
LatentTransformer - Step 4300/10000 - Val Loss: 0.915024 - Seq Acc: 5.30%
2025-03-25 01:08:28,648 - training_loop - INFO - 
SimpleTransformer - Step 6950/10000 - Val Loss: 0.983945 - Seq Acc: 10.85%
2025-03-25 01:08:33,350 - training_loop - INFO - 
LatentTransformer - Step 4350/10000 - Val Loss: 0.925845 - Seq Acc: 5.35%
2025-03-25 01:09:36,548 - training_loop - INFO - 
SimpleTransformer - Step 7000/10000 - Val Loss: 1.011126 - Seq Acc: 11.05%
2025-03-25 01:09:40,668 - training_loop - INFO - 
LatentTransformer - Step 4400/10000 - Val Loss: 0.928138 - Seq Acc: 5.75%
2025-03-25 01:10:37,547 - training_loop - INFO - 
SimpleTransformer - Step 7050/10000 - Val Loss: 1.033442 - Seq Acc: 10.95%
2025-03-25 01:10:41,636 - training_loop - INFO - 
LatentTransformer - Step 4450/10000 - Val Loss: 0.925050 - Seq Acc: 5.65%
2025-03-25 01:11:42,779 - training_loop - INFO - 
SimpleTransformer - Step 7100/10000 - Val Loss: 1.024841 - Seq Acc: 10.80%
2025-03-25 01:11:47,050 - training_loop - INFO - 
LatentTransformer - Step 4500/10000 - Val Loss: 0.937267 - Seq Acc: 4.95%
2025-03-25 01:12:45,882 - training_loop - INFO - 
SimpleTransformer - Step 7150/10000 - Val Loss: 1.018966 - Seq Acc: 10.80%
2025-03-25 01:12:49,855 - training_loop - INFO - 
LatentTransformer - Step 4550/10000 - Val Loss: 0.940268 - Seq Acc: 5.15%
2025-03-25 01:13:46,408 - training_loop - INFO - 
SimpleTransformer - Step 7200/10000 - Val Loss: 1.038663 - Seq Acc: 10.55%
2025-03-25 01:13:50,953 - training_loop - INFO - 
LatentTransformer - Step 4600/10000 - Val Loss: 0.959382 - Seq Acc: 4.35%
2025-03-25 01:15:14,826 - __main__ - INFO - Using device: cuda
2025-03-25 01:15:14,826 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:15:14,826 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:15:14,826 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:15:16,479 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:15:18,341 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:15:18,343 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:15:18,343 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:15:18,344 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:15:18,344 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:15:18,344 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:15:18,344 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:15:18,344 - __main__ - INFO - Resuming training from checkpoints:
2025-03-25 01:15:18,344 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 01:15:18,344 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 01:15:19,696 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 7200, LatentTransformer: 3900
2025-03-25 01:15:19,697 - __main__ - WARNING - Using minimum step 3900 for resuming. This may cause imbalanced training.
2025-03-25 01:15:19,697 - __main__ - INFO - Resuming from step 3900/10000
2025-03-25 01:15:19,697 - training_loop - INFO - Using max_steps from args: 10000
2025-03-25 01:15:19,699 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:15:22,114 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 01:15:22,124 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 01:15:22,138 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 01:15:22,139 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:15:22,141 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:15:22,143 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:18:04,311 - training_loop - INFO - 
SimpleTransformer - Step 7250/10000 - Val Loss: 1.041092 - Seq Acc: 10.80%
2025-03-25 01:18:14,529 - training_loop - INFO - 
LatentTransformer - Step 3950/10000 - Val Loss: 0.927435 - Seq Acc: 4.85%
2025-03-25 01:19:31,978 - __main__ - INFO - Using device: cuda
2025-03-25 01:19:31,978 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:19:31,979 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:19:31,979 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:19:33,503 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:19:35,390 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:19:35,393 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:19:35,393 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:19:35,393 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:19:35,393 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:19:35,394 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:19:35,394 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:19:35,394 - __main__ - WARNING - Could not find checkpoints to resume from. Starting fresh training.
2025-03-25 01:19:35,395 - training_loop - INFO - Using max_steps from args: 10000
2025-03-25 01:19:35,398 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:19:37,815 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:19:37,819 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:19:37,822 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:21:05,968 - __main__ - INFO - Using device: cuda
2025-03-25 01:21:05,968 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:21:05,968 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:21:05,969 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:21:07,653 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:21:09,966 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:21:09,969 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:21:09,970 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:21:09,970 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:21:09,970 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:21:09,970 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:21:09,970 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:21:09,970 - __main__ - WARNING - Could not find checkpoints to resume from. Starting fresh training.
2025-03-25 01:21:09,970 - training_loop - INFO - Using max_steps from args: 10000
2025-03-25 01:21:09,973 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:21:12,876 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:21:12,879 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:21:12,881 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:23:11,301 - __main__ - INFO - Using device: cuda
2025-03-25 01:23:11,302 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:23:11,302 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:23:11,302 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:23:12,919 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:23:14,805 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:23:14,807 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:23:14,807 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:23:14,807 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:23:14,807 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:23:14,807 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:23:14,808 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:23:14,808 - __main__ - WARNING - Could not find checkpoints to resume from. Starting fresh training.
2025-03-25 01:23:14,808 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 01:23:14,810 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:23:17,478 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:23:17,480 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:23:17,482 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:24:02,124 - __main__ - INFO - Using device: cuda
2025-03-25 01:24:02,124 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:24:02,124 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:24:02,124 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:24:03,626 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:24:05,477 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:24:05,479 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:24:05,479 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:24:05,479 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:24:05,479 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:24:05,479 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:24:05,479 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:24:05,479 - __main__ - INFO - Resuming training from checkpoints:
2025-03-25 01:24:05,479 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_best.pt
2025-03-25 01:24:05,480 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_best.pt
2025-03-25 01:25:05,545 - __main__ - INFO - Using device: cuda
2025-03-25 01:25:05,545 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:25:05,545 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:25:05,545 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:25:07,176 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:25:09,179 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:25:09,181 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:25:09,181 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:25:09,181 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:25:09,182 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:25:09,182 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:25:09,182 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:25:09,182 - __main__ - INFO - Resuming training from checkpoints:
2025-03-25 01:25:09,182 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 01:25:09,182 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 01:25:47,215 - __main__ - INFO - Using device: cuda
2025-03-25 01:25:47,215 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:25:47,215 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:25:47,215 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:25:48,786 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:25:50,700 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:25:50,703 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:25:50,703 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:25:50,703 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:25:50,703 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:25:50,703 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:25:50,703 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:25:50,703 - __main__ - INFO - Resuming training from checkpoints:
2025-03-25 01:25:50,703 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 01:25:50,703 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 01:25:52,037 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 50, LatentTransformer: 3900
2025-03-25 01:25:52,038 - __main__ - WARNING - Using minimum step 50 for resuming. This may cause imbalanced training.
2025-03-25 01:25:52,038 - __main__ - INFO - Resuming from step 50/200000
2025-03-25 01:25:52,038 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 01:25:52,040 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:25:54,294 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 01:25:54,304 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 01:25:54,317 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 01:25:54,317 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:25:54,319 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:25:54,320 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:27:36,969 - training_loop - INFO - 
SimpleTransformer - Step 100/200000 - Val Loss: 1.628256 - Seq Acc: 0.45%
2025-03-25 01:28:42,610 - __main__ - INFO - Using device: cuda
2025-03-25 01:28:42,610 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:28:42,610 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:28:42,610 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:28:44,183 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:28:46,066 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:28:46,068 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:28:46,068 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:28:46,069 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:28:46,069 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:28:46,069 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:28:46,069 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:28:46,069 - __main__ - INFO - Resuming training from checkpoints:
2025-03-25 01:28:46,069 - __main__ - INFO - - SimpleTransformer: checkpoints/simpletransformer/simpletransformer_best.pt
2025-03-25 01:28:46,069 - __main__ - INFO - - LatentTransformer: checkpoints/latenttransformer/latenttransformer_best.pt
2025-03-25 01:28:48,157 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 100, LatentTransformer: 4100
2025-03-25 01:28:48,157 - __main__ - WARNING - Using minimum step 100 for resuming. This may cause imbalanced training.
2025-03-25 01:28:48,157 - __main__ - INFO - Resuming from step 100/200000
2025-03-25 01:28:48,157 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 01:28:48,160 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:28:50,572 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 01:28:50,584 - training_loop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 01:28:50,584 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 01:28:50,597 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 01:28:50,597 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:28:50,599 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:28:50,601 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:30:25,007 - training_loop - INFO - 
SimpleTransformer - Step 150/200000 - Val Loss: 1.619617 - Seq Acc: 0.50%
2025-03-25 01:30:33,365 - training_loop - INFO - 
LatentTransformer - Step 4150/200000 - Val Loss: 0.935920 - Seq Acc: 5.25%
2025-03-25 01:31:10,567 - training_loop - INFO - 
SimpleTransformer - Step 200/200000 - Val Loss: 1.581253 - Seq Acc: 0.50%
2025-03-25 01:31:58,894 - __main__ - INFO - Using device: cuda
2025-03-25 01:31:58,895 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:31:58,895 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:31:58,895 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:32:00,342 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:32:02,158 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:32:02,161 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:32:02,161 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:32:02,161 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:32:02,161 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:32:02,161 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:32:02,161 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:32:02,808 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 200, LatentTransformer: 4150
2025-03-25 01:32:02,808 - __main__ - WARNING - Using minimum step 200 for resuming. This may cause imbalanced training.
2025-03-25 01:32:02,808 - __main__ - INFO - Resuming from step 200/200000
2025-03-25 01:32:02,808 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 01:32:02,810 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:32:05,033 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 01:32:05,042 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 01:32:05,051 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:32:05,053 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:32:05,055 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:33:37,329 - training_loop - INFO - 
SimpleTransformer - Step 250/200000 - Val Loss: 1.547194 - Seq Acc: 0.50%
2025-03-25 01:33:49,581 - training_loop - INFO - 
LatentTransformer - Step 4200/200000 - Val Loss: 0.926731 - Seq Acc: 5.45%
2025-03-25 01:34:10,363 - __main__ - INFO - Using device: cuda
2025-03-25 01:34:10,363 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:34:10,363 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:34:10,363 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:34:11,935 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:34:13,973 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:34:13,975 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:34:13,975 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:34:13,975 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:34:13,976 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:34:13,976 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:34:13,976 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:34:16,252 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 250, LatentTransformer: 4200
2025-03-25 01:34:16,252 - __main__ - WARNING - Using minimum step 250 for resuming. This may cause imbalanced training.
2025-03-25 01:34:16,252 - __main__ - INFO - Resuming from step 250/200000
2025-03-25 01:34:16,252 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 01:34:16,254 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:34:18,966 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 01:34:18,978 - training_loop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 01:34:18,978 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 01:34:18,995 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 01:34:18,995 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:34:18,999 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:34:19,001 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:35:20,214 - __main__ - INFO - Using device: cuda
2025-03-25 01:35:20,214 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:35:20,214 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:35:20,214 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:35:21,736 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:35:23,724 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:35:23,726 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:35:23,726 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:35:23,726 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:35:23,727 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:35:23,727 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:35:23,727 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:35:25,791 - __main__ - WARNING - Model steps are unequal: SimpleTransformer: 250, LatentTransformer: 4200
2025-03-25 01:35:25,791 - __main__ - WARNING - Using minimum step 250 for resuming. This may cause imbalanced training.
2025-03-25 01:35:25,791 - __main__ - INFO - Resuming from step 250/200000
2025-03-25 01:35:25,791 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 01:35:25,793 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:35:28,186 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 01:35:28,197 - training_loop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 01:35:28,197 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 01:35:28,210 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 01:35:28,210 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:35:28,212 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:35:28,214 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:36:59,338 - training_loop - INFO - 
SimpleTransformer - Step 300/200000 - Val Loss: 1.505101 - Seq Acc: 0.70%
2025-03-25 01:37:07,627 - training_loop - INFO - 
LatentTransformer - Step 4250/200000 - Val Loss: 0.933803 - Seq Acc: 5.55%
2025-03-25 01:37:30,620 - __main__ - INFO - Using device: cuda
2025-03-25 01:37:30,620 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 01:37:30,621 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 01:37:30,621 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 01:37:32,279 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 01:37:34,361 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 01:37:34,364 - __main__ - INFO - 
Model Parameters:
2025-03-25 01:37:34,364 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 01:37:34,364 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 01:37:34,364 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 01:37:34,364 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 01:37:34,364 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 01:37:34,364 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 01:37:34,366 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 01:37:37,049 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 01:37:37,057 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 01:37:37,060 - training_loop - INFO - Starting: Training (steps)
2025-03-25 01:39:06,708 - training_loop - INFO - 
SimpleTransformer - Step 50/200000 - Val Loss: 1.631572 - Seq Acc: 0.40%
2025-03-25 01:39:17,185 - training_loop - INFO - 
LatentTransformer - Step 50/200000 - Val Loss: 1.695708 - Seq Acc: 0.50%
2025-03-25 01:39:51,524 - training_loop - INFO - 
SimpleTransformer - Step 100/200000 - Val Loss: 1.627491 - Seq Acc: 0.50%
2025-03-25 01:39:57,526 - training_loop - INFO - 
LatentTransformer - Step 100/200000 - Val Loss: 1.691682 - Seq Acc: 0.35%
2025-03-25 01:40:31,309 - training_loop - INFO - 
SimpleTransformer - Step 150/200000 - Val Loss: 1.620656 - Seq Acc: 0.50%
2025-03-25 01:40:37,250 - training_loop - INFO - 
LatentTransformer - Step 150/200000 - Val Loss: 1.682230 - Seq Acc: 0.45%
2025-03-25 01:41:10,936 - training_loop - INFO - 
SimpleTransformer - Step 200/200000 - Val Loss: 1.592644 - Seq Acc: 0.50%
2025-03-25 01:41:16,670 - training_loop - INFO - 
LatentTransformer - Step 200/200000 - Val Loss: 1.655311 - Seq Acc: 0.50%
2025-03-25 01:41:50,558 - training_loop - INFO - 
SimpleTransformer - Step 250/200000 - Val Loss: 1.544852 - Seq Acc: 0.50%
2025-03-25 01:41:56,581 - training_loop - INFO - 
LatentTransformer - Step 250/200000 - Val Loss: 1.612773 - Seq Acc: 0.45%
2025-03-25 01:42:53,098 - training_loop - INFO - 
SimpleTransformer - Step 300/200000 - Val Loss: 1.521702 - Seq Acc: 0.60%
2025-03-25 01:42:59,085 - training_loop - INFO - 
LatentTransformer - Step 300/200000 - Val Loss: 1.607411 - Seq Acc: 0.50%
2025-03-25 01:43:32,632 - training_loop - INFO - 
SimpleTransformer - Step 350/200000 - Val Loss: 1.488428 - Seq Acc: 0.45%
2025-03-25 01:43:38,627 - training_loop - INFO - 
LatentTransformer - Step 350/200000 - Val Loss: 1.586777 - Seq Acc: 0.45%
2025-03-25 01:44:30,145 - training_loop - INFO - 
SimpleTransformer - Step 400/200000 - Val Loss: 1.434507 - Seq Acc: 0.50%
2025-03-25 01:44:35,873 - training_loop - INFO - 
LatentTransformer - Step 400/200000 - Val Loss: 1.570156 - Seq Acc: 0.40%
2025-03-25 01:45:09,394 - training_loop - INFO - 
SimpleTransformer - Step 450/200000 - Val Loss: 1.399981 - Seq Acc: 0.90%
2025-03-25 01:45:15,358 - training_loop - INFO - 
LatentTransformer - Step 450/200000 - Val Loss: 1.547183 - Seq Acc: 0.50%
2025-03-25 01:45:49,117 - training_loop - INFO - 
SimpleTransformer - Step 500/200000 - Val Loss: 1.369168 - Seq Acc: 0.90%
2025-03-25 01:45:55,316 - training_loop - INFO - 
LatentTransformer - Step 500/200000 - Val Loss: 1.527882 - Seq Acc: 0.60%
2025-03-25 01:46:29,123 - training_loop - INFO - 
SimpleTransformer - Step 550/200000 - Val Loss: 1.347830 - Seq Acc: 0.90%
2025-03-25 01:46:35,259 - training_loop - INFO - 
LatentTransformer - Step 550/200000 - Val Loss: 1.500140 - Seq Acc: 0.90%
2025-03-25 01:47:08,888 - training_loop - INFO - 
SimpleTransformer - Step 600/200000 - Val Loss: 1.320624 - Seq Acc: 1.20%
2025-03-25 01:47:14,836 - training_loop - INFO - 
LatentTransformer - Step 600/200000 - Val Loss: 1.438212 - Seq Acc: 0.85%
2025-03-25 01:47:48,729 - training_loop - INFO - 
SimpleTransformer - Step 650/200000 - Val Loss: 1.295584 - Seq Acc: 1.05%
2025-03-25 01:47:54,733 - training_loop - INFO - 
LatentTransformer - Step 650/200000 - Val Loss: 1.393519 - Seq Acc: 0.90%
2025-03-25 01:48:28,590 - training_loop - INFO - 
SimpleTransformer - Step 700/200000 - Val Loss: 1.286379 - Seq Acc: 0.90%
2025-03-25 01:48:34,829 - training_loop - INFO - 
LatentTransformer - Step 700/200000 - Val Loss: 1.355560 - Seq Acc: 0.95%
2025-03-25 01:49:09,147 - training_loop - INFO - 
SimpleTransformer - Step 750/200000 - Val Loss: 1.279742 - Seq Acc: 1.20%
2025-03-25 01:49:15,381 - training_loop - INFO - 
LatentTransformer - Step 750/200000 - Val Loss: 1.337458 - Seq Acc: 0.90%
2025-03-25 01:49:49,666 - training_loop - INFO - 
SimpleTransformer - Step 800/200000 - Val Loss: 1.278643 - Seq Acc: 1.00%
2025-03-25 01:49:55,916 - training_loop - INFO - 
LatentTransformer - Step 800/200000 - Val Loss: 1.336248 - Seq Acc: 1.00%
2025-03-25 01:50:29,697 - training_loop - INFO - 
SimpleTransformer - Step 850/200000 - Val Loss: 1.269636 - Seq Acc: 1.05%
2025-03-25 01:50:36,068 - training_loop - INFO - 
LatentTransformer - Step 850/200000 - Val Loss: 1.324845 - Seq Acc: 1.40%
2025-03-25 01:51:07,518 - training_loop - INFO - 
SimpleTransformer - Step 900/200000 - Val Loss: 1.273848 - Seq Acc: 1.30%
2025-03-25 01:51:11,255 - training_loop - INFO - 
LatentTransformer - Step 900/200000 - Val Loss: 1.330129 - Seq Acc: 1.00%
2025-03-25 01:51:45,662 - training_loop - INFO - 
SimpleTransformer - Step 950/200000 - Val Loss: 1.267147 - Seq Acc: 0.90%
2025-03-25 01:51:49,518 - training_loop - INFO - 
LatentTransformer - Step 950/200000 - Val Loss: 1.326260 - Seq Acc: 0.95%
2025-03-25 01:52:23,137 - training_loop - INFO - 
SimpleTransformer - Step 1000/200000 - Val Loss: 1.264041 - Seq Acc: 1.00%
2025-03-25 01:52:26,696 - training_loop - INFO - 
LatentTransformer - Step 1000/200000 - Val Loss: 1.330496 - Seq Acc: 1.20%
2025-03-25 01:53:01,299 - training_loop - INFO - 
SimpleTransformer - Step 1050/200000 - Val Loss: 1.251194 - Seq Acc: 1.60%
2025-03-25 01:53:07,562 - training_loop - INFO - 
LatentTransformer - Step 1050/200000 - Val Loss: 1.320245 - Seq Acc: 1.20%
2025-03-25 01:53:41,303 - training_loop - INFO - 
SimpleTransformer - Step 1100/200000 - Val Loss: 1.245746 - Seq Acc: 1.20%
2025-03-25 01:53:47,498 - training_loop - INFO - 
LatentTransformer - Step 1100/200000 - Val Loss: 1.318025 - Seq Acc: 0.95%
2025-03-25 01:54:18,937 - training_loop - INFO - 
SimpleTransformer - Step 1150/200000 - Val Loss: 1.245792 - Seq Acc: 1.20%
2025-03-25 01:54:25,195 - training_loop - INFO - 
LatentTransformer - Step 1150/200000 - Val Loss: 1.311210 - Seq Acc: 1.15%
2025-03-25 01:54:58,720 - training_loop - INFO - 
SimpleTransformer - Step 1200/200000 - Val Loss: 1.239980 - Seq Acc: 1.20%
2025-03-25 01:55:02,268 - training_loop - INFO - 
LatentTransformer - Step 1200/200000 - Val Loss: 1.324333 - Seq Acc: 1.00%
2025-03-25 01:55:37,119 - training_loop - INFO - 
SimpleTransformer - Step 1250/200000 - Val Loss: 1.233989 - Seq Acc: 1.15%
2025-03-25 01:55:43,145 - training_loop - INFO - 
LatentTransformer - Step 1250/200000 - Val Loss: 1.309517 - Seq Acc: 1.15%
2025-03-25 01:56:16,821 - training_loop - INFO - 
SimpleTransformer - Step 1300/200000 - Val Loss: 1.230470 - Seq Acc: 1.40%
2025-03-25 01:56:23,030 - training_loop - INFO - 
LatentTransformer - Step 1300/200000 - Val Loss: 1.307056 - Seq Acc: 0.95%
2025-03-25 01:56:56,434 - training_loop - INFO - 
SimpleTransformer - Step 1350/200000 - Val Loss: 1.224833 - Seq Acc: 1.65%
2025-03-25 01:57:02,994 - training_loop - INFO - 
LatentTransformer - Step 1350/200000 - Val Loss: 1.305158 - Seq Acc: 1.50%
2025-03-25 01:57:36,974 - training_loop - INFO - 
SimpleTransformer - Step 1400/200000 - Val Loss: 1.215585 - Seq Acc: 1.75%
2025-03-25 01:57:40,290 - training_loop - INFO - 
LatentTransformer - Step 1400/200000 - Val Loss: 1.308612 - Seq Acc: 1.10%
2025-03-25 01:58:14,889 - training_loop - INFO - 
SimpleTransformer - Step 1450/200000 - Val Loss: 1.213106 - Seq Acc: 1.60%
2025-03-25 01:58:18,476 - training_loop - INFO - 
LatentTransformer - Step 1450/200000 - Val Loss: 1.307142 - Seq Acc: 1.25%
2025-03-25 01:58:52,515 - training_loop - INFO - 
SimpleTransformer - Step 1500/200000 - Val Loss: 1.196989 - Seq Acc: 1.60%
2025-03-25 01:58:56,071 - training_loop - INFO - 
LatentTransformer - Step 1500/200000 - Val Loss: 1.305703 - Seq Acc: 1.00%
2025-03-25 01:59:30,018 - training_loop - INFO - 
SimpleTransformer - Step 1550/200000 - Val Loss: 1.193339 - Seq Acc: 1.65%
2025-03-25 01:59:36,000 - training_loop - INFO - 
LatentTransformer - Step 1550/200000 - Val Loss: 1.304433 - Seq Acc: 1.20%
2025-03-25 02:00:09,606 - training_loop - INFO - 
SimpleTransformer - Step 1600/200000 - Val Loss: 1.178872 - Seq Acc: 1.80%
2025-03-25 02:00:15,223 - training_loop - INFO - 
LatentTransformer - Step 1600/200000 - Val Loss: 1.302038 - Seq Acc: 1.10%
2025-03-25 02:00:49,675 - training_loop - INFO - 
SimpleTransformer - Step 1650/200000 - Val Loss: 1.167546 - Seq Acc: 2.00%
2025-03-25 02:00:55,584 - training_loop - INFO - 
LatentTransformer - Step 1650/200000 - Val Loss: 1.298556 - Seq Acc: 1.00%
2025-03-25 02:01:30,423 - training_loop - INFO - 
SimpleTransformer - Step 1700/200000 - Val Loss: 1.158746 - Seq Acc: 1.95%
2025-03-25 02:01:34,000 - training_loop - INFO - 
LatentTransformer - Step 1700/200000 - Val Loss: 1.300254 - Seq Acc: 1.55%
2025-03-25 02:02:07,708 - training_loop - INFO - 
SimpleTransformer - Step 1750/200000 - Val Loss: 1.150455 - Seq Acc: 1.95%
2025-03-25 02:02:13,692 - training_loop - INFO - 
LatentTransformer - Step 1750/200000 - Val Loss: 1.296437 - Seq Acc: 1.00%
2025-03-25 02:02:47,198 - training_loop - INFO - 
SimpleTransformer - Step 1800/200000 - Val Loss: 1.132979 - Seq Acc: 2.00%
2025-03-25 02:02:50,553 - training_loop - INFO - 
LatentTransformer - Step 1800/200000 - Val Loss: 1.299293 - Seq Acc: 0.85%
2025-03-25 02:03:24,906 - training_loop - INFO - 
SimpleTransformer - Step 1850/200000 - Val Loss: 1.123949 - Seq Acc: 2.15%
2025-03-25 02:03:30,877 - training_loop - INFO - 
LatentTransformer - Step 1850/200000 - Val Loss: 1.293519 - Seq Acc: 0.95%
2025-03-25 02:04:04,512 - training_loop - INFO - 
SimpleTransformer - Step 1900/200000 - Val Loss: 1.113818 - Seq Acc: 1.85%
2025-03-25 02:04:10,393 - training_loop - INFO - 
LatentTransformer - Step 1900/200000 - Val Loss: 1.289958 - Seq Acc: 1.50%
2025-03-25 02:04:43,029 - training_loop - INFO - 
SimpleTransformer - Step 1950/200000 - Val Loss: 1.122473 - Seq Acc: 2.40%
2025-03-25 02:04:46,555 - training_loop - INFO - 
LatentTransformer - Step 1950/200000 - Val Loss: 1.295456 - Seq Acc: 0.95%
2025-03-25 02:05:20,900 - training_loop - INFO - 
SimpleTransformer - Step 2000/200000 - Val Loss: 1.104372 - Seq Acc: 2.70%
2025-03-25 02:05:24,385 - training_loop - INFO - 
LatentTransformer - Step 2000/200000 - Val Loss: 1.293497 - Seq Acc: 1.10%
2025-03-25 02:05:58,743 - training_loop - INFO - 
SimpleTransformer - Step 2050/200000 - Val Loss: 1.096159 - Seq Acc: 2.70%
2025-03-25 02:06:04,762 - training_loop - INFO - 
LatentTransformer - Step 2050/200000 - Val Loss: 1.287801 - Seq Acc: 0.95%
2025-03-25 02:06:39,183 - training_loop - INFO - 
SimpleTransformer - Step 2100/200000 - Val Loss: 1.094557 - Seq Acc: 2.65%
2025-03-25 02:06:42,709 - training_loop - INFO - 
LatentTransformer - Step 2100/200000 - Val Loss: 1.288092 - Seq Acc: 1.00%
2025-03-25 02:07:17,176 - training_loop - INFO - 
SimpleTransformer - Step 2150/200000 - Val Loss: 1.089989 - Seq Acc: 2.80%
2025-03-25 02:07:20,782 - training_loop - INFO - 
LatentTransformer - Step 2150/200000 - Val Loss: 1.289905 - Seq Acc: 1.15%
2025-03-25 02:07:55,016 - training_loop - INFO - 
SimpleTransformer - Step 2200/200000 - Val Loss: 1.081851 - Seq Acc: 2.50%
2025-03-25 02:07:58,463 - training_loop - INFO - 
LatentTransformer - Step 2200/200000 - Val Loss: 1.292069 - Seq Acc: 1.10%
2025-03-25 02:08:30,676 - training_loop - INFO - 
SimpleTransformer - Step 2250/200000 - Val Loss: 1.083625 - Seq Acc: 2.90%
2025-03-25 02:08:36,579 - training_loop - INFO - 
LatentTransformer - Step 2250/200000 - Val Loss: 1.284055 - Seq Acc: 1.00%
2025-03-25 02:09:12,024 - training_loop - INFO - 
SimpleTransformer - Step 2300/200000 - Val Loss: 1.074595 - Seq Acc: 3.10%
2025-03-25 02:09:15,630 - training_loop - INFO - 
LatentTransformer - Step 2300/200000 - Val Loss: 1.290110 - Seq Acc: 1.00%
2025-03-25 02:09:47,730 - training_loop - INFO - 
SimpleTransformer - Step 2350/200000 - Val Loss: 1.076637 - Seq Acc: 3.20%
2025-03-25 02:09:53,624 - training_loop - INFO - 
LatentTransformer - Step 2350/200000 - Val Loss: 1.281121 - Seq Acc: 1.15%
2025-03-25 02:10:27,866 - training_loop - INFO - 
SimpleTransformer - Step 2400/200000 - Val Loss: 1.067686 - Seq Acc: 3.15%
2025-03-25 02:10:31,321 - training_loop - INFO - 
LatentTransformer - Step 2400/200000 - Val Loss: 1.289823 - Seq Acc: 1.10%
2025-03-25 02:11:03,478 - training_loop - INFO - 
SimpleTransformer - Step 2450/200000 - Val Loss: 1.068003 - Seq Acc: 3.25%
2025-03-25 02:11:09,563 - training_loop - INFO - 
LatentTransformer - Step 2450/200000 - Val Loss: 1.278863 - Seq Acc: 0.95%
2025-03-25 02:11:44,611 - training_loop - INFO - 
SimpleTransformer - Step 2500/200000 - Val Loss: 1.064151 - Seq Acc: 3.15%
2025-03-25 02:11:50,556 - training_loop - INFO - 
LatentTransformer - Step 2500/200000 - Val Loss: 1.277992 - Seq Acc: 1.15%
2025-03-25 02:12:24,219 - training_loop - INFO - 
SimpleTransformer - Step 2550/200000 - Val Loss: 1.058849 - Seq Acc: 3.45%
2025-03-25 02:12:30,208 - training_loop - INFO - 
LatentTransformer - Step 2550/200000 - Val Loss: 1.277396 - Seq Acc: 1.05%
2025-03-25 02:13:01,541 - training_loop - INFO - 
SimpleTransformer - Step 2600/200000 - Val Loss: 1.063559 - Seq Acc: 3.35%
2025-03-25 02:13:04,892 - training_loop - INFO - 
LatentTransformer - Step 2600/200000 - Val Loss: 1.283142 - Seq Acc: 0.70%
2025-03-25 02:13:37,700 - training_loop - INFO - 
SimpleTransformer - Step 2650/200000 - Val Loss: 1.059146 - Seq Acc: 3.15%
2025-03-25 02:13:41,269 - training_loop - INFO - 
LatentTransformer - Step 2650/200000 - Val Loss: 1.280130 - Seq Acc: 0.90%
2025-03-25 02:14:16,154 - training_loop - INFO - 
SimpleTransformer - Step 2700/200000 - Val Loss: 1.053207 - Seq Acc: 3.20%
2025-03-25 02:14:22,292 - training_loop - INFO - 
LatentTransformer - Step 2700/200000 - Val Loss: 1.260913 - Seq Acc: 1.15%
2025-03-25 02:14:56,008 - training_loop - INFO - 
SimpleTransformer - Step 2750/200000 - Val Loss: 1.051135 - Seq Acc: 3.20%
2025-03-25 02:15:02,021 - training_loop - INFO - 
LatentTransformer - Step 2750/200000 - Val Loss: 1.240670 - Seq Acc: 1.20%
2025-03-25 02:15:36,292 - training_loop - INFO - 
SimpleTransformer - Step 2800/200000 - Val Loss: 1.049126 - Seq Acc: 3.45%
2025-03-25 02:15:42,017 - training_loop - INFO - 
LatentTransformer - Step 2800/200000 - Val Loss: 1.230027 - Seq Acc: 1.25%
2025-03-25 02:16:16,465 - training_loop - INFO - 
SimpleTransformer - Step 2850/200000 - Val Loss: 1.043140 - Seq Acc: 3.30%
2025-03-25 02:16:22,607 - training_loop - INFO - 
LatentTransformer - Step 2850/200000 - Val Loss: 1.225288 - Seq Acc: 1.10%
2025-03-25 02:16:56,461 - training_loop - INFO - 
SimpleTransformer - Step 2900/200000 - Val Loss: 1.041575 - Seq Acc: 3.55%
2025-03-25 02:17:02,467 - training_loop - INFO - 
LatentTransformer - Step 2900/200000 - Val Loss: 1.197428 - Seq Acc: 1.20%
2025-03-25 02:17:36,323 - training_loop - INFO - 
SimpleTransformer - Step 2950/200000 - Val Loss: 1.038461 - Seq Acc: 3.50%
2025-03-25 02:17:42,263 - training_loop - INFO - 
LatentTransformer - Step 2950/200000 - Val Loss: 1.193192 - Seq Acc: 1.65%
2025-03-25 02:18:15,471 - training_loop - INFO - 
SimpleTransformer - Step 3000/200000 - Val Loss: 1.040795 - Seq Acc: 3.35%
2025-03-25 02:18:21,361 - training_loop - INFO - 
LatentTransformer - Step 3000/200000 - Val Loss: 1.186598 - Seq Acc: 1.25%
2025-03-25 02:18:52,914 - training_loop - INFO - 
SimpleTransformer - Step 3050/200000 - Val Loss: 1.040504 - Seq Acc: 3.45%
2025-03-25 02:18:58,921 - training_loop - INFO - 
LatentTransformer - Step 3050/200000 - Val Loss: 1.180297 - Seq Acc: 2.10%
2025-03-25 02:19:34,005 - training_loop - INFO - 
SimpleTransformer - Step 3100/200000 - Val Loss: 1.032455 - Seq Acc: 3.35%
2025-03-25 02:19:39,924 - training_loop - INFO - 
LatentTransformer - Step 3100/200000 - Val Loss: 1.172135 - Seq Acc: 1.65%
2025-03-25 02:20:14,936 - training_loop - INFO - 
SimpleTransformer - Step 3150/200000 - Val Loss: 1.032201 - Seq Acc: 3.80%
2025-03-25 02:20:18,506 - training_loop - INFO - 
LatentTransformer - Step 3150/200000 - Val Loss: 1.176425 - Seq Acc: 1.60%
2025-03-25 02:20:49,992 - training_loop - INFO - 
SimpleTransformer - Step 3200/200000 - Val Loss: 1.037880 - Seq Acc: 3.85%
2025-03-25 02:20:55,839 - training_loop - INFO - 
LatentTransformer - Step 3200/200000 - Val Loss: 1.169180 - Seq Acc: 2.05%
2025-03-25 02:21:27,488 - training_loop - INFO - 
SimpleTransformer - Step 3250/200000 - Val Loss: 1.037669 - Seq Acc: 3.65%
2025-03-25 02:21:34,206 - training_loop - INFO - 
LatentTransformer - Step 3250/200000 - Val Loss: 1.166869 - Seq Acc: 1.80%
2025-03-25 02:22:09,832 - training_loop - INFO - 
SimpleTransformer - Step 3300/200000 - Val Loss: 1.027950 - Seq Acc: 3.55%
2025-03-25 02:22:15,953 - training_loop - INFO - 
LatentTransformer - Step 3300/200000 - Val Loss: 1.156722 - Seq Acc: 1.75%
2025-03-25 02:22:47,671 - training_loop - INFO - 
SimpleTransformer - Step 3350/200000 - Val Loss: 1.029363 - Seq Acc: 3.75%
2025-03-25 02:22:54,003 - training_loop - INFO - 
LatentTransformer - Step 3350/200000 - Val Loss: 1.154446 - Seq Acc: 2.10%
2025-03-25 02:23:27,900 - training_loop - INFO - 
SimpleTransformer - Step 3400/200000 - Val Loss: 1.025628 - Seq Acc: 4.55%
2025-03-25 02:23:33,803 - training_loop - INFO - 
LatentTransformer - Step 3400/200000 - Val Loss: 1.153842 - Seq Acc: 1.60%
2025-03-25 02:24:05,918 - training_loop - INFO - 
SimpleTransformer - Step 3450/200000 - Val Loss: 1.031358 - Seq Acc: 3.85%
2025-03-25 02:24:12,015 - training_loop - INFO - 
LatentTransformer - Step 3450/200000 - Val Loss: 1.141132 - Seq Acc: 1.90%
2025-03-25 02:24:47,718 - training_loop - INFO - 
SimpleTransformer - Step 3500/200000 - Val Loss: 1.015059 - Seq Acc: 4.05%
2025-03-25 02:24:53,897 - training_loop - INFO - 
LatentTransformer - Step 3500/200000 - Val Loss: 1.135003 - Seq Acc: 2.05%
2025-03-25 02:25:26,135 - training_loop - INFO - 
SimpleTransformer - Step 3550/200000 - Val Loss: 1.017265 - Seq Acc: 3.90%
2025-03-25 02:25:32,237 - training_loop - INFO - 
LatentTransformer - Step 3550/200000 - Val Loss: 1.134039 - Seq Acc: 1.95%
2025-03-25 02:26:04,957 - training_loop - INFO - 
SimpleTransformer - Step 3600/200000 - Val Loss: 1.027204 - Seq Acc: 4.25%
2025-03-25 02:26:10,909 - training_loop - INFO - 
LatentTransformer - Step 3600/200000 - Val Loss: 1.125719 - Seq Acc: 2.55%
2025-03-25 02:26:43,617 - training_loop - INFO - 
SimpleTransformer - Step 3650/200000 - Val Loss: 1.021366 - Seq Acc: 4.25%
2025-03-25 02:26:49,798 - training_loop - INFO - 
LatentTransformer - Step 3650/200000 - Val Loss: 1.115735 - Seq Acc: 1.75%
2025-03-25 02:27:21,441 - training_loop - INFO - 
SimpleTransformer - Step 3700/200000 - Val Loss: 1.018369 - Seq Acc: 4.25%
2025-03-25 02:27:27,682 - training_loop - INFO - 
LatentTransformer - Step 3700/200000 - Val Loss: 1.095440 - Seq Acc: 2.90%
2025-03-25 02:28:02,888 - training_loop - INFO - 
SimpleTransformer - Step 3750/200000 - Val Loss: 1.007746 - Seq Acc: 4.00%
2025-03-25 02:28:06,531 - training_loop - INFO - 
LatentTransformer - Step 3750/200000 - Val Loss: 1.097920 - Seq Acc: 3.10%
2025-03-25 02:28:39,266 - training_loop - INFO - 
SimpleTransformer - Step 3800/200000 - Val Loss: 1.012754 - Seq Acc: 4.30%
2025-03-25 02:28:45,190 - training_loop - INFO - 
LatentTransformer - Step 3800/200000 - Val Loss: 1.093773 - Seq Acc: 2.65%
2025-03-25 02:29:17,536 - training_loop - INFO - 
SimpleTransformer - Step 3850/200000 - Val Loss: 1.015156 - Seq Acc: 4.25%
2025-03-25 02:29:23,678 - training_loop - INFO - 
LatentTransformer - Step 3850/200000 - Val Loss: 1.086246 - Seq Acc: 2.80%
2025-03-25 02:29:59,266 - training_loop - INFO - 
SimpleTransformer - Step 3900/200000 - Val Loss: 1.003871 - Seq Acc: 4.70%
2025-03-25 02:30:03,032 - training_loop - INFO - 
LatentTransformer - Step 3900/200000 - Val Loss: 1.086583 - Seq Acc: 2.75%
2025-03-25 02:30:37,511 - training_loop - INFO - 
SimpleTransformer - Step 3950/200000 - Val Loss: 1.003200 - Seq Acc: 4.45%
2025-03-25 02:30:41,272 - training_loop - INFO - 
LatentTransformer - Step 3950/200000 - Val Loss: 1.088974 - Seq Acc: 2.60%
2025-03-25 02:31:13,385 - training_loop - INFO - 
SimpleTransformer - Step 4000/200000 - Val Loss: 1.004518 - Seq Acc: 4.65%
2025-03-25 02:31:16,962 - training_loop - INFO - 
LatentTransformer - Step 4000/200000 - Val Loss: 1.096967 - Seq Acc: 3.15%
2025-03-25 02:31:53,950 - training_loop - INFO - 
SimpleTransformer - Step 4050/200000 - Val Loss: 0.996525 - Seq Acc: 5.05%
2025-03-25 02:31:57,650 - training_loop - INFO - 
LatentTransformer - Step 4050/200000 - Val Loss: 1.093488 - Seq Acc: 2.85%
2025-03-25 02:32:32,359 - training_loop - INFO - 
SimpleTransformer - Step 4100/200000 - Val Loss: 1.001839 - Seq Acc: 4.60%
2025-03-25 02:32:36,093 - training_loop - INFO - 
LatentTransformer - Step 4100/200000 - Val Loss: 1.095105 - Seq Acc: 2.50%
2025-03-25 02:33:10,497 - training_loop - INFO - 
SimpleTransformer - Step 4150/200000 - Val Loss: 0.988510 - Seq Acc: 4.50%
2025-03-25 02:33:16,656 - training_loop - INFO - 
LatentTransformer - Step 4150/200000 - Val Loss: 1.085149 - Seq Acc: 2.60%
2025-03-25 02:33:50,751 - training_loop - INFO - 
SimpleTransformer - Step 4200/200000 - Val Loss: 0.988570 - Seq Acc: 4.60%
2025-03-25 02:33:54,332 - training_loop - INFO - 
LatentTransformer - Step 4200/200000 - Val Loss: 1.098207 - Seq Acc: 2.60%
2025-03-25 02:34:26,580 - training_loop - INFO - 
SimpleTransformer - Step 4250/200000 - Val Loss: 1.005040 - Seq Acc: 5.20%
2025-03-25 02:34:30,356 - training_loop - INFO - 
LatentTransformer - Step 4250/200000 - Val Loss: 1.087979 - Seq Acc: 3.10%
2025-03-25 02:35:06,116 - training_loop - INFO - 
SimpleTransformer - Step 4300/200000 - Val Loss: 0.976043 - Seq Acc: 4.90%
2025-03-25 02:35:12,248 - training_loop - INFO - 
LatentTransformer - Step 4300/200000 - Val Loss: 1.083197 - Seq Acc: 2.90%
2025-03-25 02:35:46,780 - training_loop - INFO - 
SimpleTransformer - Step 4350/200000 - Val Loss: 0.971414 - Seq Acc: 4.45%
2025-03-25 02:35:50,549 - training_loop - INFO - 
LatentTransformer - Step 4350/200000 - Val Loss: 1.090135 - Seq Acc: 2.75%
2025-03-25 02:36:24,395 - training_loop - INFO - 
SimpleTransformer - Step 4400/200000 - Val Loss: 0.966738 - Seq Acc: 5.20%
2025-03-25 02:36:27,908 - training_loop - INFO - 
LatentTransformer - Step 4400/200000 - Val Loss: 1.092694 - Seq Acc: 2.80%
2025-03-25 02:37:00,832 - training_loop - INFO - 
SimpleTransformer - Step 4450/200000 - Val Loss: 0.985598 - Seq Acc: 4.85%
2025-03-25 02:37:04,564 - training_loop - INFO - 
LatentTransformer - Step 4450/200000 - Val Loss: 1.090295 - Seq Acc: 2.95%
2025-03-25 02:37:36,214 - training_loop - INFO - 
SimpleTransformer - Step 4500/200000 - Val Loss: 0.981761 - Seq Acc: 5.10%
2025-03-25 02:37:39,911 - training_loop - INFO - 
LatentTransformer - Step 4500/200000 - Val Loss: 1.093144 - Seq Acc: 3.10%
2025-03-25 02:38:14,451 - training_loop - INFO - 
SimpleTransformer - Step 4550/200000 - Val Loss: 0.965824 - Seq Acc: 5.65%
2025-03-25 02:38:18,166 - training_loop - INFO - 
LatentTransformer - Step 4550/200000 - Val Loss: 1.088763 - Seq Acc: 3.05%
2025-03-25 02:38:53,902 - training_loop - INFO - 
SimpleTransformer - Step 4600/200000 - Val Loss: 0.962562 - Seq Acc: 4.95%
2025-03-25 02:38:57,395 - training_loop - INFO - 
LatentTransformer - Step 4600/200000 - Val Loss: 1.098825 - Seq Acc: 3.25%
2025-03-25 02:39:29,628 - training_loop - INFO - 
SimpleTransformer - Step 4650/200000 - Val Loss: 0.982259 - Seq Acc: 4.95%
2025-03-25 02:39:33,338 - training_loop - INFO - 
LatentTransformer - Step 4650/200000 - Val Loss: 1.091615 - Seq Acc: 2.95%
2025-03-25 02:40:07,582 - training_loop - INFO - 
SimpleTransformer - Step 4700/200000 - Val Loss: 0.952579 - Seq Acc: 5.00%
2025-03-25 02:40:11,259 - training_loop - INFO - 
LatentTransformer - Step 4700/200000 - Val Loss: 1.089282 - Seq Acc: 3.50%
2025-03-25 02:40:46,802 - training_loop - INFO - 
SimpleTransformer - Step 4750/200000 - Val Loss: 0.946740 - Seq Acc: 5.20%
2025-03-25 02:40:50,505 - training_loop - INFO - 
LatentTransformer - Step 4750/200000 - Val Loss: 1.100379 - Seq Acc: 3.25%
2025-03-25 02:41:24,173 - training_loop - INFO - 
SimpleTransformer - Step 4800/200000 - Val Loss: 0.946257 - Seq Acc: 5.00%
2025-03-25 02:41:27,688 - training_loop - INFO - 
LatentTransformer - Step 4800/200000 - Val Loss: 1.087575 - Seq Acc: 3.35%
2025-03-25 02:42:01,593 - training_loop - INFO - 
SimpleTransformer - Step 4850/200000 - Val Loss: 0.951144 - Seq Acc: 5.35%
2025-03-25 02:42:05,339 - training_loop - INFO - 
LatentTransformer - Step 4850/200000 - Val Loss: 1.098941 - Seq Acc: 3.25%
2025-03-25 02:42:40,297 - training_loop - INFO - 
SimpleTransformer - Step 4900/200000 - Val Loss: 0.944433 - Seq Acc: 5.35%
2025-03-25 02:42:44,038 - training_loop - INFO - 
LatentTransformer - Step 4900/200000 - Val Loss: 1.089538 - Seq Acc: 3.40%
2025-03-25 02:43:19,485 - training_loop - INFO - 
SimpleTransformer - Step 4950/200000 - Val Loss: 0.925260 - Seq Acc: 5.05%
2025-03-25 02:43:23,247 - training_loop - INFO - 
LatentTransformer - Step 4950/200000 - Val Loss: 1.085745 - Seq Acc: 3.10%
2025-03-25 02:43:55,604 - training_loop - INFO - 
SimpleTransformer - Step 5000/200000 - Val Loss: 0.931988 - Seq Acc: 5.10%
2025-03-25 02:43:59,130 - training_loop - INFO - 
LatentTransformer - Step 5000/200000 - Val Loss: 1.105136 - Seq Acc: 2.40%
2025-03-25 02:44:32,469 - training_loop - INFO - 
SimpleTransformer - Step 5050/200000 - Val Loss: 0.948413 - Seq Acc: 5.55%
2025-03-25 02:44:36,268 - training_loop - INFO - 
LatentTransformer - Step 5050/200000 - Val Loss: 1.102616 - Seq Acc: 3.15%
2025-03-25 02:45:07,694 - training_loop - INFO - 
SimpleTransformer - Step 5100/200000 - Val Loss: 0.930206 - Seq Acc: 5.55%
2025-03-25 02:45:11,559 - training_loop - INFO - 
LatentTransformer - Step 5100/200000 - Val Loss: 1.098871 - Seq Acc: 2.95%
2025-03-25 02:45:44,967 - training_loop - INFO - 
SimpleTransformer - Step 5150/200000 - Val Loss: 0.927128 - Seq Acc: 5.70%
2025-03-25 02:45:48,702 - training_loop - INFO - 
LatentTransformer - Step 5150/200000 - Val Loss: 1.107385 - Seq Acc: 2.80%
2025-03-25 02:46:24,800 - training_loop - INFO - 
SimpleTransformer - Step 5200/200000 - Val Loss: 0.901007 - Seq Acc: 6.20%
2025-03-25 02:46:28,299 - training_loop - INFO - 
LatentTransformer - Step 5200/200000 - Val Loss: 1.092471 - Seq Acc: 3.00%
2025-03-25 02:46:59,674 - training_loop - INFO - 
SimpleTransformer - Step 5250/200000 - Val Loss: 0.925858 - Seq Acc: 5.75%
2025-03-25 02:47:03,383 - training_loop - INFO - 
LatentTransformer - Step 5250/200000 - Val Loss: 1.108479 - Seq Acc: 3.20%
2025-03-25 02:47:36,124 - training_loop - INFO - 
SimpleTransformer - Step 5300/200000 - Val Loss: 0.921525 - Seq Acc: 5.80%
2025-03-25 02:47:39,992 - training_loop - INFO - 
LatentTransformer - Step 5300/200000 - Val Loss: 1.103923 - Seq Acc: 2.95%
2025-03-25 02:48:12,600 - training_loop - INFO - 
SimpleTransformer - Step 5350/200000 - Val Loss: 0.923388 - Seq Acc: 6.35%
2025-03-25 02:48:16,251 - training_loop - INFO - 
LatentTransformer - Step 5350/200000 - Val Loss: 1.100274 - Seq Acc: 2.95%
2025-03-25 02:48:52,202 - training_loop - INFO - 
SimpleTransformer - Step 5400/200000 - Val Loss: 0.899828 - Seq Acc: 5.75%
2025-03-25 02:48:55,728 - training_loop - INFO - 
LatentTransformer - Step 5400/200000 - Val Loss: 1.105572 - Seq Acc: 3.35%
2025-03-25 02:49:27,145 - training_loop - INFO - 
SimpleTransformer - Step 5450/200000 - Val Loss: 0.912155 - Seq Acc: 6.05%
2025-03-25 02:49:30,847 - training_loop - INFO - 
LatentTransformer - Step 5450/200000 - Val Loss: 1.108156 - Seq Acc: 3.60%
2025-03-25 02:50:02,278 - training_loop - INFO - 
SimpleTransformer - Step 5500/200000 - Val Loss: 0.922562 - Seq Acc: 6.30%
2025-03-25 02:50:05,978 - training_loop - INFO - 
LatentTransformer - Step 5500/200000 - Val Loss: 1.114360 - Seq Acc: 3.05%
2025-03-25 02:50:39,234 - training_loop - INFO - 
SimpleTransformer - Step 5550/200000 - Val Loss: 0.900708 - Seq Acc: 6.10%
2025-03-25 02:50:42,994 - training_loop - INFO - 
LatentTransformer - Step 5550/200000 - Val Loss: 1.110194 - Seq Acc: 3.05%
2025-03-25 02:51:19,261 - training_loop - INFO - 
SimpleTransformer - Step 5600/200000 - Val Loss: 0.876419 - Seq Acc: 5.70%
2025-03-25 02:51:22,829 - training_loop - INFO - 
LatentTransformer - Step 5600/200000 - Val Loss: 1.113367 - Seq Acc: 3.00%
2025-03-25 02:51:56,676 - training_loop - INFO - 
SimpleTransformer - Step 5650/200000 - Val Loss: 0.899201 - Seq Acc: 6.25%
2025-03-25 02:52:00,313 - training_loop - INFO - 
LatentTransformer - Step 5650/200000 - Val Loss: 1.129164 - Seq Acc: 2.80%
2025-03-25 02:52:32,258 - training_loop - INFO - 
SimpleTransformer - Step 5700/200000 - Val Loss: 0.916971 - Seq Acc: 6.45%
2025-03-25 02:52:35,975 - training_loop - INFO - 
LatentTransformer - Step 5700/200000 - Val Loss: 1.119629 - Seq Acc: 3.00%
2025-03-25 02:53:09,777 - training_loop - INFO - 
SimpleTransformer - Step 5750/200000 - Val Loss: 0.902014 - Seq Acc: 6.50%
2025-03-25 02:53:13,489 - training_loop - INFO - 
LatentTransformer - Step 5750/200000 - Val Loss: 1.133899 - Seq Acc: 3.15%
2025-03-25 02:53:45,841 - training_loop - INFO - 
SimpleTransformer - Step 5800/200000 - Val Loss: 0.910422 - Seq Acc: 6.45%
2025-03-25 02:53:49,376 - training_loop - INFO - 
LatentTransformer - Step 5800/200000 - Val Loss: 1.126085 - Seq Acc: 3.05%
2025-03-25 02:54:22,021 - training_loop - INFO - 
SimpleTransformer - Step 5850/200000 - Val Loss: 0.878201 - Seq Acc: 6.90%
2025-03-25 02:54:25,820 - training_loop - INFO - 
LatentTransformer - Step 5850/200000 - Val Loss: 1.131232 - Seq Acc: 2.95%
2025-03-25 02:54:58,988 - training_loop - INFO - 
SimpleTransformer - Step 5900/200000 - Val Loss: 0.905321 - Seq Acc: 6.80%
2025-03-25 02:55:02,798 - training_loop - INFO - 
LatentTransformer - Step 5900/200000 - Val Loss: 1.137803 - Seq Acc: 3.05%
2025-03-25 02:55:36,148 - training_loop - INFO - 
SimpleTransformer - Step 5950/200000 - Val Loss: 0.906023 - Seq Acc: 6.90%
2025-03-25 02:55:39,962 - training_loop - INFO - 
LatentTransformer - Step 5950/200000 - Val Loss: 1.138037 - Seq Acc: 3.25%
2025-03-25 02:56:13,826 - training_loop - INFO - 
SimpleTransformer - Step 6000/200000 - Val Loss: 0.881079 - Seq Acc: 6.65%
2025-03-25 02:56:17,393 - training_loop - INFO - 
LatentTransformer - Step 6000/200000 - Val Loss: 1.141738 - Seq Acc: 3.30%
2025-03-25 02:56:53,587 - training_loop - INFO - 
SimpleTransformer - Step 6050/200000 - Val Loss: 0.868156 - Seq Acc: 6.85%
2025-03-25 02:56:57,912 - training_loop - INFO - 
LatentTransformer - Step 6050/200000 - Val Loss: 1.137246 - Seq Acc: 3.00%
2025-03-25 02:57:33,054 - training_loop - INFO - 
SimpleTransformer - Step 6100/200000 - Val Loss: 0.910474 - Seq Acc: 6.80%
2025-03-25 02:57:36,836 - training_loop - INFO - 
LatentTransformer - Step 6100/200000 - Val Loss: 1.139513 - Seq Acc: 3.05%
2025-03-25 02:58:10,531 - training_loop - INFO - 
SimpleTransformer - Step 6150/200000 - Val Loss: 0.886416 - Seq Acc: 7.60%
2025-03-25 02:58:14,187 - training_loop - INFO - 
LatentTransformer - Step 6150/200000 - Val Loss: 1.148683 - Seq Acc: 3.05%
2025-03-25 02:58:47,278 - training_loop - INFO - 
SimpleTransformer - Step 6200/200000 - Val Loss: 0.897447 - Seq Acc: 6.55%
2025-03-25 02:58:50,850 - training_loop - INFO - 
LatentTransformer - Step 6200/200000 - Val Loss: 1.173898 - Seq Acc: 3.05%
2025-03-25 02:59:23,590 - training_loop - INFO - 
SimpleTransformer - Step 6250/200000 - Val Loss: 0.873010 - Seq Acc: 7.45%
2025-03-25 02:59:27,365 - training_loop - INFO - 
LatentTransformer - Step 6250/200000 - Val Loss: 1.158360 - Seq Acc: 3.20%
2025-03-25 03:00:00,627 - training_loop - INFO - 
SimpleTransformer - Step 6300/200000 - Val Loss: 0.911080 - Seq Acc: 7.05%
2025-03-25 03:00:05,053 - training_loop - INFO - 
LatentTransformer - Step 6300/200000 - Val Loss: 1.162178 - Seq Acc: 3.40%
2025-03-25 03:00:37,098 - training_loop - INFO - 
SimpleTransformer - Step 6350/200000 - Val Loss: 0.899549 - Seq Acc: 7.40%
2025-03-25 03:00:40,818 - training_loop - INFO - 
LatentTransformer - Step 6350/200000 - Val Loss: 1.158370 - Seq Acc: 3.00%
2025-03-25 03:01:15,748 - training_loop - INFO - 
SimpleTransformer - Step 6400/200000 - Val Loss: 0.888198 - Seq Acc: 6.85%
2025-03-25 03:01:19,243 - training_loop - INFO - 
LatentTransformer - Step 6400/200000 - Val Loss: 1.151444 - Seq Acc: 3.55%
2025-03-25 03:01:53,782 - training_loop - INFO - 
SimpleTransformer - Step 6450/200000 - Val Loss: 0.886524 - Seq Acc: 7.20%
2025-03-25 03:01:57,524 - training_loop - INFO - 
LatentTransformer - Step 6450/200000 - Val Loss: 1.162760 - Seq Acc: 3.55%
2025-03-25 03:02:29,496 - training_loop - INFO - 
SimpleTransformer - Step 6500/200000 - Val Loss: 0.913913 - Seq Acc: 7.70%
2025-03-25 03:02:33,220 - training_loop - INFO - 
LatentTransformer - Step 6500/200000 - Val Loss: 1.187728 - Seq Acc: 3.55%
2025-03-25 03:03:05,828 - training_loop - INFO - 
SimpleTransformer - Step 6550/200000 - Val Loss: 0.910099 - Seq Acc: 7.85%
2025-03-25 03:03:09,505 - training_loop - INFO - 
LatentTransformer - Step 6550/200000 - Val Loss: 1.156845 - Seq Acc: 3.40%
2025-03-25 03:03:43,723 - training_loop - INFO - 
SimpleTransformer - Step 6600/200000 - Val Loss: 0.901719 - Seq Acc: 7.15%
2025-03-25 03:03:47,217 - training_loop - INFO - 
LatentTransformer - Step 6600/200000 - Val Loss: 1.179555 - Seq Acc: 3.05%
2025-03-25 03:04:19,847 - training_loop - INFO - 
SimpleTransformer - Step 6650/200000 - Val Loss: 0.874596 - Seq Acc: 7.50%
2025-03-25 03:04:23,626 - training_loop - INFO - 
LatentTransformer - Step 6650/200000 - Val Loss: 1.191343 - Seq Acc: 3.35%
2025-03-25 03:04:56,142 - training_loop - INFO - 
SimpleTransformer - Step 6700/200000 - Val Loss: 0.909804 - Seq Acc: 7.40%
2025-03-25 03:04:59,815 - training_loop - INFO - 
LatentTransformer - Step 6700/200000 - Val Loss: 1.180923 - Seq Acc: 3.40%
2025-03-25 03:05:33,079 - training_loop - INFO - 
SimpleTransformer - Step 6750/200000 - Val Loss: 0.931728 - Seq Acc: 7.80%
2025-03-25 03:05:36,856 - training_loop - INFO - 
LatentTransformer - Step 6750/200000 - Val Loss: 1.175551 - Seq Acc: 3.95%
2025-03-25 03:06:08,725 - training_loop - INFO - 
SimpleTransformer - Step 6800/200000 - Val Loss: 0.933568 - Seq Acc: 7.60%
2025-03-25 03:06:12,183 - training_loop - INFO - 
LatentTransformer - Step 6800/200000 - Val Loss: 1.201961 - Seq Acc: 3.65%
2025-03-25 03:06:44,813 - training_loop - INFO - 
SimpleTransformer - Step 6850/200000 - Val Loss: 0.889639 - Seq Acc: 7.50%
2025-03-25 03:06:48,503 - training_loop - INFO - 
LatentTransformer - Step 6850/200000 - Val Loss: 1.189170 - Seq Acc: 3.55%
2025-03-25 03:07:21,051 - training_loop - INFO - 
SimpleTransformer - Step 6900/200000 - Val Loss: 0.909572 - Seq Acc: 7.05%
2025-03-25 03:07:24,805 - training_loop - INFO - 
LatentTransformer - Step 6900/200000 - Val Loss: 1.226232 - Seq Acc: 3.40%
2025-03-25 03:08:00,445 - training_loop - INFO - 
SimpleTransformer - Step 6950/200000 - Val Loss: 0.920075 - Seq Acc: 7.20%
2025-03-25 03:08:04,149 - training_loop - INFO - 
LatentTransformer - Step 6950/200000 - Val Loss: 1.181601 - Seq Acc: 3.95%
2025-03-25 03:08:38,315 - training_loop - INFO - 
SimpleTransformer - Step 7000/200000 - Val Loss: 0.919105 - Seq Acc: 7.50%
2025-03-25 03:08:41,778 - training_loop - INFO - 
LatentTransformer - Step 7000/200000 - Val Loss: 1.181933 - Seq Acc: 4.45%
2025-03-25 03:09:15,656 - training_loop - INFO - 
SimpleTransformer - Step 7050/200000 - Val Loss: 0.898387 - Seq Acc: 6.95%
2025-03-25 03:09:19,360 - training_loop - INFO - 
LatentTransformer - Step 7050/200000 - Val Loss: 1.211201 - Seq Acc: 3.95%
2025-03-25 03:09:55,691 - training_loop - INFO - 
SimpleTransformer - Step 7100/200000 - Val Loss: 0.927064 - Seq Acc: 7.45%
2025-03-25 03:09:59,424 - training_loop - INFO - 
LatentTransformer - Step 7100/200000 - Val Loss: 1.215553 - Seq Acc: 3.65%
2025-03-25 03:10:32,587 - training_loop - INFO - 
SimpleTransformer - Step 7150/200000 - Val Loss: 0.936216 - Seq Acc: 7.60%
2025-03-25 03:10:36,251 - training_loop - INFO - 
LatentTransformer - Step 7150/200000 - Val Loss: 1.204140 - Seq Acc: 3.90%
2025-03-25 03:11:08,675 - training_loop - INFO - 
SimpleTransformer - Step 7200/200000 - Val Loss: 0.932297 - Seq Acc: 8.30%
2025-03-25 03:11:12,172 - training_loop - INFO - 
LatentTransformer - Step 7200/200000 - Val Loss: 1.200789 - Seq Acc: 3.85%
2025-03-25 03:11:46,662 - training_loop - INFO - 
SimpleTransformer - Step 7250/200000 - Val Loss: 0.929379 - Seq Acc: 8.10%
2025-03-25 03:11:50,346 - training_loop - INFO - 
LatentTransformer - Step 7250/200000 - Val Loss: 1.231490 - Seq Acc: 3.65%
2025-03-25 03:12:22,967 - training_loop - INFO - 
SimpleTransformer - Step 7300/200000 - Val Loss: 0.936993 - Seq Acc: 7.95%
2025-03-25 03:12:26,642 - training_loop - INFO - 
LatentTransformer - Step 7300/200000 - Val Loss: 1.254197 - Seq Acc: 4.00%
2025-03-25 03:12:58,037 - training_loop - INFO - 
SimpleTransformer - Step 7350/200000 - Val Loss: 0.951093 - Seq Acc: 7.95%
2025-03-25 03:13:01,692 - training_loop - INFO - 
LatentTransformer - Step 7350/200000 - Val Loss: 1.237244 - Seq Acc: 3.70%
2025-03-25 03:13:35,422 - training_loop - INFO - 
SimpleTransformer - Step 7400/200000 - Val Loss: 0.957887 - Seq Acc: 8.15%
2025-03-25 03:13:38,881 - training_loop - INFO - 
LatentTransformer - Step 7400/200000 - Val Loss: 1.237053 - Seq Acc: 4.60%
2025-03-25 03:14:12,180 - training_loop - INFO - 
SimpleTransformer - Step 7450/200000 - Val Loss: 0.936019 - Seq Acc: 8.05%
2025-03-25 03:14:15,876 - training_loop - INFO - 
LatentTransformer - Step 7450/200000 - Val Loss: 1.229298 - Seq Acc: 4.05%
2025-03-25 03:14:49,018 - training_loop - INFO - 
SimpleTransformer - Step 7500/200000 - Val Loss: 0.941035 - Seq Acc: 8.30%
2025-03-25 03:14:52,791 - training_loop - INFO - 
LatentTransformer - Step 7500/200000 - Val Loss: 1.265575 - Seq Acc: 3.85%
2025-03-25 03:15:26,016 - training_loop - INFO - 
SimpleTransformer - Step 7550/200000 - Val Loss: 0.973724 - Seq Acc: 8.15%
2025-03-25 03:15:29,668 - training_loop - INFO - 
LatentTransformer - Step 7550/200000 - Val Loss: 1.250855 - Seq Acc: 4.05%
2025-03-25 03:16:04,570 - training_loop - INFO - 
SimpleTransformer - Step 7600/200000 - Val Loss: 1.028718 - Seq Acc: 7.55%
2025-03-25 03:16:08,112 - training_loop - INFO - 
LatentTransformer - Step 7600/200000 - Val Loss: 1.244189 - Seq Acc: 4.25%
2025-03-25 03:16:42,971 - training_loop - INFO - 
SimpleTransformer - Step 7650/200000 - Val Loss: 0.973842 - Seq Acc: 8.30%
2025-03-25 03:16:46,645 - training_loop - INFO - 
LatentTransformer - Step 7650/200000 - Val Loss: 1.247392 - Seq Acc: 4.25%
2025-03-25 03:17:18,657 - training_loop - INFO - 
SimpleTransformer - Step 7700/200000 - Val Loss: 0.971607 - Seq Acc: 7.70%
2025-03-25 03:17:22,462 - training_loop - INFO - 
LatentTransformer - Step 7700/200000 - Val Loss: 1.261211 - Seq Acc: 3.85%
2025-03-25 03:17:55,062 - training_loop - INFO - 
SimpleTransformer - Step 7750/200000 - Val Loss: 0.998329 - Seq Acc: 8.05%
2025-03-25 03:17:58,897 - training_loop - INFO - 
LatentTransformer - Step 7750/200000 - Val Loss: 1.287736 - Seq Acc: 3.60%
2025-03-25 03:18:31,287 - training_loop - INFO - 
SimpleTransformer - Step 7800/200000 - Val Loss: 0.979288 - Seq Acc: 8.20%
2025-03-25 03:18:34,785 - training_loop - INFO - 
LatentTransformer - Step 7800/200000 - Val Loss: 1.317755 - Seq Acc: 3.90%
2025-03-25 03:19:06,935 - training_loop - INFO - 
SimpleTransformer - Step 7850/200000 - Val Loss: 1.007943 - Seq Acc: 7.45%
2025-03-25 03:19:10,748 - training_loop - INFO - 
LatentTransformer - Step 7850/200000 - Val Loss: 1.277900 - Seq Acc: 4.10%
2025-03-25 03:19:43,963 - training_loop - INFO - 
SimpleTransformer - Step 7900/200000 - Val Loss: 0.967513 - Seq Acc: 7.90%
2025-03-25 03:19:47,702 - training_loop - INFO - 
LatentTransformer - Step 7900/200000 - Val Loss: 1.310331 - Seq Acc: 4.40%
2025-03-25 03:20:22,222 - training_loop - INFO - 
SimpleTransformer - Step 7950/200000 - Val Loss: 0.988632 - Seq Acc: 8.75%
2025-03-25 03:20:25,986 - training_loop - INFO - 
LatentTransformer - Step 7950/200000 - Val Loss: 1.299446 - Seq Acc: 3.90%
2025-03-25 03:20:59,844 - training_loop - INFO - 
SimpleTransformer - Step 8000/200000 - Val Loss: 1.005026 - Seq Acc: 8.15%
2025-03-25 03:21:03,408 - training_loop - INFO - 
LatentTransformer - Step 8000/200000 - Val Loss: 1.268021 - Seq Acc: 4.00%
2025-03-25 03:21:39,032 - training_loop - INFO - 
SimpleTransformer - Step 8050/200000 - Val Loss: 1.007914 - Seq Acc: 8.90%
2025-03-25 03:21:42,790 - training_loop - INFO - 
LatentTransformer - Step 8050/200000 - Val Loss: 1.295557 - Seq Acc: 4.20%
2025-03-25 03:22:16,044 - training_loop - INFO - 
SimpleTransformer - Step 8100/200000 - Val Loss: 0.994134 - Seq Acc: 8.10%
2025-03-25 03:22:19,760 - training_loop - INFO - 
LatentTransformer - Step 8100/200000 - Val Loss: 1.318212 - Seq Acc: 4.25%
2025-03-25 03:22:52,981 - training_loop - INFO - 
SimpleTransformer - Step 8150/200000 - Val Loss: 1.009711 - Seq Acc: 8.75%
2025-03-25 03:22:56,682 - training_loop - INFO - 
LatentTransformer - Step 8150/200000 - Val Loss: 1.312591 - Seq Acc: 4.45%
2025-03-25 03:23:30,246 - training_loop - INFO - 
SimpleTransformer - Step 8200/200000 - Val Loss: 1.009688 - Seq Acc: 8.40%
2025-03-25 03:23:33,818 - training_loop - INFO - 
LatentTransformer - Step 8200/200000 - Val Loss: 1.360699 - Seq Acc: 3.95%
2025-03-25 03:24:07,186 - training_loop - INFO - 
SimpleTransformer - Step 8250/200000 - Val Loss: 1.020333 - Seq Acc: 8.00%
2025-03-25 03:24:10,931 - training_loop - INFO - 
LatentTransformer - Step 8250/200000 - Val Loss: 1.315162 - Seq Acc: 4.00%
2025-03-25 03:24:44,863 - training_loop - INFO - 
SimpleTransformer - Step 8300/200000 - Val Loss: 1.027630 - Seq Acc: 8.10%
2025-03-25 03:24:48,589 - training_loop - INFO - 
LatentTransformer - Step 8300/200000 - Val Loss: 1.338873 - Seq Acc: 4.75%
2025-03-25 03:25:21,225 - training_loop - INFO - 
SimpleTransformer - Step 8350/200000 - Val Loss: 1.037813 - Seq Acc: 8.25%
2025-03-25 03:25:24,930 - training_loop - INFO - 
LatentTransformer - Step 8350/200000 - Val Loss: 1.331232 - Seq Acc: 4.15%
2025-03-25 03:25:56,822 - training_loop - INFO - 
SimpleTransformer - Step 8400/200000 - Val Loss: 1.054834 - Seq Acc: 8.10%
2025-03-25 03:26:00,303 - training_loop - INFO - 
LatentTransformer - Step 8400/200000 - Val Loss: 1.390387 - Seq Acc: 4.30%
2025-03-25 03:26:34,837 - training_loop - INFO - 
SimpleTransformer - Step 8450/200000 - Val Loss: 1.056604 - Seq Acc: 8.10%
2025-03-25 03:26:38,632 - training_loop - INFO - 
LatentTransformer - Step 8450/200000 - Val Loss: 1.354776 - Seq Acc: 4.30%
2025-03-25 03:27:11,887 - training_loop - INFO - 
SimpleTransformer - Step 8500/200000 - Val Loss: 1.072172 - Seq Acc: 7.85%
2025-03-25 03:27:15,603 - training_loop - INFO - 
LatentTransformer - Step 8500/200000 - Val Loss: 1.384015 - Seq Acc: 4.35%
2025-03-25 03:27:50,202 - training_loop - INFO - 
SimpleTransformer - Step 8550/200000 - Val Loss: 1.057642 - Seq Acc: 8.35%
2025-03-25 03:27:53,980 - training_loop - INFO - 
LatentTransformer - Step 8550/200000 - Val Loss: 1.389540 - Seq Acc: 4.50%
2025-03-25 03:28:27,275 - training_loop - INFO - 
SimpleTransformer - Step 8600/200000 - Val Loss: 1.077141 - Seq Acc: 8.20%
2025-03-25 03:28:30,826 - training_loop - INFO - 
LatentTransformer - Step 8600/200000 - Val Loss: 1.375575 - Seq Acc: 3.70%
2025-03-25 03:29:02,307 - training_loop - INFO - 
SimpleTransformer - Step 8650/200000 - Val Loss: 1.051325 - Seq Acc: 9.05%
2025-03-25 03:29:06,123 - training_loop - INFO - 
LatentTransformer - Step 8650/200000 - Val Loss: 1.403486 - Seq Acc: 4.25%
2025-03-25 03:29:40,640 - training_loop - INFO - 
SimpleTransformer - Step 8700/200000 - Val Loss: 1.082509 - Seq Acc: 8.10%
2025-03-25 03:29:44,388 - training_loop - INFO - 
LatentTransformer - Step 8700/200000 - Val Loss: 1.376670 - Seq Acc: 4.30%
2025-03-25 03:30:19,704 - training_loop - INFO - 
SimpleTransformer - Step 8750/200000 - Val Loss: 1.088112 - Seq Acc: 8.55%
2025-03-25 03:30:23,671 - training_loop - INFO - 
LatentTransformer - Step 8750/200000 - Val Loss: 1.369625 - Seq Acc: 4.45%
2025-03-25 03:30:58,338 - training_loop - INFO - 
SimpleTransformer - Step 8800/200000 - Val Loss: 1.087478 - Seq Acc: 8.75%
2025-03-25 03:31:01,942 - training_loop - INFO - 
LatentTransformer - Step 8800/200000 - Val Loss: 1.408984 - Seq Acc: 4.20%
2025-03-25 03:31:37,958 - training_loop - INFO - 
SimpleTransformer - Step 8850/200000 - Val Loss: 1.075541 - Seq Acc: 8.10%
2025-03-25 03:31:41,697 - training_loop - INFO - 
LatentTransformer - Step 8850/200000 - Val Loss: 1.432014 - Seq Acc: 3.85%
2025-03-25 03:32:16,448 - training_loop - INFO - 
SimpleTransformer - Step 8900/200000 - Val Loss: 1.088708 - Seq Acc: 7.80%
2025-03-25 03:32:21,019 - training_loop - INFO - 
LatentTransformer - Step 8900/200000 - Val Loss: 1.442937 - Seq Acc: 4.35%
2025-03-25 03:32:56,875 - training_loop - INFO - 
SimpleTransformer - Step 8950/200000 - Val Loss: 1.111591 - Seq Acc: 9.25%
2025-03-25 03:33:01,914 - training_loop - INFO - 
LatentTransformer - Step 8950/200000 - Val Loss: 1.423383 - Seq Acc: 4.25%
2025-03-25 03:33:37,046 - training_loop - INFO - 
SimpleTransformer - Step 9000/200000 - Val Loss: 1.091129 - Seq Acc: 8.50%
2025-03-25 03:33:41,819 - training_loop - INFO - 
LatentTransformer - Step 9000/200000 - Val Loss: 1.414030 - Seq Acc: 4.55%
2025-03-25 03:34:14,913 - training_loop - INFO - 
SimpleTransformer - Step 9050/200000 - Val Loss: 1.118914 - Seq Acc: 7.70%
2025-03-25 03:34:19,270 - training_loop - INFO - 
LatentTransformer - Step 9050/200000 - Val Loss: 1.469246 - Seq Acc: 4.25%
2025-03-25 03:34:54,012 - training_loop - INFO - 
SimpleTransformer - Step 9100/200000 - Val Loss: 1.053558 - Seq Acc: 8.00%
2025-03-25 03:34:57,990 - training_loop - INFO - 
LatentTransformer - Step 9100/200000 - Val Loss: 1.475187 - Seq Acc: 4.25%
2025-03-25 03:35:30,355 - training_loop - INFO - 
SimpleTransformer - Step 9150/200000 - Val Loss: 1.084298 - Seq Acc: 8.30%
2025-03-25 03:35:34,254 - training_loop - INFO - 
LatentTransformer - Step 9150/200000 - Val Loss: 1.454708 - Seq Acc: 4.45%
2025-03-25 03:36:07,132 - training_loop - INFO - 
SimpleTransformer - Step 9200/200000 - Val Loss: 1.111183 - Seq Acc: 8.70%
2025-03-25 03:36:10,994 - training_loop - INFO - 
LatentTransformer - Step 9200/200000 - Val Loss: 1.446701 - Seq Acc: 3.95%
2025-03-25 03:36:46,820 - training_loop - INFO - 
SimpleTransformer - Step 9250/200000 - Val Loss: 1.072562 - Seq Acc: 9.10%
2025-03-25 03:36:50,692 - training_loop - INFO - 
LatentTransformer - Step 9250/200000 - Val Loss: 1.448741 - Seq Acc: 4.40%
2025-03-25 03:37:25,376 - training_loop - INFO - 
SimpleTransformer - Step 9300/200000 - Val Loss: 1.098584 - Seq Acc: 8.20%
2025-03-25 03:37:29,394 - training_loop - INFO - 
LatentTransformer - Step 9300/200000 - Val Loss: 1.425712 - Seq Acc: 5.00%
2025-03-25 03:38:03,482 - training_loop - INFO - 
SimpleTransformer - Step 9350/200000 - Val Loss: 1.113985 - Seq Acc: 8.50%
2025-03-25 03:38:07,369 - training_loop - INFO - 
LatentTransformer - Step 9350/200000 - Val Loss: 1.470157 - Seq Acc: 4.75%
2025-03-25 03:38:40,122 - training_loop - INFO - 
SimpleTransformer - Step 9400/200000 - Val Loss: 1.156721 - Seq Acc: 8.00%
2025-03-25 03:38:43,930 - training_loop - INFO - 
LatentTransformer - Step 9400/200000 - Val Loss: 1.457010 - Seq Acc: 4.85%
2025-03-25 03:39:16,906 - training_loop - INFO - 
SimpleTransformer - Step 9450/200000 - Val Loss: 1.121209 - Seq Acc: 8.80%
2025-03-25 03:39:20,896 - training_loop - INFO - 
LatentTransformer - Step 9450/200000 - Val Loss: 1.475733 - Seq Acc: 4.65%
2025-03-25 03:39:55,729 - training_loop - INFO - 
SimpleTransformer - Step 9500/200000 - Val Loss: 1.119712 - Seq Acc: 8.95%
2025-03-25 03:39:59,829 - training_loop - INFO - 
LatentTransformer - Step 9500/200000 - Val Loss: 1.486908 - Seq Acc: 5.30%
2025-03-25 03:40:37,094 - training_loop - INFO - 
SimpleTransformer - Step 9550/200000 - Val Loss: 1.115570 - Seq Acc: 8.70%
2025-03-25 03:40:41,101 - training_loop - INFO - 
LatentTransformer - Step 9550/200000 - Val Loss: 1.448876 - Seq Acc: 4.55%
2025-03-25 03:41:15,197 - training_loop - INFO - 
SimpleTransformer - Step 9600/200000 - Val Loss: 1.134906 - Seq Acc: 8.80%
2025-03-25 03:41:18,975 - training_loop - INFO - 
LatentTransformer - Step 9600/200000 - Val Loss: 1.467945 - Seq Acc: 4.90%
2025-03-25 03:41:54,938 - training_loop - INFO - 
SimpleTransformer - Step 9650/200000 - Val Loss: 1.116539 - Seq Acc: 8.65%
2025-03-25 03:41:58,873 - training_loop - INFO - 
LatentTransformer - Step 9650/200000 - Val Loss: 1.468432 - Seq Acc: 4.90%
2025-03-25 03:42:34,287 - training_loop - INFO - 
SimpleTransformer - Step 9700/200000 - Val Loss: 1.118381 - Seq Acc: 8.10%
2025-03-25 03:42:38,817 - training_loop - INFO - 
LatentTransformer - Step 9700/200000 - Val Loss: 1.499559 - Seq Acc: 5.70%
2025-03-25 03:43:14,392 - training_loop - INFO - 
SimpleTransformer - Step 9750/200000 - Val Loss: 1.120284 - Seq Acc: 8.40%
2025-03-25 03:43:18,375 - training_loop - INFO - 
LatentTransformer - Step 9750/200000 - Val Loss: 1.510331 - Seq Acc: 4.95%
2025-03-25 03:43:55,387 - training_loop - INFO - 
SimpleTransformer - Step 9800/200000 - Val Loss: 1.100146 - Seq Acc: 8.40%
2025-03-25 03:43:59,158 - training_loop - INFO - 
LatentTransformer - Step 9800/200000 - Val Loss: 1.476529 - Seq Acc: 4.90%
2025-03-25 03:44:33,334 - training_loop - INFO - 
SimpleTransformer - Step 9850/200000 - Val Loss: 1.107767 - Seq Acc: 9.00%
2025-03-25 03:44:37,278 - training_loop - INFO - 
LatentTransformer - Step 9850/200000 - Val Loss: 1.509170 - Seq Acc: 4.35%
2025-03-25 03:45:11,434 - training_loop - INFO - 
SimpleTransformer - Step 9900/200000 - Val Loss: 1.108861 - Seq Acc: 8.80%
2025-03-25 03:45:15,545 - training_loop - INFO - 
LatentTransformer - Step 9900/200000 - Val Loss: 1.514097 - Seq Acc: 5.55%
2025-03-25 03:45:50,309 - training_loop - INFO - 
SimpleTransformer - Step 9950/200000 - Val Loss: 1.121354 - Seq Acc: 9.70%
2025-03-25 03:45:55,008 - training_loop - INFO - 
LatentTransformer - Step 9950/200000 - Val Loss: 1.509103 - Seq Acc: 5.05%
2025-03-25 03:46:28,379 - training_loop - INFO - 
SimpleTransformer - Step 10000/200000 - Val Loss: 1.114378 - Seq Acc: 9.15%
2025-03-25 03:46:32,199 - training_loop - INFO - 
LatentTransformer - Step 10000/200000 - Val Loss: 1.495172 - Seq Acc: 4.55%
2025-03-25 03:47:08,142 - training_loop - INFO - 
SimpleTransformer - Step 10050/200000 - Val Loss: 1.118352 - Seq Acc: 8.55%
2025-03-25 03:47:12,201 - training_loop - INFO - 
LatentTransformer - Step 10050/200000 - Val Loss: 1.492886 - Seq Acc: 5.00%
2025-03-25 03:47:46,312 - training_loop - INFO - 
SimpleTransformer - Step 10100/200000 - Val Loss: 1.116482 - Seq Acc: 9.35%
2025-03-25 03:47:50,960 - training_loop - INFO - 
LatentTransformer - Step 10100/200000 - Val Loss: 1.540769 - Seq Acc: 5.10%
2025-03-25 03:48:24,693 - training_loop - INFO - 
SimpleTransformer - Step 10150/200000 - Val Loss: 1.117190 - Seq Acc: 9.90%
2025-03-25 03:48:28,697 - training_loop - INFO - 
LatentTransformer - Step 10150/200000 - Val Loss: 1.518749 - Seq Acc: 5.45%
2025-03-25 03:49:03,522 - training_loop - INFO - 
SimpleTransformer - Step 10200/200000 - Val Loss: 1.120763 - Seq Acc: 8.55%
2025-03-25 03:49:07,302 - training_loop - INFO - 
LatentTransformer - Step 10200/200000 - Val Loss: 1.517855 - Seq Acc: 5.20%
2025-03-25 03:49:41,594 - training_loop - INFO - 
SimpleTransformer - Step 10250/200000 - Val Loss: 1.138679 - Seq Acc: 8.40%
2025-03-25 03:49:45,564 - training_loop - INFO - 
LatentTransformer - Step 10250/200000 - Val Loss: 1.472538 - Seq Acc: 5.05%
2025-03-25 03:50:18,651 - training_loop - INFO - 
SimpleTransformer - Step 10300/200000 - Val Loss: 1.110807 - Seq Acc: 9.10%
2025-03-25 03:50:22,665 - training_loop - INFO - 
LatentTransformer - Step 10300/200000 - Val Loss: 1.532284 - Seq Acc: 5.15%
2025-03-25 03:50:58,667 - training_loop - INFO - 
SimpleTransformer - Step 10350/200000 - Val Loss: 1.129709 - Seq Acc: 8.95%
2025-03-25 03:51:02,574 - training_loop - INFO - 
LatentTransformer - Step 10350/200000 - Val Loss: 1.527306 - Seq Acc: 5.50%
2025-03-25 03:51:35,880 - training_loop - INFO - 
SimpleTransformer - Step 10400/200000 - Val Loss: 1.152275 - Seq Acc: 8.25%
2025-03-25 03:51:39,602 - training_loop - INFO - 
LatentTransformer - Step 10400/200000 - Val Loss: 1.547050 - Seq Acc: 5.35%
2025-03-25 03:52:14,915 - training_loop - INFO - 
SimpleTransformer - Step 10450/200000 - Val Loss: 1.122474 - Seq Acc: 8.80%
2025-03-25 03:52:19,670 - training_loop - INFO - 
LatentTransformer - Step 10450/200000 - Val Loss: 1.505114 - Seq Acc: 5.60%
2025-03-25 03:52:54,917 - training_loop - INFO - 
SimpleTransformer - Step 10500/200000 - Val Loss: 1.087268 - Seq Acc: 8.95%
2025-03-25 03:52:58,850 - training_loop - INFO - 
LatentTransformer - Step 10500/200000 - Val Loss: 1.526082 - Seq Acc: 5.70%
2025-03-25 03:53:36,832 - training_loop - INFO - 
SimpleTransformer - Step 10550/200000 - Val Loss: 1.111551 - Seq Acc: 9.35%
2025-03-25 03:53:40,745 - training_loop - INFO - 
LatentTransformer - Step 10550/200000 - Val Loss: 1.473231 - Seq Acc: 4.90%
2025-03-25 03:54:15,887 - training_loop - INFO - 
SimpleTransformer - Step 10600/200000 - Val Loss: 1.139614 - Seq Acc: 8.75%
2025-03-25 03:54:19,641 - training_loop - INFO - 
LatentTransformer - Step 10600/200000 - Val Loss: 1.529014 - Seq Acc: 5.80%
2025-03-25 03:54:55,749 - training_loop - INFO - 
SimpleTransformer - Step 10650/200000 - Val Loss: 1.113212 - Seq Acc: 9.10%
2025-03-25 03:54:59,637 - training_loop - INFO - 
LatentTransformer - Step 10650/200000 - Val Loss: 1.505359 - Seq Acc: 5.45%
2025-03-25 03:55:33,869 - training_loop - INFO - 
SimpleTransformer - Step 10700/200000 - Val Loss: 1.123830 - Seq Acc: 9.20%
2025-03-25 03:55:37,824 - training_loop - INFO - 
LatentTransformer - Step 10700/200000 - Val Loss: 1.537918 - Seq Acc: 5.15%
2025-03-25 03:56:11,329 - training_loop - INFO - 
SimpleTransformer - Step 10750/200000 - Val Loss: 1.113769 - Seq Acc: 10.00%
2025-03-25 03:56:15,264 - training_loop - INFO - 
LatentTransformer - Step 10750/200000 - Val Loss: 1.537708 - Seq Acc: 5.80%
2025-03-25 03:56:47,940 - training_loop - INFO - 
SimpleTransformer - Step 10800/200000 - Val Loss: 1.145774 - Seq Acc: 8.70%
2025-03-25 03:56:51,392 - training_loop - INFO - 
LatentTransformer - Step 10800/200000 - Val Loss: 1.549243 - Seq Acc: 5.75%
2025-03-25 03:57:25,340 - training_loop - INFO - 
SimpleTransformer - Step 10850/200000 - Val Loss: 1.121776 - Seq Acc: 9.55%
2025-03-25 03:57:29,122 - training_loop - INFO - 
LatentTransformer - Step 10850/200000 - Val Loss: 1.545698 - Seq Acc: 5.55%
2025-03-25 03:58:02,304 - training_loop - INFO - 
SimpleTransformer - Step 10900/200000 - Val Loss: 1.136973 - Seq Acc: 9.00%
2025-03-25 03:58:05,987 - training_loop - INFO - 
LatentTransformer - Step 10900/200000 - Val Loss: 1.587231 - Seq Acc: 5.30%
2025-03-25 10:07:27,222 - __main__ - INFO - Using device: cuda
2025-03-25 10:07:27,223 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 10:07:27,223 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 10:07:27,223 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 10:07:28,509 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 10:07:30,410 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 10:07:30,412 - __main__ - INFO - 
Model Parameters:
2025-03-25 10:07:30,413 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 10:07:30,413 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 10:07:30,413 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 10:07:30,413 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 10:07:30,413 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 10:07:30,414 - training_loop - INFO - Using max_steps from args: 200000
2025-03-25 10:07:30,416 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 10:07:33,059 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 10:07:33,062 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 10:07:33,064 - training_loop - INFO - Starting: Training (steps)
2025-03-25 10:10:13,936 - training_loop - INFO - 
SimpleTransformer - Step 50/200000 - Val Loss: 1.631571 - Seq Acc: 0.40%
2025-03-25 10:10:29,535 - training_loop - INFO - 
LatentTransformer - Step 50/200000 - Val Loss: 1.695729 - Seq Acc: 0.50%
2025-03-25 10:11:02,834 - training_loop - INFO - 
SimpleTransformer - Step 100/200000 - Val Loss: 1.627490 - Seq Acc: 0.50%
2025-03-25 10:11:08,541 - training_loop - INFO - 
LatentTransformer - Step 100/200000 - Val Loss: 1.691682 - Seq Acc: 0.35%
2025-03-25 10:11:41,898 - training_loop - INFO - 
SimpleTransformer - Step 150/200000 - Val Loss: 1.620656 - Seq Acc: 0.50%
2025-03-25 10:11:47,520 - training_loop - INFO - 
LatentTransformer - Step 150/200000 - Val Loss: 1.682232 - Seq Acc: 0.45%
2025-03-25 10:12:20,806 - training_loop - INFO - 
SimpleTransformer - Step 200/200000 - Val Loss: 1.592638 - Seq Acc: 0.50%
2025-03-25 10:12:26,295 - training_loop - INFO - 
LatentTransformer - Step 200/200000 - Val Loss: 1.655265 - Seq Acc: 0.50%
2025-03-25 10:12:59,711 - training_loop - INFO - 
SimpleTransformer - Step 250/200000 - Val Loss: 1.544889 - Seq Acc: 0.50%
2025-03-25 10:13:05,426 - training_loop - INFO - 
LatentTransformer - Step 250/200000 - Val Loss: 1.612326 - Seq Acc: 0.45%
2025-03-25 10:14:30,693 - training_loop - INFO - 
SimpleTransformer - Step 300/200000 - Val Loss: 1.521875 - Seq Acc: 0.55%
2025-03-25 10:14:36,797 - training_loop - INFO - 
LatentTransformer - Step 300/200000 - Val Loss: 1.594925 - Seq Acc: 0.60%
2025-03-25 10:15:10,271 - training_loop - INFO - 
SimpleTransformer - Step 350/200000 - Val Loss: 1.490744 - Seq Acc: 0.40%
2025-03-25 10:15:16,114 - training_loop - INFO - 
LatentTransformer - Step 350/200000 - Val Loss: 1.586507 - Seq Acc: 0.50%
2025-03-25 10:16:24,056 - training_loop - INFO - 
SimpleTransformer - Step 400/200000 - Val Loss: 1.434439 - Seq Acc: 0.65%
2025-03-25 10:16:29,531 - training_loop - INFO - 
LatentTransformer - Step 400/200000 - Val Loss: 1.572871 - Seq Acc: 0.50%
2025-03-25 10:17:02,937 - training_loop - INFO - 
SimpleTransformer - Step 450/200000 - Val Loss: 1.399419 - Seq Acc: 0.75%
2025-03-25 10:17:08,597 - training_loop - INFO - 
LatentTransformer - Step 450/200000 - Val Loss: 1.557639 - Seq Acc: 0.70%
2025-03-25 10:17:42,250 - training_loop - INFO - 
SimpleTransformer - Step 500/200000 - Val Loss: 1.367266 - Seq Acc: 0.95%
2025-03-25 10:17:48,080 - training_loop - INFO - 
LatentTransformer - Step 500/200000 - Val Loss: 1.524564 - Seq Acc: 0.65%
2025-03-25 10:18:21,639 - training_loop - INFO - 
SimpleTransformer - Step 550/200000 - Val Loss: 1.346328 - Seq Acc: 1.10%
2025-03-25 10:18:27,278 - training_loop - INFO - 
LatentTransformer - Step 550/200000 - Val Loss: 1.508131 - Seq Acc: 0.70%
2025-03-25 10:19:00,674 - training_loop - INFO - 
SimpleTransformer - Step 600/200000 - Val Loss: 1.318858 - Seq Acc: 1.00%
2025-03-25 10:19:07,050 - training_loop - INFO - 
LatentTransformer - Step 600/200000 - Val Loss: 1.457904 - Seq Acc: 0.75%
2025-03-25 10:19:40,506 - training_loop - INFO - 
SimpleTransformer - Step 650/200000 - Val Loss: 1.297628 - Seq Acc: 0.95%
2025-03-25 10:19:46,231 - training_loop - INFO - 
LatentTransformer - Step 650/200000 - Val Loss: 1.412272 - Seq Acc: 0.95%
2025-03-25 10:20:19,939 - training_loop - INFO - 
SimpleTransformer - Step 700/200000 - Val Loss: 1.287556 - Seq Acc: 1.05%
2025-03-25 10:20:26,241 - training_loop - INFO - 
LatentTransformer - Step 700/200000 - Val Loss: 1.382761 - Seq Acc: 1.15%
2025-03-25 10:20:57,985 - training_loop - INFO - 
SimpleTransformer - Step 750/200000 - Val Loss: 1.290366 - Seq Acc: 0.85%
2025-03-25 10:21:03,610 - training_loop - INFO - 
LatentTransformer - Step 750/200000 - Val Loss: 1.352014 - Seq Acc: 1.00%
2025-03-25 10:21:37,543 - training_loop - INFO - 
SimpleTransformer - Step 800/200000 - Val Loss: 1.279383 - Seq Acc: 1.00%
2025-03-25 10:21:42,959 - training_loop - INFO - 
LatentTransformer - Step 800/200000 - Val Loss: 1.337170 - Seq Acc: 1.00%
2025-03-25 10:22:16,304 - training_loop - INFO - 
SimpleTransformer - Step 850/200000 - Val Loss: 1.271952 - Seq Acc: 1.00%
2025-03-25 10:22:19,569 - training_loop - INFO - 
LatentTransformer - Step 850/200000 - Val Loss: 1.339091 - Seq Acc: 1.00%
2025-03-25 10:22:53,225 - training_loop - INFO - 
SimpleTransformer - Step 900/200000 - Val Loss: 1.268161 - Seq Acc: 1.20%
2025-03-25 10:22:58,955 - training_loop - INFO - 
LatentTransformer - Step 900/200000 - Val Loss: 1.316389 - Seq Acc: 1.10%
2025-03-25 10:23:33,004 - training_loop - INFO - 
SimpleTransformer - Step 950/200000 - Val Loss: 1.267371 - Seq Acc: 1.15%
2025-03-25 10:23:36,292 - training_loop - INFO - 
LatentTransformer - Step 950/200000 - Val Loss: 1.320560 - Seq Acc: 1.00%
2025-03-25 10:24:09,472 - training_loop - INFO - 
SimpleTransformer - Step 1000/200000 - Val Loss: 1.258248 - Seq Acc: 1.15%
2025-03-25 10:24:14,906 - training_loop - INFO - 
LatentTransformer - Step 1000/200000 - Val Loss: 1.315902 - Seq Acc: 1.00%
2025-03-25 10:24:48,946 - training_loop - INFO - 
SimpleTransformer - Step 1050/200000 - Val Loss: 1.254295 - Seq Acc: 1.10%
2025-03-25 10:24:54,762 - training_loop - INFO - 
LatentTransformer - Step 1050/200000 - Val Loss: 1.315626 - Seq Acc: 0.90%
2025-03-25 10:25:28,173 - training_loop - INFO - 
SimpleTransformer - Step 1100/200000 - Val Loss: 1.247674 - Seq Acc: 1.30%
2025-03-25 10:25:33,803 - training_loop - INFO - 
LatentTransformer - Step 1100/200000 - Val Loss: 1.310971 - Seq Acc: 0.90%
2025-03-25 10:26:07,161 - training_loop - INFO - 
SimpleTransformer - Step 1150/200000 - Val Loss: 1.240275 - Seq Acc: 1.40%
2025-03-25 10:26:12,820 - training_loop - INFO - 
LatentTransformer - Step 1150/200000 - Val Loss: 1.305768 - Seq Acc: 1.20%
2025-03-25 10:26:46,030 - training_loop - INFO - 
SimpleTransformer - Step 1200/200000 - Val Loss: 1.239753 - Seq Acc: 1.00%
2025-03-25 10:26:49,117 - training_loop - INFO - 
LatentTransformer - Step 1200/200000 - Val Loss: 1.306772 - Seq Acc: 1.00%
2025-03-25 10:27:23,708 - training_loop - INFO - 
SimpleTransformer - Step 1250/200000 - Val Loss: 1.234188 - Seq Acc: 1.25%
2025-03-25 10:27:29,414 - training_loop - INFO - 
LatentTransformer - Step 1250/200000 - Val Loss: 1.302469 - Seq Acc: 1.15%
2025-03-25 10:28:02,758 - training_loop - INFO - 
SimpleTransformer - Step 1300/200000 - Val Loss: 1.227262 - Seq Acc: 1.60%
2025-03-25 10:28:06,037 - training_loop - INFO - 
LatentTransformer - Step 1300/200000 - Val Loss: 1.306721 - Seq Acc: 1.15%
2025-03-25 10:28:39,389 - training_loop - INFO - 
SimpleTransformer - Step 1350/200000 - Val Loss: 1.221829 - Seq Acc: 1.85%
2025-03-25 10:28:42,677 - training_loop - INFO - 
LatentTransformer - Step 1350/200000 - Val Loss: 1.305558 - Seq Acc: 1.45%
2025-03-25 10:29:17,693 - training_loop - INFO - 
SimpleTransformer - Step 1400/200000 - Val Loss: 1.209606 - Seq Acc: 1.15%
2025-03-25 10:29:23,254 - training_loop - INFO - 
LatentTransformer - Step 1400/200000 - Val Loss: 1.300269 - Seq Acc: 0.95%
2025-03-25 10:29:59,533 - training_loop - INFO - 
SimpleTransformer - Step 1450/200000 - Val Loss: 1.203639 - Seq Acc: 1.40%
2025-03-25 10:30:02,884 - training_loop - INFO - 
LatentTransformer - Step 1450/200000 - Val Loss: 1.306982 - Seq Acc: 1.10%
2025-03-25 10:30:38,501 - training_loop - INFO - 
SimpleTransformer - Step 1500/200000 - Val Loss: 1.188760 - Seq Acc: 1.60%
2025-03-25 10:30:41,854 - training_loop - INFO - 
LatentTransformer - Step 1500/200000 - Val Loss: 1.300881 - Seq Acc: 1.15%
2025-03-25 10:31:17,530 - training_loop - INFO - 
SimpleTransformer - Step 1550/200000 - Val Loss: 1.176628 - Seq Acc: 1.70%
2025-03-25 10:31:20,887 - training_loop - INFO - 
LatentTransformer - Step 1550/200000 - Val Loss: 1.300347 - Seq Acc: 1.40%
2025-03-25 10:31:55,921 - training_loop - INFO - 
SimpleTransformer - Step 1600/200000 - Val Loss: 1.156434 - Seq Acc: 2.00%
2025-03-25 10:31:59,098 - training_loop - INFO - 
LatentTransformer - Step 1600/200000 - Val Loss: 1.304122 - Seq Acc: 1.10%
2025-03-25 10:32:34,801 - training_loop - INFO - 
SimpleTransformer - Step 1650/200000 - Val Loss: 1.144246 - Seq Acc: 1.90%
2025-03-25 10:32:38,137 - training_loop - INFO - 
LatentTransformer - Step 1650/200000 - Val Loss: 1.302984 - Seq Acc: 1.15%
2025-03-25 10:33:12,131 - training_loop - INFO - 
SimpleTransformer - Step 1700/200000 - Val Loss: 1.145618 - Seq Acc: 2.10%
2025-03-25 10:33:15,527 - training_loop - INFO - 
LatentTransformer - Step 1700/200000 - Val Loss: 1.302082 - Seq Acc: 1.50%
2025-03-25 10:33:50,662 - training_loop - INFO - 
SimpleTransformer - Step 1750/200000 - Val Loss: 1.142857 - Seq Acc: 2.55%
2025-03-25 10:33:54,213 - training_loop - INFO - 
LatentTransformer - Step 1750/200000 - Val Loss: 1.301283 - Seq Acc: 1.20%
2025-03-25 10:34:29,111 - training_loop - INFO - 
SimpleTransformer - Step 1800/200000 - Val Loss: 1.131004 - Seq Acc: 2.40%
2025-03-25 10:34:32,304 - training_loop - INFO - 
LatentTransformer - Step 1800/200000 - Val Loss: 1.301866 - Seq Acc: 1.15%
2025-03-25 10:35:08,095 - training_loop - INFO - 
SimpleTransformer - Step 1850/200000 - Val Loss: 1.122398 - Seq Acc: 2.50%
2025-03-25 10:35:11,556 - training_loop - INFO - 
LatentTransformer - Step 1850/200000 - Val Loss: 1.303762 - Seq Acc: 1.45%
2025-03-25 10:35:46,744 - training_loop - INFO - 
SimpleTransformer - Step 1900/200000 - Val Loss: 1.111974 - Seq Acc: 2.55%
2025-03-25 10:35:52,588 - training_loop - INFO - 
LatentTransformer - Step 1900/200000 - Val Loss: 1.297185 - Seq Acc: 1.55%
2025-03-25 10:36:28,844 - training_loop - INFO - 
SimpleTransformer - Step 1950/200000 - Val Loss: 1.109991 - Seq Acc: 2.70%
2025-03-25 10:36:32,192 - training_loop - INFO - 
LatentTransformer - Step 1950/200000 - Val Loss: 1.299195 - Seq Acc: 1.30%
2025-03-25 10:37:07,757 - training_loop - INFO - 
SimpleTransformer - Step 2000/200000 - Val Loss: 1.099631 - Seq Acc: 2.20%
2025-03-25 10:37:10,899 - training_loop - INFO - 
LatentTransformer - Step 2000/200000 - Val Loss: 1.306383 - Seq Acc: 0.95%
2025-03-25 10:37:46,442 - training_loop - INFO - 
SimpleTransformer - Step 2050/200000 - Val Loss: 1.089056 - Seq Acc: 2.70%
2025-03-25 10:37:49,827 - training_loop - INFO - 
LatentTransformer - Step 2050/200000 - Val Loss: 1.301593 - Seq Acc: 0.90%
2025-03-25 10:38:23,564 - training_loop - INFO - 
SimpleTransformer - Step 2100/200000 - Val Loss: 1.098169 - Seq Acc: 2.70%
2025-03-25 10:38:26,999 - training_loop - INFO - 
LatentTransformer - Step 2100/200000 - Val Loss: 1.300140 - Seq Acc: 1.30%
2025-03-25 10:39:02,747 - training_loop - INFO - 
SimpleTransformer - Step 2150/200000 - Val Loss: 1.079832 - Seq Acc: 3.15%
2025-03-25 10:39:08,559 - training_loop - INFO - 
LatentTransformer - Step 2150/200000 - Val Loss: 1.296594 - Seq Acc: 1.50%
2025-03-25 10:39:43,971 - training_loop - INFO - 
SimpleTransformer - Step 2200/200000 - Val Loss: 1.073844 - Seq Acc: 3.65%
2025-03-25 10:39:47,171 - training_loop - INFO - 
LatentTransformer - Step 2200/200000 - Val Loss: 1.301442 - Seq Acc: 1.00%
2025-03-25 10:40:22,955 - training_loop - INFO - 
SimpleTransformer - Step 2250/200000 - Val Loss: 1.073094 - Seq Acc: 2.80%
2025-03-25 10:40:26,407 - training_loop - INFO - 
LatentTransformer - Step 2250/200000 - Val Loss: 1.304992 - Seq Acc: 0.95%
2025-03-25 10:41:03,256 - training_loop - INFO - 
SimpleTransformer - Step 2300/200000 - Val Loss: 1.072001 - Seq Acc: 3.20%
2025-03-25 10:41:06,663 - training_loop - INFO - 
LatentTransformer - Step 2300/200000 - Val Loss: 1.301955 - Seq Acc: 0.90%
2025-03-25 10:41:42,315 - training_loop - INFO - 
SimpleTransformer - Step 2350/200000 - Val Loss: 1.068303 - Seq Acc: 3.25%
2025-03-25 10:41:45,723 - training_loop - INFO - 
LatentTransformer - Step 2350/200000 - Val Loss: 1.297716 - Seq Acc: 1.25%
2025-03-25 10:42:21,391 - training_loop - INFO - 
SimpleTransformer - Step 2400/200000 - Val Loss: 1.062146 - Seq Acc: 3.25%
2025-03-25 10:42:24,894 - training_loop - INFO - 
LatentTransformer - Step 2400/200000 - Val Loss: 1.300841 - Seq Acc: 1.10%
2025-03-25 10:43:00,675 - training_loop - INFO - 
SimpleTransformer - Step 2450/200000 - Val Loss: 1.061124 - Seq Acc: 2.90%
2025-03-25 10:43:06,432 - training_loop - INFO - 
LatentTransformer - Step 2450/200000 - Val Loss: 1.296090 - Seq Acc: 1.20%
2025-03-25 10:43:42,852 - training_loop - INFO - 
SimpleTransformer - Step 2500/200000 - Val Loss: 1.060595 - Seq Acc: 2.70%
2025-03-25 10:43:46,231 - training_loop - INFO - 
LatentTransformer - Step 2500/200000 - Val Loss: 1.296335 - Seq Acc: 1.30%
2025-03-25 10:44:21,235 - training_loop - INFO - 
SimpleTransformer - Step 2550/200000 - Val Loss: 1.058191 - Seq Acc: 3.05%
2025-03-25 10:44:27,060 - training_loop - INFO - 
LatentTransformer - Step 2550/200000 - Val Loss: 1.291343 - Seq Acc: 1.10%
2025-03-25 10:44:59,642 - training_loop - INFO - 
SimpleTransformer - Step 2600/200000 - Val Loss: 1.070097 - Seq Acc: 3.30%
2025-03-25 10:45:02,769 - training_loop - INFO - 
LatentTransformer - Step 2600/200000 - Val Loss: 1.294133 - Seq Acc: 0.70%
2025-03-25 10:45:39,028 - training_loop - INFO - 
SimpleTransformer - Step 2650/200000 - Val Loss: 1.054569 - Seq Acc: 3.00%
2025-03-25 10:45:44,715 - training_loop - INFO - 
LatentTransformer - Step 2650/200000 - Val Loss: 1.291010 - Seq Acc: 0.90%
2025-03-25 10:46:21,047 - training_loop - INFO - 
SimpleTransformer - Step 2700/200000 - Val Loss: 1.047635 - Seq Acc: 3.20%
2025-03-25 10:46:24,609 - training_loop - INFO - 
LatentTransformer - Step 2700/200000 - Val Loss: 1.291328 - Seq Acc: 1.40%
2025-03-25 10:46:57,450 - training_loop - INFO - 
SimpleTransformer - Step 2750/200000 - Val Loss: 1.050346 - Seq Acc: 3.80%
2025-03-25 10:47:03,187 - training_loop - INFO - 
LatentTransformer - Step 2750/200000 - Val Loss: 1.285370 - Seq Acc: 1.50%
2025-03-25 10:47:38,639 - training_loop - INFO - 
SimpleTransformer - Step 2800/200000 - Val Loss: 1.042276 - Seq Acc: 3.70%
2025-03-25 10:47:41,785 - training_loop - INFO - 
LatentTransformer - Step 2800/200000 - Val Loss: 1.300463 - Seq Acc: 0.95%
2025-03-25 10:48:15,206 - training_loop - INFO - 
SimpleTransformer - Step 2850/200000 - Val Loss: 1.051467 - Seq Acc: 3.85%
2025-03-25 10:48:20,928 - training_loop - INFO - 
LatentTransformer - Step 2850/200000 - Val Loss: 1.284743 - Seq Acc: 0.95%
2025-03-25 10:48:53,996 - training_loop - INFO - 
SimpleTransformer - Step 2900/200000 - Val Loss: 1.045624 - Seq Acc: 3.20%
2025-03-25 10:48:59,798 - training_loop - INFO - 
LatentTransformer - Step 2900/200000 - Val Loss: 1.276262 - Seq Acc: 1.20%
2025-03-25 10:49:34,894 - training_loop - INFO - 
SimpleTransformer - Step 2950/200000 - Val Loss: 1.041858 - Seq Acc: 3.20%
2025-03-25 10:49:40,590 - training_loop - INFO - 
LatentTransformer - Step 2950/200000 - Val Loss: 1.269472 - Seq Acc: 1.25%
2025-03-25 10:50:17,391 - training_loop - INFO - 
SimpleTransformer - Step 3000/200000 - Val Loss: 1.033191 - Seq Acc: 3.45%
2025-03-25 10:50:20,510 - training_loop - INFO - 
LatentTransformer - Step 3000/200000 - Val Loss: 1.278092 - Seq Acc: 1.35%
2025-03-25 10:50:53,410 - training_loop - INFO - 
SimpleTransformer - Step 3050/200000 - Val Loss: 1.039076 - Seq Acc: 3.55%
2025-03-25 10:50:59,075 - training_loop - INFO - 
LatentTransformer - Step 3050/200000 - Val Loss: 1.261259 - Seq Acc: 1.15%
2025-03-25 10:51:33,084 - training_loop - INFO - 
SimpleTransformer - Step 3100/200000 - Val Loss: 1.038737 - Seq Acc: 3.65%
2025-03-25 10:51:38,754 - training_loop - INFO - 
LatentTransformer - Step 3100/200000 - Val Loss: 1.253293 - Seq Acc: 1.25%
2025-03-25 10:52:15,075 - training_loop - INFO - 
SimpleTransformer - Step 3150/200000 - Val Loss: 1.028145 - Seq Acc: 3.70%
2025-03-25 10:52:18,477 - training_loop - INFO - 
LatentTransformer - Step 3150/200000 - Val Loss: 1.268714 - Seq Acc: 1.25%
2025-03-25 10:52:53,541 - training_loop - INFO - 
SimpleTransformer - Step 3200/200000 - Val Loss: 1.027951 - Seq Acc: 3.80%
2025-03-25 10:52:59,172 - training_loop - INFO - 
LatentTransformer - Step 3200/200000 - Val Loss: 1.246943 - Seq Acc: 1.60%
2025-03-25 10:53:32,160 - training_loop - INFO - 
SimpleTransformer - Step 3250/200000 - Val Loss: 1.030880 - Seq Acc: 3.80%
2025-03-25 10:53:38,619 - training_loop - INFO - 
LatentTransformer - Step 3250/200000 - Val Loss: 1.234184 - Seq Acc: 1.45%
2025-03-25 10:54:15,704 - training_loop - INFO - 
SimpleTransformer - Step 3300/200000 - Val Loss: 1.022288 - Seq Acc: 3.65%
2025-03-25 10:54:21,565 - training_loop - INFO - 
LatentTransformer - Step 3300/200000 - Val Loss: 1.221230 - Seq Acc: 1.50%
2025-03-25 10:54:54,659 - training_loop - INFO - 
SimpleTransformer - Step 3350/200000 - Val Loss: 1.032214 - Seq Acc: 3.25%
2025-03-25 10:55:00,427 - training_loop - INFO - 
LatentTransformer - Step 3350/200000 - Val Loss: 1.216530 - Seq Acc: 1.65%
2025-03-25 10:55:35,522 - training_loop - INFO - 
SimpleTransformer - Step 3400/200000 - Val Loss: 1.022170 - Seq Acc: 3.45%
2025-03-25 10:55:41,130 - training_loop - INFO - 
LatentTransformer - Step 3400/200000 - Val Loss: 1.205233 - Seq Acc: 1.80%
2025-03-25 10:56:16,858 - training_loop - INFO - 
SimpleTransformer - Step 3450/200000 - Val Loss: 1.018085 - Seq Acc: 3.75%
2025-03-25 10:56:22,767 - training_loop - INFO - 
LatentTransformer - Step 3450/200000 - Val Loss: 1.200484 - Seq Acc: 1.50%
2025-03-25 10:57:00,065 - training_loop - INFO - 
SimpleTransformer - Step 3500/200000 - Val Loss: 1.013261 - Seq Acc: 4.20%
2025-03-25 10:57:05,856 - training_loop - INFO - 
LatentTransformer - Step 3500/200000 - Val Loss: 1.185692 - Seq Acc: 1.65%
2025-03-25 10:57:39,393 - training_loop - INFO - 
SimpleTransformer - Step 3550/200000 - Val Loss: 1.014476 - Seq Acc: 3.70%
2025-03-25 10:57:45,215 - training_loop - INFO - 
LatentTransformer - Step 3550/200000 - Val Loss: 1.171887 - Seq Acc: 2.10%
2025-03-25 10:58:21,503 - training_loop - INFO - 
SimpleTransformer - Step 3600/200000 - Val Loss: 1.010421 - Seq Acc: 3.65%
2025-03-25 10:58:27,351 - training_loop - INFO - 
LatentTransformer - Step 3600/200000 - Val Loss: 1.156854 - Seq Acc: 1.80%
2025-03-25 10:59:01,486 - training_loop - INFO - 
SimpleTransformer - Step 3650/200000 - Val Loss: 1.014960 - Seq Acc: 3.35%
2025-03-25 10:59:07,315 - training_loop - INFO - 
LatentTransformer - Step 3650/200000 - Val Loss: 1.142214 - Seq Acc: 1.70%
2025-03-25 10:59:40,219 - training_loop - INFO - 
SimpleTransformer - Step 3700/200000 - Val Loss: 1.013438 - Seq Acc: 3.55%
2025-03-25 10:59:46,122 - training_loop - INFO - 
LatentTransformer - Step 3700/200000 - Val Loss: 1.131174 - Seq Acc: 2.05%
2025-03-25 11:00:22,567 - training_loop - INFO - 
SimpleTransformer - Step 3750/200000 - Val Loss: 1.007157 - Seq Acc: 3.55%
2025-03-25 11:00:28,574 - training_loop - INFO - 
LatentTransformer - Step 3750/200000 - Val Loss: 1.125178 - Seq Acc: 2.20%
2025-03-25 11:01:04,809 - training_loop - INFO - 
SimpleTransformer - Step 3800/200000 - Val Loss: 1.001430 - Seq Acc: 4.15%
2025-03-25 11:01:10,382 - training_loop - INFO - 
LatentTransformer - Step 3800/200000 - Val Loss: 1.122888 - Seq Acc: 1.95%
2025-03-25 11:01:43,994 - training_loop - INFO - 
SimpleTransformer - Step 3850/200000 - Val Loss: 1.011354 - Seq Acc: 3.90%
2025-03-25 11:01:49,917 - training_loop - INFO - 
LatentTransformer - Step 3850/200000 - Val Loss: 1.116023 - Seq Acc: 2.30%
2025-03-25 11:02:27,108 - training_loop - INFO - 
SimpleTransformer - Step 3900/200000 - Val Loss: 1.000957 - Seq Acc: 3.35%
2025-03-25 11:02:34,173 - training_loop - INFO - 
LatentTransformer - Step 3900/200000 - Val Loss: 1.106050 - Seq Acc: 2.40%
2025-03-25 11:03:09,829 - training_loop - INFO - 
SimpleTransformer - Step 3950/200000 - Val Loss: 0.996456 - Seq Acc: 3.40%
2025-03-25 11:03:15,611 - training_loop - INFO - 
LatentTransformer - Step 3950/200000 - Val Loss: 1.101043 - Seq Acc: 2.50%
2025-03-25 11:03:49,118 - training_loop - INFO - 
SimpleTransformer - Step 4000/200000 - Val Loss: 0.998537 - Seq Acc: 3.50%
2025-03-25 11:03:52,476 - training_loop - INFO - 
LatentTransformer - Step 4000/200000 - Val Loss: 1.103563 - Seq Acc: 2.35%
2025-03-25 11:04:30,960 - training_loop - INFO - 
SimpleTransformer - Step 4050/200000 - Val Loss: 0.996284 - Seq Acc: 3.65%
2025-03-25 11:04:34,476 - training_loop - INFO - 
LatentTransformer - Step 4050/200000 - Val Loss: 1.112731 - Seq Acc: 2.60%
2025-03-25 11:05:12,819 - training_loop - INFO - 
SimpleTransformer - Step 4100/200000 - Val Loss: 0.992224 - Seq Acc: 3.70%
2025-03-25 11:05:18,621 - training_loop - INFO - 
LatentTransformer - Step 4100/200000 - Val Loss: 1.098600 - Seq Acc: 2.85%
2025-03-25 11:05:54,515 - training_loop - INFO - 
SimpleTransformer - Step 4150/200000 - Val Loss: 0.977539 - Seq Acc: 4.15%
2025-03-25 11:06:00,359 - training_loop - INFO - 
LatentTransformer - Step 4150/200000 - Val Loss: 1.090950 - Seq Acc: 3.10%
2025-03-25 11:06:37,927 - training_loop - INFO - 
SimpleTransformer - Step 4200/200000 - Val Loss: 0.976951 - Seq Acc: 4.05%
2025-03-25 11:06:41,206 - training_loop - INFO - 
LatentTransformer - Step 4200/200000 - Val Loss: 1.123208 - Seq Acc: 2.70%
2025-03-25 11:07:14,699 - training_loop - INFO - 
SimpleTransformer - Step 4250/200000 - Val Loss: 0.998561 - Seq Acc: 3.85%
2025-03-25 11:07:18,231 - training_loop - INFO - 
LatentTransformer - Step 4250/200000 - Val Loss: 1.097034 - Seq Acc: 2.85%
2025-03-25 11:07:53,116 - training_loop - INFO - 
SimpleTransformer - Step 4300/200000 - Val Loss: 0.990162 - Seq Acc: 4.10%
2025-03-25 11:07:56,715 - training_loop - INFO - 
LatentTransformer - Step 4300/200000 - Val Loss: 1.096020 - Seq Acc: 3.05%
2025-03-25 11:08:30,364 - training_loop - INFO - 
SimpleTransformer - Step 4350/200000 - Val Loss: 0.980212 - Seq Acc: 3.95%
2025-03-25 11:08:33,826 - training_loop - INFO - 
LatentTransformer - Step 4350/200000 - Val Loss: 1.096178 - Seq Acc: 3.20%
2025-03-25 11:09:05,773 - training_loop - INFO - 
SimpleTransformer - Step 4400/200000 - Val Loss: 0.977904 - Seq Acc: 4.25%
2025-03-25 11:09:08,998 - training_loop - INFO - 
LatentTransformer - Step 4400/200000 - Val Loss: 1.103369 - Seq Acc: 2.75%
2025-03-25 11:09:41,289 - training_loop - INFO - 
SimpleTransformer - Step 4450/200000 - Val Loss: 0.983653 - Seq Acc: 4.20%
2025-03-25 11:09:44,670 - training_loop - INFO - 
LatentTransformer - Step 4450/200000 - Val Loss: 1.098493 - Seq Acc: 3.10%
2025-03-25 11:10:15,606 - training_loop - INFO - 
SimpleTransformer - Step 4500/200000 - Val Loss: 0.977624 - Seq Acc: 4.35%
2025-03-25 11:10:18,975 - training_loop - INFO - 
LatentTransformer - Step 4500/200000 - Val Loss: 1.099835 - Seq Acc: 2.80%
2025-03-25 11:10:52,804 - training_loop - INFO - 
SimpleTransformer - Step 4550/200000 - Val Loss: 0.962355 - Seq Acc: 4.75%
2025-03-25 11:10:56,275 - training_loop - INFO - 
LatentTransformer - Step 4550/200000 - Val Loss: 1.101945 - Seq Acc: 2.75%
2025-03-25 11:11:29,217 - training_loop - INFO - 
SimpleTransformer - Step 4600/200000 - Val Loss: 0.968900 - Seq Acc: 4.40%
2025-03-25 11:11:32,585 - training_loop - INFO - 
LatentTransformer - Step 4600/200000 - Val Loss: 1.122045 - Seq Acc: 3.10%
2025-03-25 11:12:05,900 - training_loop - INFO - 
SimpleTransformer - Step 4650/200000 - Val Loss: 0.964916 - Seq Acc: 4.65%
2025-03-25 11:12:09,785 - training_loop - INFO - 
LatentTransformer - Step 4650/200000 - Val Loss: 1.104007 - Seq Acc: 3.15%
2025-03-25 11:12:43,772 - training_loop - INFO - 
SimpleTransformer - Step 4700/200000 - Val Loss: 0.966112 - Seq Acc: 4.65%
2025-03-25 11:12:47,499 - training_loop - INFO - 
LatentTransformer - Step 4700/200000 - Val Loss: 1.105471 - Seq Acc: 2.65%
2025-03-25 11:13:21,546 - training_loop - INFO - 
SimpleTransformer - Step 4750/200000 - Val Loss: 0.967641 - Seq Acc: 3.95%
2025-03-25 11:13:25,298 - training_loop - INFO - 
LatentTransformer - Step 4750/200000 - Val Loss: 1.115126 - Seq Acc: 2.65%
2025-03-25 11:14:00,115 - training_loop - INFO - 
SimpleTransformer - Step 4800/200000 - Val Loss: 0.962345 - Seq Acc: 4.10%
2025-03-25 11:14:03,523 - training_loop - INFO - 
LatentTransformer - Step 4800/200000 - Val Loss: 1.111079 - Seq Acc: 2.70%
2025-03-25 11:14:40,010 - training_loop - INFO - 
SimpleTransformer - Step 4850/200000 - Val Loss: 0.971805 - Seq Acc: 4.55%
2025-03-25 11:14:43,559 - training_loop - INFO - 
LatentTransformer - Step 4850/200000 - Val Loss: 1.112369 - Seq Acc: 2.70%
2025-03-25 11:15:17,917 - training_loop - INFO - 
SimpleTransformer - Step 4900/200000 - Val Loss: 0.975334 - Seq Acc: 4.75%
2025-03-25 11:15:21,531 - training_loop - INFO - 
LatentTransformer - Step 4900/200000 - Val Loss: 1.107178 - Seq Acc: 3.25%
2025-03-25 11:15:57,015 - training_loop - INFO - 
SimpleTransformer - Step 4950/200000 - Val Loss: 0.979476 - Seq Acc: 4.30%
2025-03-25 11:16:00,733 - training_loop - INFO - 
LatentTransformer - Step 4950/200000 - Val Loss: 1.109660 - Seq Acc: 3.00%
2025-03-25 11:16:36,462 - training_loop - INFO - 
SimpleTransformer - Step 5000/200000 - Val Loss: 0.955715 - Seq Acc: 4.40%
2025-03-25 11:16:39,740 - training_loop - INFO - 
LatentTransformer - Step 5000/200000 - Val Loss: 1.125987 - Seq Acc: 3.35%
2025-03-25 11:17:15,567 - training_loop - INFO - 
SimpleTransformer - Step 5050/200000 - Val Loss: 0.953794 - Seq Acc: 4.50%
2025-03-25 11:17:19,060 - training_loop - INFO - 
LatentTransformer - Step 5050/200000 - Val Loss: 1.115158 - Seq Acc: 2.50%
2025-03-25 11:17:52,264 - training_loop - INFO - 
SimpleTransformer - Step 5100/200000 - Val Loss: 0.955424 - Seq Acc: 5.20%
2025-03-25 11:17:56,339 - training_loop - INFO - 
LatentTransformer - Step 5100/200000 - Val Loss: 1.123692 - Seq Acc: 2.80%
2025-03-25 11:18:31,418 - training_loop - INFO - 
SimpleTransformer - Step 5150/200000 - Val Loss: 0.955948 - Seq Acc: 4.65%
2025-03-25 11:18:34,879 - training_loop - INFO - 
LatentTransformer - Step 5150/200000 - Val Loss: 1.121109 - Seq Acc: 3.05%
2025-03-25 11:19:12,170 - training_loop - INFO - 
SimpleTransformer - Step 5200/200000 - Val Loss: 0.953669 - Seq Acc: 4.55%
2025-03-25 11:19:15,484 - training_loop - INFO - 
LatentTransformer - Step 5200/200000 - Val Loss: 1.121810 - Seq Acc: 3.30%
2025-03-25 11:19:50,616 - training_loop - INFO - 
SimpleTransformer - Step 5250/200000 - Val Loss: 0.951747 - Seq Acc: 4.70%
2025-03-25 11:19:54,376 - training_loop - INFO - 
LatentTransformer - Step 5250/200000 - Val Loss: 1.127237 - Seq Acc: 3.20%
2025-03-25 11:20:29,616 - training_loop - INFO - 
SimpleTransformer - Step 5300/200000 - Val Loss: 0.961490 - Seq Acc: 5.50%
2025-03-25 11:20:33,239 - training_loop - INFO - 
LatentTransformer - Step 5300/200000 - Val Loss: 1.124113 - Seq Acc: 2.95%
2025-03-25 11:21:08,523 - training_loop - INFO - 
SimpleTransformer - Step 5350/200000 - Val Loss: 0.974654 - Seq Acc: 5.20%
2025-03-25 11:21:12,159 - training_loop - INFO - 
LatentTransformer - Step 5350/200000 - Val Loss: 1.125577 - Seq Acc: 2.80%
2025-03-25 11:21:50,852 - training_loop - INFO - 
SimpleTransformer - Step 5400/200000 - Val Loss: 0.946169 - Seq Acc: 5.10%
2025-03-25 11:21:54,368 - training_loop - INFO - 
LatentTransformer - Step 5400/200000 - Val Loss: 1.137927 - Seq Acc: 2.75%
2025-03-25 11:22:28,347 - training_loop - INFO - 
SimpleTransformer - Step 5450/200000 - Val Loss: 0.948434 - Seq Acc: 5.05%
2025-03-25 11:22:32,015 - training_loop - INFO - 
LatentTransformer - Step 5450/200000 - Val Loss: 1.143061 - Seq Acc: 3.15%
2025-03-25 11:23:05,464 - training_loop - INFO - 
SimpleTransformer - Step 5500/200000 - Val Loss: 0.960808 - Seq Acc: 5.50%
2025-03-25 11:23:09,123 - training_loop - INFO - 
LatentTransformer - Step 5500/200000 - Val Loss: 1.132633 - Seq Acc: 2.85%
2025-03-25 11:23:17,199 - __main__ - INFO - Using device: cuda
2025-03-25 11:23:17,200 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 11:23:17,200 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 11:23:17,200 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 11:23:18,748 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 11:23:43,407 - training_loop - INFO - 
SimpleTransformer - Step 5550/200000 - Val Loss: 0.958788 - Seq Acc: 5.00%
2025-03-25 11:23:46,840 - training_loop - INFO - 
LatentTransformer - Step 5550/200000 - Val Loss: 1.139671 - Seq Acc: 3.00%
2025-03-25 11:24:23,825 - training_loop - INFO - 
SimpleTransformer - Step 5600/200000 - Val Loss: 0.934285 - Seq Acc: 5.00%
2025-03-25 11:24:24,931 - __main__ - INFO - Using device: cuda
2025-03-25 11:24:24,931 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 11:24:24,931 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 11:24:24,931 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 11:24:26,641 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 11:24:27,597 - training_loop - INFO - 
LatentTransformer - Step 5600/200000 - Val Loss: 1.161402 - Seq Acc: 3.35%
2025-03-25 11:24:28,769 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 11:24:28,771 - __main__ - INFO - 
Model Parameters:
2025-03-25 11:24:28,772 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 11:24:28,772 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 11:24:28,772 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 11:24:28,772 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 11:24:28,772 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 11:24:28,772 - training_loop - INFO - Using max_steps from args: 20000
2025-03-25 11:24:28,775 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 11:24:31,240 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 11:24:31,256 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 11:24:31,259 - training_loop - INFO - Starting: Training (steps)
2025-03-25 11:28:08,103 - training_loop - INFO - 
SimpleTransformer - Step 5650/200000 - Val Loss: 0.959802 - Seq Acc: 4.50%
2025-03-25 11:28:13,695 - training_loop - INFO - 
LatentTransformer - Step 5650/200000 - Val Loss: 1.155717 - Seq Acc: 3.50%
2025-03-25 11:29:37,508 - training_loop - INFO - 
SimpleTransformer - Step 5700/200000 - Val Loss: 0.974194 - Seq Acc: 5.35%
2025-03-25 11:29:42,919 - training_loop - INFO - 
LatentTransformer - Step 5700/200000 - Val Loss: 1.153980 - Seq Acc: 3.55%
2025-03-25 11:30:26,340 - training_loop - INFO - 
SimpleTransformer - Step 5750/200000 - Val Loss: 0.954028 - Seq Acc: 5.35%
2025-03-25 11:30:29,865 - training_loop - INFO - 
LatentTransformer - Step 5750/200000 - Val Loss: 1.158395 - Seq Acc: 2.65%
2025-03-25 11:31:12,792 - training_loop - INFO - 
SimpleTransformer - Step 50/20000 - Val Loss: 1.633290 - Seq Acc: 0.50%
2025-03-25 11:31:38,093 - training_loop - INFO - 
LatentTransformer - Step 50/20000 - Val Loss: 1.695350 - Seq Acc: 0.55%
2025-03-25 11:32:04,908 - training_loop - INFO - 
SimpleTransformer - Step 5800/200000 - Val Loss: 0.938590 - Seq Acc: 5.40%
2025-03-25 11:32:14,224 - training_loop - INFO - 
LatentTransformer - Step 5800/200000 - Val Loss: 1.158862 - Seq Acc: 3.05%
2025-03-25 11:32:57,928 - training_loop - ERROR - Error in training step for SimpleTransformer: [Errno 32] Broken pipe
2025-03-25 11:33:00,049 - training_loop - ERROR - Error in training step for LatentTransformer: [Errno 32] Broken pipe
2025-03-25 11:34:31,958 - __main__ - INFO - Using device: cuda
2025-03-25 11:34:31,958 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 11:34:31,958 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 11:34:31,958 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 11:34:33,326 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 11:34:35,170 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 11:34:35,173 - __main__ - INFO - 
Model Parameters:
2025-03-25 11:34:35,173 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 11:34:35,174 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 11:34:35,174 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 11:34:35,174 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 11:34:35,174 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 11:34:35,174 - training_loop - INFO - Using max_steps from args: 20000
2025-03-25 11:34:35,176 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 11:34:37,325 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 11:34:37,327 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 11:34:37,329 - training_loop - INFO - Starting: Training (steps)
2025-03-25 11:35:58,859 - training_loop - INFO - 
SimpleTransformer - Step 50/20000 - Val Loss: 1.633290 - Seq Acc: 0.50%
2025-03-25 11:36:11,873 - training_loop - INFO - 
LatentTransformer - Step 50/20000 - Val Loss: 1.695350 - Seq Acc: 0.55%
2025-03-25 11:36:51,653 - training_loop - INFO - 
SimpleTransformer - Step 100/20000 - Val Loss: 1.628858 - Seq Acc: 0.45%
2025-03-25 11:36:57,415 - training_loop - INFO - 
LatentTransformer - Step 100/20000 - Val Loss: 1.691220 - Seq Acc: 0.50%
2025-03-25 11:37:31,186 - training_loop - INFO - 
SimpleTransformer - Step 150/20000 - Val Loss: 1.624284 - Seq Acc: 0.40%
2025-03-25 11:37:37,002 - training_loop - INFO - 
LatentTransformer - Step 150/20000 - Val Loss: 1.687405 - Seq Acc: 0.45%
2025-03-25 11:38:10,616 - training_loop - INFO - 
SimpleTransformer - Step 200/20000 - Val Loss: 1.610929 - Seq Acc: 0.60%
2025-03-25 11:38:16,216 - training_loop - INFO - 
LatentTransformer - Step 200/20000 - Val Loss: 1.682114 - Seq Acc: 0.60%
2025-03-25 11:38:49,984 - training_loop - INFO - 
SimpleTransformer - Step 250/20000 - Val Loss: 1.589560 - Seq Acc: 0.55%
2025-03-25 11:38:55,891 - training_loop - INFO - 
LatentTransformer - Step 250/20000 - Val Loss: 1.638566 - Seq Acc: 0.45%
2025-03-25 11:40:08,767 - training_loop - INFO - 
SimpleTransformer - Step 300/20000 - Val Loss: 1.539892 - Seq Acc: 0.60%
2025-03-25 11:40:14,534 - training_loop - INFO - 
LatentTransformer - Step 300/20000 - Val Loss: 1.610137 - Seq Acc: 0.50%
2025-03-25 11:40:48,926 - training_loop - INFO - 
SimpleTransformer - Step 350/20000 - Val Loss: 1.522262 - Seq Acc: 0.40%
2025-03-25 11:40:54,632 - training_loop - INFO - 
LatentTransformer - Step 350/20000 - Val Loss: 1.600560 - Seq Acc: 0.50%
2025-03-25 11:42:06,281 - training_loop - INFO - 
SimpleTransformer - Step 400/20000 - Val Loss: 1.512116 - Seq Acc: 0.55%
2025-03-25 11:42:09,500 - training_loop - INFO - 
LatentTransformer - Step 400/20000 - Val Loss: 1.605968 - Seq Acc: 0.50%
2025-03-25 11:42:44,249 - training_loop - INFO - 
SimpleTransformer - Step 450/20000 - Val Loss: 1.465005 - Seq Acc: 0.65%
2025-03-25 11:42:50,150 - training_loop - INFO - 
LatentTransformer - Step 450/20000 - Val Loss: 1.556049 - Seq Acc: 0.65%
2025-03-25 11:43:26,040 - training_loop - INFO - 
SimpleTransformer - Step 500/20000 - Val Loss: 1.419175 - Seq Acc: 0.85%
2025-03-25 11:43:31,816 - training_loop - INFO - 
LatentTransformer - Step 500/20000 - Val Loss: 1.527693 - Seq Acc: 0.75%
2025-03-25 11:44:06,618 - training_loop - INFO - 
SimpleTransformer - Step 550/20000 - Val Loss: 1.387289 - Seq Acc: 1.05%
2025-03-25 11:44:12,447 - training_loop - INFO - 
LatentTransformer - Step 550/20000 - Val Loss: 1.495828 - Seq Acc: 0.70%
2025-03-25 11:44:47,290 - training_loop - INFO - 
SimpleTransformer - Step 600/20000 - Val Loss: 1.360334 - Seq Acc: 1.00%
2025-03-25 11:44:52,999 - training_loop - INFO - 
LatentTransformer - Step 600/20000 - Val Loss: 1.447204 - Seq Acc: 0.75%
2025-03-25 11:45:27,121 - training_loop - INFO - 
SimpleTransformer - Step 650/20000 - Val Loss: 1.337109 - Seq Acc: 0.70%
2025-03-25 11:45:32,794 - training_loop - INFO - 
LatentTransformer - Step 650/20000 - Val Loss: 1.388575 - Seq Acc: 0.80%
2025-03-25 11:46:07,432 - training_loop - INFO - 
SimpleTransformer - Step 700/20000 - Val Loss: 1.312420 - Seq Acc: 1.25%
2025-03-25 11:46:13,208 - training_loop - INFO - 
LatentTransformer - Step 700/20000 - Val Loss: 1.355750 - Seq Acc: 0.95%
2025-03-25 11:46:49,954 - training_loop - INFO - 
SimpleTransformer - Step 750/20000 - Val Loss: 1.295882 - Seq Acc: 0.90%
2025-03-25 11:46:55,732 - training_loop - INFO - 
LatentTransformer - Step 750/20000 - Val Loss: 1.348483 - Seq Acc: 0.85%
2025-03-25 11:47:30,930 - training_loop - INFO - 
SimpleTransformer - Step 800/20000 - Val Loss: 1.289197 - Seq Acc: 0.85%
2025-03-25 11:47:36,337 - training_loop - INFO - 
LatentTransformer - Step 800/20000 - Val Loss: 1.343077 - Seq Acc: 1.05%
2025-03-25 11:48:12,403 - training_loop - INFO - 
SimpleTransformer - Step 850/20000 - Val Loss: 1.277510 - Seq Acc: 1.20%
2025-03-25 11:48:16,466 - training_loop - INFO - 
LatentTransformer - Step 850/20000 - Val Loss: 1.350090 - Seq Acc: 0.80%
2025-03-25 11:48:52,579 - training_loop - INFO - 
SimpleTransformer - Step 900/20000 - Val Loss: 1.274843 - Seq Acc: 1.25%
2025-03-25 11:48:59,055 - training_loop - INFO - 
LatentTransformer - Step 900/20000 - Val Loss: 1.324441 - Seq Acc: 1.05%
2025-03-25 11:49:34,274 - training_loop - INFO - 
SimpleTransformer - Step 950/20000 - Val Loss: 1.273770 - Seq Acc: 1.15%
2025-03-25 11:49:37,716 - training_loop - INFO - 
LatentTransformer - Step 950/20000 - Val Loss: 1.326543 - Seq Acc: 0.95%
2025-03-25 11:50:13,330 - training_loop - INFO - 
SimpleTransformer - Step 1000/20000 - Val Loss: 1.268606 - Seq Acc: 1.15%
2025-03-25 11:50:16,463 - training_loop - INFO - 
LatentTransformer - Step 1000/20000 - Val Loss: 1.333104 - Seq Acc: 0.95%
2025-03-25 11:50:51,162 - training_loop - INFO - 
SimpleTransformer - Step 1050/20000 - Val Loss: 1.273461 - Seq Acc: 1.00%
2025-03-25 11:50:54,708 - training_loop - INFO - 
LatentTransformer - Step 1050/20000 - Val Loss: 1.334596 - Seq Acc: 0.90%
2025-03-25 11:51:31,616 - training_loop - INFO - 
SimpleTransformer - Step 1100/20000 - Val Loss: 1.263109 - Seq Acc: 1.60%
2025-03-25 11:51:37,365 - training_loop - INFO - 
LatentTransformer - Step 1100/20000 - Val Loss: 1.318537 - Seq Acc: 0.95%
2025-03-25 11:52:14,590 - training_loop - INFO - 
SimpleTransformer - Step 1150/20000 - Val Loss: 1.255082 - Seq Acc: 1.20%
2025-03-25 11:52:17,949 - training_loop - INFO - 
LatentTransformer - Step 1150/20000 - Val Loss: 1.325268 - Seq Acc: 0.70%
2025-03-25 11:52:54,464 - training_loop - INFO - 
SimpleTransformer - Step 1200/20000 - Val Loss: 1.254128 - Seq Acc: 1.15%
2025-03-25 11:52:57,755 - training_loop - INFO - 
LatentTransformer - Step 1200/20000 - Val Loss: 1.328062 - Seq Acc: 1.10%
2025-03-25 11:53:34,591 - training_loop - INFO - 
SimpleTransformer - Step 1250/20000 - Val Loss: 1.260652 - Seq Acc: 1.00%
2025-03-25 11:53:37,953 - training_loop - INFO - 
LatentTransformer - Step 1250/20000 - Val Loss: 1.328782 - Seq Acc: 0.90%
2025-03-25 11:54:13,986 - training_loop - INFO - 
SimpleTransformer - Step 1300/20000 - Val Loss: 1.232355 - Seq Acc: 1.20%
2025-03-25 11:54:19,625 - training_loop - INFO - 
LatentTransformer - Step 1300/20000 - Val Loss: 1.312892 - Seq Acc: 1.05%
2025-03-25 11:54:56,169 - training_loop - INFO - 
SimpleTransformer - Step 1350/20000 - Val Loss: 1.230206 - Seq Acc: 1.30%
2025-03-25 11:54:59,551 - training_loop - INFO - 
LatentTransformer - Step 1350/20000 - Val Loss: 1.317553 - Seq Acc: 1.00%
2025-03-25 11:55:37,354 - training_loop - INFO - 
SimpleTransformer - Step 1400/20000 - Val Loss: 1.212019 - Seq Acc: 1.50%
2025-03-25 11:55:40,617 - training_loop - INFO - 
LatentTransformer - Step 1400/20000 - Val Loss: 1.327395 - Seq Acc: 0.75%
2025-03-25 11:56:16,748 - training_loop - INFO - 
SimpleTransformer - Step 1450/20000 - Val Loss: 1.252517 - Seq Acc: 1.35%
2025-03-25 11:56:22,439 - training_loop - INFO - 
LatentTransformer - Step 1450/20000 - Val Loss: 1.311923 - Seq Acc: 0.80%
2025-03-25 11:57:04,483 - training_loop - INFO - 
SimpleTransformer - Step 1500/20000 - Val Loss: 1.199199 - Seq Acc: 1.65%
2025-03-25 11:57:07,857 - training_loop - INFO - 
LatentTransformer - Step 1500/20000 - Val Loss: 1.321039 - Seq Acc: 1.05%
2025-03-25 11:57:44,946 - training_loop - INFO - 
SimpleTransformer - Step 1550/20000 - Val Loss: 1.185868 - Seq Acc: 1.80%
2025-03-25 11:57:48,397 - training_loop - INFO - 
LatentTransformer - Step 1550/20000 - Val Loss: 1.317727 - Seq Acc: 1.00%
2025-03-25 11:58:21,645 - training_loop - INFO - 
SimpleTransformer - Step 1600/20000 - Val Loss: 1.186791 - Seq Acc: 1.55%
2025-03-25 11:58:24,820 - training_loop - INFO - 
LatentTransformer - Step 1600/20000 - Val Loss: 1.313545 - Seq Acc: 1.05%
2025-03-25 11:59:00,663 - training_loop - INFO - 
SimpleTransformer - Step 1650/20000 - Val Loss: 1.161073 - Seq Acc: 1.55%
2025-03-25 11:59:06,616 - training_loop - INFO - 
LatentTransformer - Step 1650/20000 - Val Loss: 1.307785 - Seq Acc: 0.90%
2025-03-25 11:59:43,357 - training_loop - INFO - 
SimpleTransformer - Step 1700/20000 - Val Loss: 1.143940 - Seq Acc: 2.15%
2025-03-25 11:59:49,119 - training_loop - INFO - 
LatentTransformer - Step 1700/20000 - Val Loss: 1.271059 - Seq Acc: 1.30%
2025-03-25 12:00:27,253 - training_loop - INFO - 
SimpleTransformer - Step 1750/20000 - Val Loss: 1.131084 - Seq Acc: 2.05%
2025-03-25 12:00:33,289 - training_loop - INFO - 
LatentTransformer - Step 1750/20000 - Val Loss: 1.263820 - Seq Acc: 1.10%
2025-03-25 12:01:12,401 - training_loop - INFO - 
SimpleTransformer - Step 1800/20000 - Val Loss: 1.140061 - Seq Acc: 1.65%
2025-03-25 12:01:15,575 - training_loop - INFO - 
LatentTransformer - Step 1800/20000 - Val Loss: 1.295929 - Seq Acc: 0.85%
2025-03-25 12:01:50,997 - training_loop - INFO - 
SimpleTransformer - Step 1850/20000 - Val Loss: 1.213112 - Seq Acc: 2.00%
2025-03-25 12:01:54,337 - training_loop - INFO - 
LatentTransformer - Step 1850/20000 - Val Loss: 1.268615 - Seq Acc: 1.20%
2025-03-25 12:02:33,493 - training_loop - INFO - 
SimpleTransformer - Step 1900/20000 - Val Loss: 1.115170 - Seq Acc: 1.80%
2025-03-25 12:02:36,889 - training_loop - INFO - 
LatentTransformer - Step 1900/20000 - Val Loss: 1.265293 - Seq Acc: 1.65%
2025-03-25 12:03:14,039 - training_loop - INFO - 
SimpleTransformer - Step 1950/20000 - Val Loss: 1.101324 - Seq Acc: 2.00%
2025-03-25 12:03:17,382 - training_loop - INFO - 
LatentTransformer - Step 1950/20000 - Val Loss: 1.280819 - Seq Acc: 1.00%
2025-03-25 12:03:51,973 - training_loop - INFO - 
SimpleTransformer - Step 2000/20000 - Val Loss: 1.094752 - Seq Acc: 2.20%
2025-03-25 12:03:55,120 - training_loop - INFO - 
LatentTransformer - Step 2000/20000 - Val Loss: 1.268416 - Seq Acc: 1.45%
2025-03-25 12:04:32,347 - training_loop - INFO - 
SimpleTransformer - Step 2050/20000 - Val Loss: 1.085464 - Seq Acc: 2.45%
2025-03-25 12:04:36,460 - training_loop - INFO - 
LatentTransformer - Step 2050/20000 - Val Loss: 1.304805 - Seq Acc: 1.00%
2025-03-25 12:05:19,199 - training_loop - INFO - 
SimpleTransformer - Step 2100/20000 - Val Loss: 1.084450 - Seq Acc: 2.20%
2025-03-25 12:05:24,901 - training_loop - INFO - 
LatentTransformer - Step 2100/20000 - Val Loss: 1.258725 - Seq Acc: 1.35%
2025-03-25 12:06:02,240 - training_loop - INFO - 
SimpleTransformer - Step 2150/20000 - Val Loss: 1.077116 - Seq Acc: 2.30%
2025-03-25 12:06:05,581 - training_loop - INFO - 
LatentTransformer - Step 2150/20000 - Val Loss: 1.264079 - Seq Acc: 0.90%
2025-03-25 12:06:41,016 - training_loop - INFO - 
SimpleTransformer - Step 2200/20000 - Val Loss: 1.093159 - Seq Acc: 2.50%
2025-03-25 12:06:44,131 - training_loop - INFO - 
LatentTransformer - Step 2200/20000 - Val Loss: 1.276534 - Seq Acc: 1.15%
2025-03-25 12:07:21,934 - training_loop - INFO - 
SimpleTransformer - Step 2250/20000 - Val Loss: 1.075295 - Seq Acc: 2.50%
2025-03-25 12:07:25,284 - training_loop - INFO - 
LatentTransformer - Step 2250/20000 - Val Loss: 1.259116 - Seq Acc: 1.40%
2025-03-25 12:08:03,015 - training_loop - INFO - 
SimpleTransformer - Step 2300/20000 - Val Loss: 1.106225 - Seq Acc: 1.90%
2025-03-25 12:08:06,387 - training_loop - INFO - 
LatentTransformer - Step 2300/20000 - Val Loss: 1.261999 - Seq Acc: 1.45%
2025-03-25 12:08:44,179 - training_loop - INFO - 
SimpleTransformer - Step 2350/20000 - Val Loss: 1.069586 - Seq Acc: 2.70%
2025-03-25 12:08:47,553 - training_loop - INFO - 
LatentTransformer - Step 2350/20000 - Val Loss: 1.360241 - Seq Acc: 0.95%
2025-03-25 12:09:28,212 - training_loop - INFO - 
SimpleTransformer - Step 2400/20000 - Val Loss: 1.294999 - Seq Acc: 1.95%
2025-03-25 12:09:31,382 - training_loop - INFO - 
LatentTransformer - Step 2400/20000 - Val Loss: 1.266357 - Seq Acc: 1.15%
2025-03-25 12:10:07,010 - training_loop - INFO - 
SimpleTransformer - Step 2450/20000 - Val Loss: 1.087242 - Seq Acc: 2.55%
2025-03-25 12:10:10,406 - training_loop - INFO - 
LatentTransformer - Step 2450/20000 - Val Loss: 1.267750 - Seq Acc: 1.20%
2025-03-25 12:10:49,899 - training_loop - INFO - 
SimpleTransformer - Step 2500/20000 - Val Loss: 1.062314 - Seq Acc: 2.40%
2025-03-25 12:10:53,368 - training_loop - INFO - 
LatentTransformer - Step 2500/20000 - Val Loss: 1.264023 - Seq Acc: 1.20%
2025-03-25 12:11:32,849 - training_loop - INFO - 
SimpleTransformer - Step 2550/20000 - Val Loss: 1.065204 - Seq Acc: 2.75%
2025-03-25 12:11:36,247 - training_loop - INFO - 
LatentTransformer - Step 2550/20000 - Val Loss: 1.263974 - Seq Acc: 1.10%
2025-03-25 12:12:12,715 - training_loop - INFO - 
SimpleTransformer - Step 2600/20000 - Val Loss: 1.065251 - Seq Acc: 2.95%
2025-03-25 12:12:15,982 - training_loop - INFO - 
LatentTransformer - Step 2600/20000 - Val Loss: 1.280834 - Seq Acc: 1.70%
2025-03-25 12:12:57,400 - training_loop - INFO - 
SimpleTransformer - Step 2650/20000 - Val Loss: 1.141666 - Seq Acc: 2.60%
2025-03-25 12:13:00,813 - training_loop - INFO - 
LatentTransformer - Step 2650/20000 - Val Loss: 1.272826 - Seq Acc: 1.15%
2025-03-25 12:13:43,101 - training_loop - INFO - 
SimpleTransformer - Step 2700/20000 - Val Loss: 1.050269 - Seq Acc: 2.75%
2025-03-25 12:13:46,546 - training_loop - INFO - 
LatentTransformer - Step 2700/20000 - Val Loss: 1.258826 - Seq Acc: 1.50%
2025-03-25 12:14:31,040 - training_loop - INFO - 
SimpleTransformer - Step 2750/20000 - Val Loss: 1.051151 - Seq Acc: 3.00%
2025-03-25 12:14:34,432 - training_loop - INFO - 
LatentTransformer - Step 2750/20000 - Val Loss: 1.261820 - Seq Acc: 1.20%
2025-03-25 12:15:13,035 - training_loop - INFO - 
SimpleTransformer - Step 2800/20000 - Val Loss: 1.059474 - Seq Acc: 2.85%
2025-03-25 12:15:16,281 - training_loop - INFO - 
LatentTransformer - Step 2800/20000 - Val Loss: 1.271666 - Seq Acc: 1.40%
2025-03-25 12:15:56,602 - training_loop - INFO - 
SimpleTransformer - Step 2850/20000 - Val Loss: 1.089566 - Seq Acc: 2.65%
2025-03-25 12:16:00,720 - training_loop - INFO - 
LatentTransformer - Step 2850/20000 - Val Loss: 1.262725 - Seq Acc: 1.35%
2025-03-25 12:16:43,254 - training_loop - INFO - 
SimpleTransformer - Step 2900/20000 - Val Loss: 1.105191 - Seq Acc: 2.45%
2025-03-25 12:16:46,715 - training_loop - INFO - 
LatentTransformer - Step 2900/20000 - Val Loss: 1.316345 - Seq Acc: 1.45%
2025-03-25 12:17:29,670 - training_loop - INFO - 
SimpleTransformer - Step 2950/20000 - Val Loss: 1.043311 - Seq Acc: 3.35%
2025-03-25 12:17:33,219 - training_loop - INFO - 
LatentTransformer - Step 2950/20000 - Val Loss: 1.265661 - Seq Acc: 1.05%
2025-03-25 12:18:17,295 - training_loop - INFO - 
SimpleTransformer - Step 3000/20000 - Val Loss: 1.057120 - Seq Acc: 3.25%
2025-03-25 12:18:20,489 - training_loop - INFO - 
LatentTransformer - Step 3000/20000 - Val Loss: 1.268479 - Seq Acc: 1.25%
2025-03-25 12:19:01,025 - training_loop - INFO - 
SimpleTransformer - Step 3050/20000 - Val Loss: 1.069042 - Seq Acc: 3.00%
2025-03-25 12:19:06,760 - training_loop - INFO - 
LatentTransformer - Step 3050/20000 - Val Loss: 1.256107 - Seq Acc: 1.45%
2025-03-25 12:19:48,915 - training_loop - INFO - 
SimpleTransformer - Step 3100/20000 - Val Loss: 1.021708 - Seq Acc: 3.45%
2025-03-25 12:19:52,369 - training_loop - INFO - 
LatentTransformer - Step 3100/20000 - Val Loss: 1.268758 - Seq Acc: 1.50%
2025-03-25 12:20:32,405 - training_loop - INFO - 
SimpleTransformer - Step 3150/20000 - Val Loss: 1.053893 - Seq Acc: 2.85%
2025-03-25 12:20:35,856 - training_loop - INFO - 
LatentTransformer - Step 3150/20000 - Val Loss: 1.265181 - Seq Acc: 1.15%
2025-03-25 12:21:19,980 - training_loop - INFO - 
SimpleTransformer - Step 3200/20000 - Val Loss: 1.023952 - Seq Acc: 3.00%
2025-03-25 12:21:23,301 - training_loop - INFO - 
LatentTransformer - Step 3200/20000 - Val Loss: 1.293824 - Seq Acc: 1.05%
2025-03-25 12:22:12,365 - training_loop - INFO - 
SimpleTransformer - Step 3250/20000 - Val Loss: 1.019814 - Seq Acc: 3.05%
2025-03-25 12:22:16,546 - training_loop - INFO - 
LatentTransformer - Step 3250/20000 - Val Loss: 1.276096 - Seq Acc: 1.10%
2025-03-25 12:23:05,047 - training_loop - INFO - 
SimpleTransformer - Step 3300/20000 - Val Loss: 0.995231 - Seq Acc: 3.60%
2025-03-25 12:23:08,566 - training_loop - INFO - 
LatentTransformer - Step 3300/20000 - Val Loss: 1.275927 - Seq Acc: 1.30%
2025-03-25 12:23:51,787 - training_loop - INFO - 
SimpleTransformer - Step 3350/20000 - Val Loss: 0.991888 - Seq Acc: 3.80%
2025-03-25 12:23:55,313 - training_loop - INFO - 
LatentTransformer - Step 3350/20000 - Val Loss: 1.265066 - Seq Acc: 1.10%
2025-03-25 12:24:40,496 - training_loop - INFO - 
SimpleTransformer - Step 3400/20000 - Val Loss: 0.990306 - Seq Acc: 3.50%
2025-03-25 12:24:43,874 - training_loop - INFO - 
LatentTransformer - Step 3400/20000 - Val Loss: 1.260497 - Seq Acc: 1.30%
2025-03-25 12:25:27,395 - training_loop - INFO - 
SimpleTransformer - Step 3450/20000 - Val Loss: 0.974742 - Seq Acc: 4.15%
2025-03-25 12:25:31,672 - training_loop - INFO - 
LatentTransformer - Step 3450/20000 - Val Loss: 1.268415 - Seq Acc: 1.55%
2025-03-25 12:26:13,748 - training_loop - INFO - 
SimpleTransformer - Step 3500/20000 - Val Loss: 0.974658 - Seq Acc: 3.30%
2025-03-25 12:26:17,311 - training_loop - INFO - 
LatentTransformer - Step 3500/20000 - Val Loss: 1.264836 - Seq Acc: 1.05%
2025-03-25 12:27:03,854 - training_loop - INFO - 
SimpleTransformer - Step 3550/20000 - Val Loss: 0.949998 - Seq Acc: 4.40%
2025-03-25 12:27:07,421 - training_loop - INFO - 
LatentTransformer - Step 3550/20000 - Val Loss: 1.303171 - Seq Acc: 1.15%
2025-03-25 12:27:50,596 - training_loop - INFO - 
SimpleTransformer - Step 3600/20000 - Val Loss: 0.931788 - Seq Acc: 4.45%
2025-03-25 12:27:53,900 - training_loop - INFO - 
LatentTransformer - Step 3600/20000 - Val Loss: 1.271158 - Seq Acc: 1.20%
2025-03-25 12:28:37,732 - training_loop - INFO - 
SimpleTransformer - Step 3650/20000 - Val Loss: 0.915466 - Seq Acc: 4.45%
2025-03-25 12:28:41,234 - training_loop - INFO - 
LatentTransformer - Step 3650/20000 - Val Loss: 1.278060 - Seq Acc: 1.30%
2025-03-25 12:29:24,095 - training_loop - INFO - 
SimpleTransformer - Step 3700/20000 - Val Loss: 0.907963 - Seq Acc: 4.50%
2025-03-25 12:29:27,644 - training_loop - INFO - 
LatentTransformer - Step 3700/20000 - Val Loss: 1.263589 - Seq Acc: 1.30%
2025-03-25 12:30:15,685 - training_loop - INFO - 
SimpleTransformer - Step 3750/20000 - Val Loss: 0.895510 - Seq Acc: 5.10%
2025-03-25 12:30:19,238 - training_loop - INFO - 
LatentTransformer - Step 3750/20000 - Val Loss: 1.258739 - Seq Acc: 1.30%
2025-03-25 12:31:01,566 - training_loop - INFO - 
SimpleTransformer - Step 3800/20000 - Val Loss: 0.890601 - Seq Acc: 4.60%
2025-03-25 12:31:04,898 - training_loop - INFO - 
LatentTransformer - Step 3800/20000 - Val Loss: 1.267542 - Seq Acc: 1.40%
2025-03-25 12:31:48,768 - training_loop - INFO - 
SimpleTransformer - Step 3850/20000 - Val Loss: 0.894370 - Seq Acc: 4.60%
2025-03-25 12:31:52,330 - training_loop - INFO - 
LatentTransformer - Step 3850/20000 - Val Loss: 1.258219 - Seq Acc: 1.25%
2025-03-25 12:32:39,672 - training_loop - INFO - 
SimpleTransformer - Step 3900/20000 - Val Loss: 0.881000 - Seq Acc: 5.10%
2025-03-25 12:32:43,273 - training_loop - INFO - 
LatentTransformer - Step 3900/20000 - Val Loss: 1.263511 - Seq Acc: 1.35%
2025-03-25 12:33:27,052 - training_loop - INFO - 
SimpleTransformer - Step 3950/20000 - Val Loss: 0.973786 - Seq Acc: 4.45%
2025-03-25 12:33:30,730 - training_loop - INFO - 
LatentTransformer - Step 3950/20000 - Val Loss: 1.265785 - Seq Acc: 1.05%
2025-03-25 12:34:14,291 - training_loop - INFO - 
SimpleTransformer - Step 4000/20000 - Val Loss: 0.889559 - Seq Acc: 4.50%
2025-03-25 12:34:17,638 - training_loop - INFO - 
LatentTransformer - Step 4000/20000 - Val Loss: 1.263339 - Seq Acc: 1.25%
2025-03-25 12:35:08,714 - training_loop - INFO - 
SimpleTransformer - Step 4050/20000 - Val Loss: 0.872794 - Seq Acc: 5.40%
2025-03-25 12:35:13,033 - training_loop - INFO - 
LatentTransformer - Step 4050/20000 - Val Loss: 1.261707 - Seq Acc: 1.25%
2025-03-25 12:36:02,389 - training_loop - INFO - 
SimpleTransformer - Step 4100/20000 - Val Loss: 0.867595 - Seq Acc: 5.35%
2025-03-25 12:36:05,928 - training_loop - INFO - 
LatentTransformer - Step 4100/20000 - Val Loss: 1.260289 - Seq Acc: 1.40%
2025-03-25 12:36:52,739 - training_loop - INFO - 
SimpleTransformer - Step 4150/20000 - Val Loss: 0.864572 - Seq Acc: 5.60%
2025-03-25 12:36:56,261 - training_loop - INFO - 
LatentTransformer - Step 4150/20000 - Val Loss: 1.265056 - Seq Acc: 1.00%
2025-03-25 12:37:41,820 - training_loop - INFO - 
SimpleTransformer - Step 4200/20000 - Val Loss: 0.869410 - Seq Acc: 5.15%
2025-03-25 12:37:45,138 - training_loop - INFO - 
LatentTransformer - Step 4200/20000 - Val Loss: 1.262814 - Seq Acc: 1.45%
2025-03-25 12:38:34,260 - training_loop - INFO - 
SimpleTransformer - Step 4250/20000 - Val Loss: 0.862297 - Seq Acc: 5.50%
2025-03-25 12:38:38,441 - training_loop - INFO - 
LatentTransformer - Step 4250/20000 - Val Loss: 1.264319 - Seq Acc: 1.50%
2025-03-25 12:39:22,092 - training_loop - INFO - 
SimpleTransformer - Step 4300/20000 - Val Loss: 0.869378 - Seq Acc: 5.10%
2025-03-25 12:39:25,654 - training_loop - INFO - 
LatentTransformer - Step 4300/20000 - Val Loss: 1.260062 - Seq Acc: 0.95%
2025-03-25 12:40:12,421 - training_loop - INFO - 
SimpleTransformer - Step 4350/20000 - Val Loss: 0.859064 - Seq Acc: 5.25%
2025-03-25 12:40:16,664 - training_loop - INFO - 
LatentTransformer - Step 4350/20000 - Val Loss: 1.264678 - Seq Acc: 1.20%
2025-03-25 12:41:02,814 - training_loop - INFO - 
SimpleTransformer - Step 4400/20000 - Val Loss: 0.871964 - Seq Acc: 5.40%
2025-03-25 12:41:06,109 - training_loop - INFO - 
LatentTransformer - Step 4400/20000 - Val Loss: 1.269791 - Seq Acc: 1.20%
2025-03-25 12:41:56,746 - training_loop - INFO - 
SimpleTransformer - Step 4450/20000 - Val Loss: 0.871504 - Seq Acc: 4.65%
2025-03-25 12:42:00,376 - training_loop - INFO - 
LatentTransformer - Step 4450/20000 - Val Loss: 1.266833 - Seq Acc: 1.10%
2025-03-25 12:42:46,718 - training_loop - INFO - 
SimpleTransformer - Step 4500/20000 - Val Loss: 0.863324 - Seq Acc: 5.45%
2025-03-25 12:42:50,266 - training_loop - INFO - 
LatentTransformer - Step 4500/20000 - Val Loss: 1.260597 - Seq Acc: 1.20%
2025-03-25 12:43:37,395 - training_loop - INFO - 
SimpleTransformer - Step 4550/20000 - Val Loss: 0.862695 - Seq Acc: 5.45%
2025-03-25 12:43:41,554 - training_loop - INFO - 
LatentTransformer - Step 4550/20000 - Val Loss: 1.257712 - Seq Acc: 1.30%
2025-03-25 12:44:28,426 - training_loop - INFO - 
SimpleTransformer - Step 4600/20000 - Val Loss: 0.870259 - Seq Acc: 5.55%
2025-03-25 12:44:31,746 - training_loop - INFO - 
LatentTransformer - Step 4600/20000 - Val Loss: 1.263131 - Seq Acc: 1.25%
2025-03-25 12:45:20,963 - training_loop - INFO - 
SimpleTransformer - Step 4650/20000 - Val Loss: 0.873631 - Seq Acc: 5.30%
2025-03-25 12:45:25,162 - training_loop - INFO - 
LatentTransformer - Step 4650/20000 - Val Loss: 1.260669 - Seq Acc: 1.25%
2025-03-25 12:46:13,741 - training_loop - INFO - 
SimpleTransformer - Step 4700/20000 - Val Loss: 0.856936 - Seq Acc: 5.40%
2025-03-25 12:46:17,239 - training_loop - INFO - 
LatentTransformer - Step 4700/20000 - Val Loss: 1.273046 - Seq Acc: 1.20%
2025-03-25 12:47:06,071 - training_loop - INFO - 
SimpleTransformer - Step 4750/20000 - Val Loss: 0.862523 - Seq Acc: 5.65%
2025-03-25 12:47:11,955 - training_loop - INFO - 
LatentTransformer - Step 4750/20000 - Val Loss: 1.254974 - Seq Acc: 1.00%
2025-03-25 12:47:55,599 - training_loop - INFO - 
SimpleTransformer - Step 4800/20000 - Val Loss: 0.863636 - Seq Acc: 5.25%
2025-03-25 12:47:58,929 - training_loop - INFO - 
LatentTransformer - Step 4800/20000 - Val Loss: 1.274235 - Seq Acc: 1.10%
2025-03-25 12:48:48,489 - training_loop - INFO - 
SimpleTransformer - Step 4850/20000 - Val Loss: 0.868965 - Seq Acc: 5.50%
2025-03-25 12:48:52,029 - training_loop - INFO - 
LatentTransformer - Step 4850/20000 - Val Loss: 1.261656 - Seq Acc: 1.10%
2025-03-25 12:49:33,179 - training_loop - INFO - 
SimpleTransformer - Step 4900/20000 - Val Loss: 0.859003 - Seq Acc: 5.60%
2025-03-25 12:49:36,747 - training_loop - INFO - 
LatentTransformer - Step 4900/20000 - Val Loss: 1.257792 - Seq Acc: 1.55%
2025-03-25 12:50:27,221 - training_loop - INFO - 
SimpleTransformer - Step 4950/20000 - Val Loss: 0.856758 - Seq Acc: 5.60%
2025-03-25 12:50:31,540 - training_loop - INFO - 
LatentTransformer - Step 4950/20000 - Val Loss: 1.274754 - Seq Acc: 1.05%
2025-03-25 12:51:18,326 - training_loop - INFO - 
SimpleTransformer - Step 5000/20000 - Val Loss: 0.863229 - Seq Acc: 5.15%
2025-03-25 12:51:21,556 - training_loop - INFO - 
LatentTransformer - Step 5000/20000 - Val Loss: 1.258040 - Seq Acc: 1.35%
2025-03-25 12:52:04,540 - training_loop - INFO - 
SimpleTransformer - Step 5050/20000 - Val Loss: 0.866806 - Seq Acc: 5.85%
2025-03-25 12:52:07,959 - training_loop - INFO - 
LatentTransformer - Step 5050/20000 - Val Loss: 1.255347 - Seq Acc: 1.55%
2025-03-25 12:52:51,506 - training_loop - INFO - 
SimpleTransformer - Step 5100/20000 - Val Loss: 0.857932 - Seq Acc: 5.35%
2025-03-25 12:52:57,341 - training_loop - INFO - 
LatentTransformer - Step 5100/20000 - Val Loss: 1.252529 - Seq Acc: 1.20%
2025-03-25 12:53:46,261 - training_loop - INFO - 
SimpleTransformer - Step 5150/20000 - Val Loss: 0.853444 - Seq Acc: 5.25%
2025-03-25 12:53:49,784 - training_loop - INFO - 
LatentTransformer - Step 5150/20000 - Val Loss: 1.255867 - Seq Acc: 1.25%
2025-03-25 12:54:37,834 - training_loop - INFO - 
SimpleTransformer - Step 5200/20000 - Val Loss: 0.857448 - Seq Acc: 6.00%
2025-03-25 12:54:43,399 - training_loop - INFO - 
LatentTransformer - Step 5200/20000 - Val Loss: 1.251868 - Seq Acc: 1.60%
2025-03-25 12:55:29,452 - training_loop - INFO - 
SimpleTransformer - Step 5250/20000 - Val Loss: 0.894271 - Seq Acc: 5.80%
2025-03-25 12:55:32,923 - training_loop - INFO - 
LatentTransformer - Step 5250/20000 - Val Loss: 1.255014 - Seq Acc: 1.35%
2025-03-25 12:56:15,320 - training_loop - INFO - 
SimpleTransformer - Step 5300/20000 - Val Loss: 0.871995 - Seq Acc: 5.75%
2025-03-25 12:56:18,818 - training_loop - INFO - 
LatentTransformer - Step 5300/20000 - Val Loss: 1.255303 - Seq Acc: 1.35%
2025-03-25 12:57:03,740 - training_loop - INFO - 
SimpleTransformer - Step 5350/20000 - Val Loss: 0.865283 - Seq Acc: 5.60%
2025-03-25 12:57:07,156 - training_loop - INFO - 
LatentTransformer - Step 5350/20000 - Val Loss: 1.255030 - Seq Acc: 1.35%
2025-03-25 12:57:55,920 - training_loop - INFO - 
SimpleTransformer - Step 5400/20000 - Val Loss: 0.859791 - Seq Acc: 5.05%
2025-03-25 12:57:59,165 - training_loop - INFO - 
LatentTransformer - Step 5400/20000 - Val Loss: 1.257394 - Seq Acc: 1.20%
2025-03-25 12:58:42,471 - training_loop - INFO - 
SimpleTransformer - Step 5450/20000 - Val Loss: 0.883216 - Seq Acc: 5.45%
2025-03-25 12:58:45,915 - training_loop - INFO - 
LatentTransformer - Step 5450/20000 - Val Loss: 1.254328 - Seq Acc: 1.55%
2025-03-25 12:59:36,698 - training_loop - INFO - 
SimpleTransformer - Step 5500/20000 - Val Loss: 0.871920 - Seq Acc: 5.85%
2025-03-25 12:59:40,177 - training_loop - INFO - 
LatentTransformer - Step 5500/20000 - Val Loss: 1.261440 - Seq Acc: 1.30%
2025-03-25 13:00:26,789 - training_loop - INFO - 
SimpleTransformer - Step 5550/20000 - Val Loss: 0.867745 - Seq Acc: 5.70%
2025-03-25 13:00:31,039 - training_loop - INFO - 
LatentTransformer - Step 5550/20000 - Val Loss: 1.262372 - Seq Acc: 1.20%
2025-03-25 13:01:15,420 - training_loop - INFO - 
SimpleTransformer - Step 5600/20000 - Val Loss: 0.861587 - Seq Acc: 5.45%
2025-03-25 13:01:18,644 - training_loop - INFO - 
LatentTransformer - Step 5600/20000 - Val Loss: 1.281265 - Seq Acc: 1.25%
2025-03-25 13:02:09,432 - training_loop - INFO - 
SimpleTransformer - Step 5650/20000 - Val Loss: 0.879515 - Seq Acc: 6.05%
2025-03-25 13:02:12,904 - training_loop - INFO - 
LatentTransformer - Step 5650/20000 - Val Loss: 1.526934 - Seq Acc: 0.55%
2025-03-25 13:02:56,982 - training_loop - INFO - 
SimpleTransformer - Step 5700/20000 - Val Loss: 0.880159 - Seq Acc: 5.70%
2025-03-25 13:03:01,153 - training_loop - INFO - 
LatentTransformer - Step 5700/20000 - Val Loss: 1.449858 - Seq Acc: 0.65%
2025-03-25 13:03:49,236 - training_loop - INFO - 
SimpleTransformer - Step 5750/20000 - Val Loss: 0.902688 - Seq Acc: 5.20%
2025-03-25 13:03:52,714 - training_loop - INFO - 
LatentTransformer - Step 5750/20000 - Val Loss: 1.259778 - Seq Acc: 1.25%
2025-03-25 13:04:38,804 - training_loop - INFO - 
SimpleTransformer - Step 5800/20000 - Val Loss: 0.883658 - Seq Acc: 5.10%
2025-03-25 13:04:42,084 - training_loop - INFO - 
LatentTransformer - Step 5800/20000 - Val Loss: 1.260301 - Seq Acc: 1.30%
2025-03-25 13:05:31,573 - training_loop - INFO - 
SimpleTransformer - Step 5850/20000 - Val Loss: 0.868971 - Seq Acc: 5.65%
2025-03-25 13:05:35,026 - training_loop - INFO - 
LatentTransformer - Step 5850/20000 - Val Loss: 1.257037 - Seq Acc: 1.25%
2025-03-25 13:06:23,293 - training_loop - INFO - 
SimpleTransformer - Step 5900/20000 - Val Loss: 0.897463 - Seq Acc: 6.15%
2025-03-25 13:06:26,779 - training_loop - INFO - 
LatentTransformer - Step 5900/20000 - Val Loss: 1.273225 - Seq Acc: 1.50%
2025-03-25 13:07:17,208 - training_loop - INFO - 
SimpleTransformer - Step 5950/20000 - Val Loss: 0.883699 - Seq Acc: 5.65%
2025-03-25 13:07:23,640 - training_loop - INFO - 
LatentTransformer - Step 5950/20000 - Val Loss: 1.247144 - Seq Acc: 1.20%
2025-03-25 13:08:16,308 - training_loop - INFO - 
SimpleTransformer - Step 6000/20000 - Val Loss: 0.869364 - Seq Acc: 5.40%
2025-03-25 13:08:19,607 - training_loop - INFO - 
LatentTransformer - Step 6000/20000 - Val Loss: 1.251934 - Seq Acc: 1.60%
2025-03-25 13:09:12,280 - training_loop - INFO - 
SimpleTransformer - Step 6050/20000 - Val Loss: 0.875362 - Seq Acc: 5.35%
2025-03-25 13:09:16,344 - training_loop - INFO - 
LatentTransformer - Step 6050/20000 - Val Loss: 1.249868 - Seq Acc: 1.25%
2025-03-25 13:10:08,479 - training_loop - INFO - 
SimpleTransformer - Step 6100/20000 - Val Loss: 0.907055 - Seq Acc: 6.05%
2025-03-25 13:10:14,273 - training_loop - INFO - 
LatentTransformer - Step 6100/20000 - Val Loss: 1.245699 - Seq Acc: 1.25%
2025-03-25 13:11:03,897 - training_loop - INFO - 
SimpleTransformer - Step 6150/20000 - Val Loss: 0.905327 - Seq Acc: 6.30%
2025-03-25 13:11:07,359 - training_loop - INFO - 
LatentTransformer - Step 6150/20000 - Val Loss: 1.248274 - Seq Acc: 1.30%
2025-03-25 13:11:57,775 - training_loop - INFO - 
SimpleTransformer - Step 6200/20000 - Val Loss: 0.889639 - Seq Acc: 6.10%
2025-03-25 13:12:01,144 - training_loop - INFO - 
LatentTransformer - Step 6200/20000 - Val Loss: 1.262797 - Seq Acc: 1.00%
2025-03-25 13:12:46,065 - training_loop - INFO - 
SimpleTransformer - Step 6250/20000 - Val Loss: 0.874676 - Seq Acc: 6.40%
2025-03-25 13:12:49,522 - training_loop - INFO - 
LatentTransformer - Step 6250/20000 - Val Loss: 1.267056 - Seq Acc: 1.65%
2025-03-25 13:13:38,653 - training_loop - INFO - 
SimpleTransformer - Step 6300/20000 - Val Loss: 0.917159 - Seq Acc: 6.75%
2025-03-25 13:13:42,760 - training_loop - INFO - 
LatentTransformer - Step 6300/20000 - Val Loss: 1.264892 - Seq Acc: 1.15%
2025-03-25 13:14:35,955 - training_loop - INFO - 
SimpleTransformer - Step 6350/20000 - Val Loss: 0.887205 - Seq Acc: 6.70%
2025-03-25 13:14:41,889 - training_loop - INFO - 
LatentTransformer - Step 6350/20000 - Val Loss: 1.245162 - Seq Acc: 1.45%
2025-03-25 13:15:30,456 - training_loop - INFO - 
SimpleTransformer - Step 6400/20000 - Val Loss: 0.846093 - Seq Acc: 7.10%
2025-03-25 13:15:33,831 - training_loop - INFO - 
LatentTransformer - Step 6400/20000 - Val Loss: 1.253266 - Seq Acc: 1.25%
2025-03-25 13:16:22,756 - training_loop - INFO - 
SimpleTransformer - Step 6450/20000 - Val Loss: 0.855661 - Seq Acc: 6.50%
2025-03-25 13:16:26,219 - training_loop - INFO - 
LatentTransformer - Step 6450/20000 - Val Loss: 1.256306 - Seq Acc: 1.55%
2025-03-25 13:17:11,572 - training_loop - INFO - 
SimpleTransformer - Step 6500/20000 - Val Loss: 0.868034 - Seq Acc: 7.55%
2025-03-25 13:17:15,015 - training_loop - INFO - 
LatentTransformer - Step 6500/20000 - Val Loss: 1.249159 - Seq Acc: 1.60%
2025-03-25 13:18:05,338 - training_loop - INFO - 
SimpleTransformer - Step 6550/20000 - Val Loss: 0.839694 - Seq Acc: 7.30%
2025-03-25 13:18:11,172 - training_loop - INFO - 
LatentTransformer - Step 6550/20000 - Val Loss: 1.236052 - Seq Acc: 1.45%
2025-03-25 13:19:09,989 - training_loop - INFO - 
SimpleTransformer - Step 6600/20000 - Val Loss: 0.809250 - Seq Acc: 8.30%
2025-03-25 13:19:13,199 - training_loop - INFO - 
LatentTransformer - Step 6600/20000 - Val Loss: 1.243121 - Seq Acc: 1.45%
2025-03-25 13:20:02,403 - training_loop - INFO - 
SimpleTransformer - Step 6650/20000 - Val Loss: 0.823511 - Seq Acc: 8.70%
2025-03-25 13:20:06,465 - training_loop - INFO - 
LatentTransformer - Step 6650/20000 - Val Loss: 1.246400 - Seq Acc: 1.55%
2025-03-25 13:20:55,969 - training_loop - INFO - 
SimpleTransformer - Step 6700/20000 - Val Loss: 0.839883 - Seq Acc: 8.15%
2025-03-25 13:20:59,423 - training_loop - INFO - 
LatentTransformer - Step 6700/20000 - Val Loss: 1.248331 - Seq Acc: 1.60%
2025-03-25 13:21:46,882 - training_loop - INFO - 
SimpleTransformer - Step 6750/20000 - Val Loss: 0.830058 - Seq Acc: 8.20%
2025-03-25 13:21:50,329 - training_loop - INFO - 
LatentTransformer - Step 6750/20000 - Val Loss: 1.259039 - Seq Acc: 1.65%
2025-03-25 13:22:38,842 - training_loop - INFO - 
SimpleTransformer - Step 6800/20000 - Val Loss: 0.788369 - Seq Acc: 8.70%
2025-03-25 13:22:42,088 - training_loop - INFO - 
LatentTransformer - Step 6800/20000 - Val Loss: 1.242812 - Seq Acc: 1.65%
2025-03-25 13:23:33,428 - training_loop - INFO - 
SimpleTransformer - Step 6850/20000 - Val Loss: 0.813077 - Seq Acc: 8.75%
2025-03-25 13:23:36,935 - training_loop - INFO - 
LatentTransformer - Step 6850/20000 - Val Loss: 1.248216 - Seq Acc: 1.60%
2025-03-25 13:24:22,061 - training_loop - INFO - 
SimpleTransformer - Step 6900/20000 - Val Loss: 0.815599 - Seq Acc: 9.05%
2025-03-25 13:24:25,517 - training_loop - INFO - 
LatentTransformer - Step 6900/20000 - Val Loss: 1.256935 - Seq Acc: 1.75%
2025-03-25 13:25:18,996 - training_loop - INFO - 
SimpleTransformer - Step 6950/20000 - Val Loss: 0.833494 - Seq Acc: 9.15%
2025-03-25 13:25:22,479 - training_loop - INFO - 
LatentTransformer - Step 6950/20000 - Val Loss: 1.238297 - Seq Acc: 1.50%
2025-03-25 13:26:13,675 - training_loop - INFO - 
SimpleTransformer - Step 7000/20000 - Val Loss: 0.803273 - Seq Acc: 9.20%
2025-03-25 13:26:16,924 - training_loop - INFO - 
LatentTransformer - Step 7000/20000 - Val Loss: 1.241584 - Seq Acc: 1.50%
2025-03-25 13:27:08,672 - training_loop - INFO - 
SimpleTransformer - Step 7050/20000 - Val Loss: 0.801433 - Seq Acc: 9.75%
2025-03-25 13:27:12,768 - training_loop - INFO - 
LatentTransformer - Step 7050/20000 - Val Loss: 1.246177 - Seq Acc: 1.35%
2025-03-25 13:28:05,570 - training_loop - INFO - 
SimpleTransformer - Step 7100/20000 - Val Loss: 0.837746 - Seq Acc: 9.30%
2025-03-25 13:28:09,606 - training_loop - INFO - 
LatentTransformer - Step 7100/20000 - Val Loss: 1.246699 - Seq Acc: 1.65%
2025-03-25 13:28:58,459 - training_loop - INFO - 
SimpleTransformer - Step 7150/20000 - Val Loss: 0.862254 - Seq Acc: 9.25%
2025-03-25 13:29:02,685 - training_loop - INFO - 
LatentTransformer - Step 7150/20000 - Val Loss: 1.241022 - Seq Acc: 1.95%
2025-03-25 13:29:53,906 - training_loop - INFO - 
SimpleTransformer - Step 7200/20000 - Val Loss: 0.817402 - Seq Acc: 9.00%
2025-03-25 13:29:57,167 - training_loop - INFO - 
LatentTransformer - Step 7200/20000 - Val Loss: 1.257208 - Seq Acc: 1.25%
2025-03-25 13:30:50,836 - training_loop - INFO - 
SimpleTransformer - Step 7250/20000 - Val Loss: 0.805960 - Seq Acc: 10.20%
2025-03-25 13:30:54,956 - training_loop - INFO - 
LatentTransformer - Step 7250/20000 - Val Loss: 1.243649 - Seq Acc: 1.40%
2025-03-25 13:31:49,157 - training_loop - INFO - 
SimpleTransformer - Step 7300/20000 - Val Loss: 0.832773 - Seq Acc: 9.90%
2025-03-25 13:31:53,379 - training_loop - INFO - 
LatentTransformer - Step 7300/20000 - Val Loss: 1.238080 - Seq Acc: 1.95%
2025-03-25 13:32:35,862 - training_loop - INFO - 
SimpleTransformer - Step 7350/20000 - Val Loss: 0.860744 - Seq Acc: 10.20%
2025-03-25 13:32:42,163 - training_loop - INFO - 
LatentTransformer - Step 7350/20000 - Val Loss: 1.231533 - Seq Acc: 1.50%
2025-03-25 13:33:34,871 - training_loop - INFO - 
SimpleTransformer - Step 7400/20000 - Val Loss: 0.855575 - Seq Acc: 9.00%
2025-03-25 13:33:38,061 - training_loop - INFO - 
LatentTransformer - Step 7400/20000 - Val Loss: 1.245904 - Seq Acc: 1.35%
2025-03-25 13:34:26,944 - training_loop - INFO - 
SimpleTransformer - Step 7450/20000 - Val Loss: 0.814879 - Seq Acc: 10.10%
2025-03-25 13:34:31,036 - training_loop - INFO - 
LatentTransformer - Step 7450/20000 - Val Loss: 1.236863 - Seq Acc: 1.60%
2025-03-25 13:35:28,311 - training_loop - INFO - 
SimpleTransformer - Step 7500/20000 - Val Loss: 0.852872 - Seq Acc: 9.10%
2025-03-25 13:35:31,808 - training_loop - INFO - 
LatentTransformer - Step 7500/20000 - Val Loss: 1.234969 - Seq Acc: 1.95%
2025-03-25 13:36:25,842 - training_loop - INFO - 
SimpleTransformer - Step 7550/20000 - Val Loss: 0.912608 - Seq Acc: 9.80%
2025-03-25 13:36:32,315 - training_loop - INFO - 
LatentTransformer - Step 7550/20000 - Val Loss: 1.228499 - Seq Acc: 1.65%
2025-03-25 13:37:27,056 - training_loop - INFO - 
SimpleTransformer - Step 7600/20000 - Val Loss: 0.840371 - Seq Acc: 10.75%
2025-03-25 13:37:30,459 - training_loop - INFO - 
LatentTransformer - Step 7600/20000 - Val Loss: 1.231186 - Seq Acc: 1.85%
2025-03-25 13:38:22,886 - training_loop - INFO - 
SimpleTransformer - Step 7650/20000 - Val Loss: 0.827142 - Seq Acc: 9.95%
2025-03-25 13:38:26,366 - training_loop - INFO - 
LatentTransformer - Step 7650/20000 - Val Loss: 1.240774 - Seq Acc: 2.15%
2025-03-25 13:39:26,095 - training_loop - INFO - 
SimpleTransformer - Step 7700/20000 - Val Loss: 0.855063 - Seq Acc: 10.30%
2025-03-25 13:39:31,839 - training_loop - INFO - 
LatentTransformer - Step 7700/20000 - Val Loss: 1.227412 - Seq Acc: 1.80%
2025-03-25 13:40:22,940 - training_loop - INFO - 
SimpleTransformer - Step 7750/20000 - Val Loss: 0.909646 - Seq Acc: 10.50%
2025-03-25 13:40:29,306 - training_loop - INFO - 
LatentTransformer - Step 7750/20000 - Val Loss: 1.221571 - Seq Acc: 2.05%
2025-03-25 13:41:19,478 - training_loop - INFO - 
SimpleTransformer - Step 7800/20000 - Val Loss: 0.862843 - Seq Acc: 10.60%
2025-03-25 13:41:22,782 - training_loop - INFO - 
LatentTransformer - Step 7800/20000 - Val Loss: 1.227701 - Seq Acc: 1.90%
2025-03-25 13:42:18,029 - training_loop - INFO - 
SimpleTransformer - Step 7850/20000 - Val Loss: 0.855355 - Seq Acc: 10.30%
2025-03-25 13:42:22,123 - training_loop - INFO - 
LatentTransformer - Step 7850/20000 - Val Loss: 1.235466 - Seq Acc: 1.60%
2025-03-25 13:43:16,532 - training_loop - INFO - 
SimpleTransformer - Step 7900/20000 - Val Loss: 0.870283 - Seq Acc: 10.75%
2025-03-25 13:43:20,029 - training_loop - INFO - 
LatentTransformer - Step 7900/20000 - Val Loss: 1.223570 - Seq Acc: 2.00%
2025-03-25 13:44:15,537 - training_loop - INFO - 
SimpleTransformer - Step 7950/20000 - Val Loss: 0.910408 - Seq Acc: 10.75%
2025-03-25 13:44:21,325 - training_loop - INFO - 
LatentTransformer - Step 7950/20000 - Val Loss: 1.214584 - Seq Acc: 1.70%
2025-03-25 13:45:15,817 - training_loop - INFO - 
SimpleTransformer - Step 8000/20000 - Val Loss: 0.921012 - Seq Acc: 11.00%
2025-03-25 13:45:19,479 - training_loop - INFO - 
LatentTransformer - Step 8000/20000 - Val Loss: 1.223884 - Seq Acc: 1.70%
2025-03-25 13:46:15,321 - training_loop - INFO - 
SimpleTransformer - Step 8050/20000 - Val Loss: 0.848942 - Seq Acc: 10.90%
2025-03-25 13:46:18,828 - training_loop - INFO - 
LatentTransformer - Step 8050/20000 - Val Loss: 1.232035 - Seq Acc: 1.95%
2025-03-25 13:47:16,116 - training_loop - INFO - 
SimpleTransformer - Step 8100/20000 - Val Loss: 0.894674 - Seq Acc: 10.60%
2025-03-25 13:47:20,253 - training_loop - INFO - 
LatentTransformer - Step 8100/20000 - Val Loss: 1.218404 - Seq Acc: 2.05%
2025-03-25 13:48:14,664 - training_loop - INFO - 
SimpleTransformer - Step 8150/20000 - Val Loss: 0.921534 - Seq Acc: 11.85%
2025-03-25 13:48:18,231 - training_loop - INFO - 
LatentTransformer - Step 8150/20000 - Val Loss: 1.216856 - Seq Acc: 2.15%
2025-03-25 13:49:11,084 - training_loop - INFO - 
SimpleTransformer - Step 8200/20000 - Val Loss: 0.976074 - Seq Acc: 10.80%
2025-03-25 13:49:14,463 - training_loop - INFO - 
LatentTransformer - Step 8200/20000 - Val Loss: 1.220678 - Seq Acc: 1.90%
2025-03-25 13:50:12,214 - training_loop - INFO - 
SimpleTransformer - Step 8250/20000 - Val Loss: 0.861458 - Seq Acc: 11.00%
2025-03-25 13:50:15,787 - training_loop - INFO - 
LatentTransformer - Step 8250/20000 - Val Loss: 1.223236 - Seq Acc: 2.05%
2025-03-25 13:51:11,169 - training_loop - INFO - 
SimpleTransformer - Step 8300/20000 - Val Loss: 0.899447 - Seq Acc: 11.55%
2025-03-25 13:51:17,655 - training_loop - INFO - 
LatentTransformer - Step 8300/20000 - Val Loss: 1.202323 - Seq Acc: 2.35%
2025-03-25 13:52:12,569 - training_loop - INFO - 
SimpleTransformer - Step 8350/20000 - Val Loss: 0.941831 - Seq Acc: 11.15%
2025-03-25 13:52:18,438 - training_loop - INFO - 
LatentTransformer - Step 8350/20000 - Val Loss: 1.193419 - Seq Acc: 2.60%
2025-03-25 13:53:15,922 - training_loop - INFO - 
SimpleTransformer - Step 8400/20000 - Val Loss: 0.984372 - Seq Acc: 11.45%
2025-03-25 13:53:21,534 - training_loop - INFO - 
LatentTransformer - Step 8400/20000 - Val Loss: 1.190716 - Seq Acc: 2.15%
2025-03-25 13:54:15,862 - training_loop - INFO - 
SimpleTransformer - Step 8450/20000 - Val Loss: 0.905283 - Seq Acc: 11.05%
2025-03-25 13:54:19,329 - training_loop - INFO - 
LatentTransformer - Step 8450/20000 - Val Loss: 1.200479 - Seq Acc: 2.50%
2025-03-25 13:55:16,051 - training_loop - INFO - 
SimpleTransformer - Step 8500/20000 - Val Loss: 0.930318 - Seq Acc: 10.85%
2025-03-25 13:55:22,495 - training_loop - INFO - 
LatentTransformer - Step 8500/20000 - Val Loss: 1.149281 - Seq Acc: 2.50%
2025-03-25 13:56:18,050 - training_loop - INFO - 
SimpleTransformer - Step 8550/20000 - Val Loss: 0.960300 - Seq Acc: 10.85%
2025-03-25 13:56:24,486 - training_loop - INFO - 
LatentTransformer - Step 8550/20000 - Val Loss: 1.118793 - Seq Acc: 2.60%
2025-03-25 13:57:19,874 - training_loop - INFO - 
SimpleTransformer - Step 8600/20000 - Val Loss: 1.015142 - Seq Acc: 10.40%
2025-03-25 13:57:23,200 - training_loop - INFO - 
LatentTransformer - Step 8600/20000 - Val Loss: 1.131727 - Seq Acc: 2.35%
2025-03-25 13:58:14,232 - training_loop - INFO - 
SimpleTransformer - Step 8650/20000 - Val Loss: 0.951861 - Seq Acc: 10.55%
2025-03-25 13:58:18,405 - training_loop - INFO - 
LatentTransformer - Step 8650/20000 - Val Loss: 1.129742 - Seq Acc: 2.20%
2025-03-25 13:59:13,953 - training_loop - INFO - 
SimpleTransformer - Step 8700/20000 - Val Loss: 0.956830 - Seq Acc: 10.50%
2025-03-25 13:59:20,412 - training_loop - INFO - 
LatentTransformer - Step 8700/20000 - Val Loss: 1.083164 - Seq Acc: 2.95%
2025-03-25 14:00:19,685 - training_loop - INFO - 
SimpleTransformer - Step 8750/20000 - Val Loss: 0.991975 - Seq Acc: 11.45%
2025-03-25 14:00:23,818 - training_loop - INFO - 
LatentTransformer - Step 8750/20000 - Val Loss: 1.095278 - Seq Acc: 2.80%
2025-03-25 14:01:21,792 - training_loop - INFO - 
SimpleTransformer - Step 8800/20000 - Val Loss: 1.012762 - Seq Acc: 10.95%
2025-03-25 14:01:25,117 - training_loop - INFO - 
LatentTransformer - Step 8800/20000 - Val Loss: 1.090132 - Seq Acc: 3.00%
2025-03-25 14:02:26,760 - training_loop - INFO - 
SimpleTransformer - Step 8850/20000 - Val Loss: 0.991362 - Seq Acc: 11.25%
2025-03-25 14:02:33,258 - training_loop - INFO - 
LatentTransformer - Step 8850/20000 - Val Loss: 1.069031 - Seq Acc: 2.90%
2025-03-25 14:03:29,836 - training_loop - INFO - 
SimpleTransformer - Step 8900/20000 - Val Loss: 0.962072 - Seq Acc: 11.05%
2025-03-25 14:03:35,651 - training_loop - INFO - 
LatentTransformer - Step 8900/20000 - Val Loss: 1.065031 - Seq Acc: 3.25%
2025-03-25 14:04:36,939 - training_loop - INFO - 
SimpleTransformer - Step 8950/20000 - Val Loss: 1.012166 - Seq Acc: 11.60%
2025-03-25 14:04:42,710 - training_loop - INFO - 
LatentTransformer - Step 8950/20000 - Val Loss: 1.044327 - Seq Acc: 2.90%
2025-03-25 14:05:40,515 - training_loop - INFO - 
SimpleTransformer - Step 9000/20000 - Val Loss: 1.056603 - Seq Acc: 11.00%
2025-03-25 14:05:43,819 - training_loop - INFO - 
LatentTransformer - Step 9000/20000 - Val Loss: 1.070326 - Seq Acc: 3.05%
2025-03-25 14:06:42,473 - training_loop - INFO - 
SimpleTransformer - Step 9050/20000 - Val Loss: 1.010400 - Seq Acc: 11.25%
2025-03-25 14:06:45,960 - training_loop - INFO - 
LatentTransformer - Step 9050/20000 - Val Loss: 1.049007 - Seq Acc: 3.50%
2025-03-25 14:07:46,247 - training_loop - INFO - 
SimpleTransformer - Step 9100/20000 - Val Loss: 0.983523 - Seq Acc: 11.75%
2025-03-25 14:07:52,756 - training_loop - INFO - 
LatentTransformer - Step 9100/20000 - Val Loss: 1.015887 - Seq Acc: 3.60%
2025-03-25 14:08:51,271 - training_loop - INFO - 
SimpleTransformer - Step 9150/20000 - Val Loss: 1.032484 - Seq Acc: 11.60%
2025-03-25 14:08:54,825 - training_loop - INFO - 
LatentTransformer - Step 9150/20000 - Val Loss: 1.020637 - Seq Acc: 3.75%
2025-03-25 14:09:57,727 - training_loop - INFO - 
SimpleTransformer - Step 9200/20000 - Val Loss: 1.052094 - Seq Acc: 11.55%
2025-03-25 14:10:01,091 - training_loop - INFO - 
LatentTransformer - Step 9200/20000 - Val Loss: 1.016709 - Seq Acc: 3.15%
2025-03-25 14:11:01,943 - training_loop - INFO - 
SimpleTransformer - Step 9250/20000 - Val Loss: 1.024270 - Seq Acc: 11.70%
2025-03-25 14:11:05,631 - training_loop - INFO - 
LatentTransformer - Step 9250/20000 - Val Loss: 1.028370 - Seq Acc: 3.55%
2025-03-25 14:12:07,509 - training_loop - INFO - 
SimpleTransformer - Step 9300/20000 - Val Loss: 1.019784 - Seq Acc: 11.55%
2025-03-25 14:12:14,092 - training_loop - INFO - 
LatentTransformer - Step 9300/20000 - Val Loss: 1.011209 - Seq Acc: 3.55%
2025-03-25 14:13:14,663 - training_loop - INFO - 
SimpleTransformer - Step 9350/20000 - Val Loss: 1.045023 - Seq Acc: 11.00%
2025-03-25 14:13:18,286 - training_loop - INFO - 
LatentTransformer - Step 9350/20000 - Val Loss: 1.015397 - Seq Acc: 3.75%
2025-03-25 14:14:12,627 - training_loop - INFO - 
SimpleTransformer - Step 9400/20000 - Val Loss: 1.070583 - Seq Acc: 11.80%
2025-03-25 14:14:18,196 - training_loop - INFO - 
LatentTransformer - Step 9400/20000 - Val Loss: 1.007840 - Seq Acc: 4.00%
2025-03-25 14:15:28,130 - training_loop - INFO - 
SimpleTransformer - Step 9450/20000 - Val Loss: 1.055056 - Seq Acc: 11.60%
2025-03-25 14:15:31,680 - training_loop - INFO - 
LatentTransformer - Step 9450/20000 - Val Loss: 1.044304 - Seq Acc: 3.60%
2025-03-25 14:16:32,610 - training_loop - INFO - 
SimpleTransformer - Step 9500/20000 - Val Loss: 1.033468 - Seq Acc: 11.65%
2025-03-25 14:16:36,283 - training_loop - INFO - 
LatentTransformer - Step 9500/20000 - Val Loss: 1.015294 - Seq Acc: 3.30%
2025-03-25 14:17:42,715 - training_loop - INFO - 
SimpleTransformer - Step 9550/20000 - Val Loss: 1.054755 - Seq Acc: 11.35%
2025-03-25 14:17:47,004 - training_loop - INFO - 
LatentTransformer - Step 9550/20000 - Val Loss: 1.030313 - Seq Acc: 3.75%
2025-03-25 14:18:45,625 - training_loop - INFO - 
SimpleTransformer - Step 9600/20000 - Val Loss: 1.078047 - Seq Acc: 11.80%
2025-03-25 14:18:49,076 - training_loop - INFO - 
LatentTransformer - Step 9600/20000 - Val Loss: 1.010043 - Seq Acc: 3.60%
2025-03-25 14:19:51,749 - training_loop - INFO - 
SimpleTransformer - Step 9650/20000 - Val Loss: 1.077256 - Seq Acc: 12.25%
2025-03-25 14:19:55,289 - training_loop - INFO - 
LatentTransformer - Step 9650/20000 - Val Loss: 1.023591 - Seq Acc: 4.20%
2025-03-25 14:20:57,776 - training_loop - INFO - 
SimpleTransformer - Step 9700/20000 - Val Loss: 1.058086 - Seq Acc: 12.65%
2025-03-25 14:21:04,228 - training_loop - INFO - 
LatentTransformer - Step 9700/20000 - Val Loss: 1.005488 - Seq Acc: 4.15%
2025-03-25 14:22:05,502 - training_loop - INFO - 
SimpleTransformer - Step 9750/20000 - Val Loss: 1.059279 - Seq Acc: 12.20%
2025-03-25 14:22:09,043 - training_loop - INFO - 
LatentTransformer - Step 9750/20000 - Val Loss: 1.006998 - Seq Acc: 4.15%
2025-03-25 14:23:09,327 - training_loop - INFO - 
SimpleTransformer - Step 9800/20000 - Val Loss: 1.102257 - Seq Acc: 11.20%
2025-03-25 14:23:14,978 - training_loop - INFO - 
LatentTransformer - Step 9800/20000 - Val Loss: 0.989968 - Seq Acc: 3.95%
2025-03-25 14:24:19,501 - training_loop - INFO - 
SimpleTransformer - Step 9850/20000 - Val Loss: 1.082205 - Seq Acc: 12.35%
2025-03-25 14:24:23,707 - training_loop - INFO - 
LatentTransformer - Step 9850/20000 - Val Loss: 1.010635 - Seq Acc: 4.25%
2025-03-25 14:25:29,039 - training_loop - INFO - 
SimpleTransformer - Step 9900/20000 - Val Loss: 1.080082 - Seq Acc: 12.40%
2025-03-25 14:25:33,361 - training_loop - INFO - 
LatentTransformer - Step 9900/20000 - Val Loss: 1.007449 - Seq Acc: 4.75%
2025-03-25 14:26:35,552 - training_loop - INFO - 
SimpleTransformer - Step 9950/20000 - Val Loss: 1.079640 - Seq Acc: 12.00%
2025-03-25 14:26:39,794 - training_loop - INFO - 
LatentTransformer - Step 9950/20000 - Val Loss: 1.002265 - Seq Acc: 3.80%
2025-03-25 14:27:37,908 - training_loop - INFO - 
SimpleTransformer - Step 10000/20000 - Val Loss: 1.121733 - Seq Acc: 12.00%
2025-03-25 14:27:41,219 - training_loop - INFO - 
LatentTransformer - Step 10000/20000 - Val Loss: 1.015800 - Seq Acc: 4.35%
2025-03-25 14:28:44,647 - training_loop - INFO - 
SimpleTransformer - Step 10050/20000 - Val Loss: 1.108281 - Seq Acc: 12.40%
2025-03-25 14:28:48,876 - training_loop - INFO - 
LatentTransformer - Step 10050/20000 - Val Loss: 1.008336 - Seq Acc: 4.55%
2025-03-25 14:29:53,057 - training_loop - INFO - 
SimpleTransformer - Step 10100/20000 - Val Loss: 1.094649 - Seq Acc: 11.50%
2025-03-25 14:29:57,294 - training_loop - INFO - 
LatentTransformer - Step 10100/20000 - Val Loss: 1.008923 - Seq Acc: 4.30%
2025-03-25 14:30:58,150 - training_loop - INFO - 
SimpleTransformer - Step 10150/20000 - Val Loss: 1.073246 - Seq Acc: 12.75%
2025-03-25 14:31:01,767 - training_loop - INFO - 
LatentTransformer - Step 10150/20000 - Val Loss: 1.007753 - Seq Acc: 4.30%
2025-03-25 14:32:04,077 - training_loop - INFO - 
SimpleTransformer - Step 10200/20000 - Val Loss: 1.103014 - Seq Acc: 12.55%
2025-03-25 14:32:07,500 - training_loop - INFO - 
LatentTransformer - Step 10200/20000 - Val Loss: 1.008667 - Seq Acc: 4.35%
2025-03-25 14:33:08,333 - training_loop - INFO - 
SimpleTransformer - Step 10250/20000 - Val Loss: 1.087572 - Seq Acc: 13.10%
2025-03-25 14:33:11,858 - training_loop - INFO - 
LatentTransformer - Step 10250/20000 - Val Loss: 1.017760 - Seq Acc: 4.60%
2025-03-25 14:34:14,090 - training_loop - INFO - 
SimpleTransformer - Step 10300/20000 - Val Loss: 1.097558 - Seq Acc: 12.25%
2025-03-25 14:34:18,279 - training_loop - INFO - 
LatentTransformer - Step 10300/20000 - Val Loss: 1.009270 - Seq Acc: 4.60%
2025-03-25 14:35:25,195 - training_loop - INFO - 
SimpleTransformer - Step 10350/20000 - Val Loss: 1.090387 - Seq Acc: 11.65%
2025-03-25 14:35:29,497 - training_loop - INFO - 
LatentTransformer - Step 10350/20000 - Val Loss: 1.021518 - Seq Acc: 4.50%
2025-03-25 14:36:36,638 - training_loop - INFO - 
SimpleTransformer - Step 10400/20000 - Val Loss: 1.096023 - Seq Acc: 12.05%
2025-03-25 14:36:39,915 - training_loop - INFO - 
LatentTransformer - Step 10400/20000 - Val Loss: 1.015901 - Seq Acc: 4.45%
2025-03-25 14:37:43,836 - training_loop - INFO - 
SimpleTransformer - Step 10450/20000 - Val Loss: 1.107003 - Seq Acc: 12.10%
2025-03-25 14:37:48,063 - training_loop - INFO - 
LatentTransformer - Step 10450/20000 - Val Loss: 1.041075 - Seq Acc: 4.50%
2025-03-25 14:38:57,193 - training_loop - INFO - 
SimpleTransformer - Step 10500/20000 - Val Loss: 1.101014 - Seq Acc: 12.15%
2025-03-25 14:39:01,414 - training_loop - INFO - 
LatentTransformer - Step 10500/20000 - Val Loss: 1.031078 - Seq Acc: 4.70%
2025-03-25 14:40:06,528 - training_loop - INFO - 
SimpleTransformer - Step 10550/20000 - Val Loss: 1.088906 - Seq Acc: 12.15%
2025-03-25 14:40:10,821 - training_loop - INFO - 
LatentTransformer - Step 10550/20000 - Val Loss: 1.014255 - Seq Acc: 4.55%
2025-03-25 14:41:11,680 - training_loop - INFO - 
SimpleTransformer - Step 10600/20000 - Val Loss: 1.096092 - Seq Acc: 12.45%
2025-03-25 14:41:15,066 - training_loop - INFO - 
LatentTransformer - Step 10600/20000 - Val Loss: 1.037512 - Seq Acc: 4.25%
2025-03-25 14:42:19,352 - training_loop - INFO - 
SimpleTransformer - Step 10650/20000 - Val Loss: 1.114255 - Seq Acc: 11.45%
2025-03-25 14:42:23,598 - training_loop - INFO - 
LatentTransformer - Step 10650/20000 - Val Loss: 1.033441 - Seq Acc: 4.75%
2025-03-25 14:43:22,737 - training_loop - INFO - 
SimpleTransformer - Step 10700/20000 - Val Loss: 1.100300 - Seq Acc: 11.85%
2025-03-25 14:43:26,949 - training_loop - INFO - 
LatentTransformer - Step 10700/20000 - Val Loss: 1.057398 - Seq Acc: 5.15%
2025-03-25 14:44:33,165 - training_loop - INFO - 
SimpleTransformer - Step 10750/20000 - Val Loss: 1.094120 - Seq Acc: 11.40%
2025-03-25 14:44:37,475 - training_loop - INFO - 
LatentTransformer - Step 10750/20000 - Val Loss: 1.014585 - Seq Acc: 4.70%
2025-03-25 14:45:44,893 - training_loop - INFO - 
SimpleTransformer - Step 10800/20000 - Val Loss: 1.098580 - Seq Acc: 12.25%
2025-03-25 14:45:48,201 - training_loop - INFO - 
LatentTransformer - Step 10800/20000 - Val Loss: 1.049945 - Seq Acc: 4.60%
2025-03-25 14:46:54,764 - training_loop - INFO - 
SimpleTransformer - Step 10850/20000 - Val Loss: 1.104313 - Seq Acc: 12.25%
2025-03-25 14:46:58,323 - training_loop - INFO - 
LatentTransformer - Step 10850/20000 - Val Loss: 1.051965 - Seq Acc: 4.35%
2025-03-25 14:48:04,709 - training_loop - INFO - 
SimpleTransformer - Step 10900/20000 - Val Loss: 1.104027 - Seq Acc: 11.30%
2025-03-25 14:48:08,423 - training_loop - INFO - 
LatentTransformer - Step 10900/20000 - Val Loss: 1.053098 - Seq Acc: 5.55%
2025-03-25 14:49:15,757 - training_loop - INFO - 
SimpleTransformer - Step 10950/20000 - Val Loss: 1.098949 - Seq Acc: 11.95%
2025-03-25 14:49:19,850 - training_loop - INFO - 
LatentTransformer - Step 10950/20000 - Val Loss: 1.017527 - Seq Acc: 4.70%
2025-03-25 14:50:27,174 - training_loop - INFO - 
SimpleTransformer - Step 11000/20000 - Val Loss: 1.109996 - Seq Acc: 12.00%
2025-03-25 14:50:30,534 - training_loop - INFO - 
LatentTransformer - Step 11000/20000 - Val Loss: 1.072881 - Seq Acc: 4.65%
2025-03-25 14:51:31,101 - training_loop - INFO - 
SimpleTransformer - Step 11050/20000 - Val Loss: 1.101505 - Seq Acc: 12.65%
2025-03-25 14:51:35,184 - training_loop - INFO - 
LatentTransformer - Step 11050/20000 - Val Loss: 1.048727 - Seq Acc: 4.55%
2025-03-25 14:52:37,866 - training_loop - INFO - 
SimpleTransformer - Step 11100/20000 - Val Loss: 1.099747 - Seq Acc: 12.40%
2025-03-25 14:52:41,948 - training_loop - INFO - 
LatentTransformer - Step 11100/20000 - Val Loss: 1.078964 - Seq Acc: 4.50%
2025-03-25 14:53:40,858 - training_loop - INFO - 
SimpleTransformer - Step 11150/20000 - Val Loss: 1.100567 - Seq Acc: 12.00%
2025-03-25 14:53:44,436 - training_loop - INFO - 
LatentTransformer - Step 11150/20000 - Val Loss: 1.032333 - Seq Acc: 4.95%
2025-03-25 14:54:39,492 - training_loop - INFO - 
SimpleTransformer - Step 11200/20000 - Val Loss: 1.114924 - Seq Acc: 12.10%
2025-03-25 14:54:42,814 - training_loop - INFO - 
LatentTransformer - Step 11200/20000 - Val Loss: 1.076022 - Seq Acc: 4.60%
2025-03-25 14:55:48,186 - training_loop - INFO - 
SimpleTransformer - Step 11250/20000 - Val Loss: 1.126884 - Seq Acc: 11.00%
2025-03-25 14:55:52,258 - training_loop - INFO - 
LatentTransformer - Step 11250/20000 - Val Loss: 1.048073 - Seq Acc: 5.05%
2025-03-25 14:56:56,623 - training_loop - INFO - 
SimpleTransformer - Step 11300/20000 - Val Loss: 1.086700 - Seq Acc: 12.30%
2025-03-25 14:57:00,126 - training_loop - INFO - 
LatentTransformer - Step 11300/20000 - Val Loss: 1.091436 - Seq Acc: 4.60%
2025-03-25 14:58:02,690 - training_loop - INFO - 
SimpleTransformer - Step 11350/20000 - Val Loss: 1.099459 - Seq Acc: 12.45%
2025-03-25 14:58:06,151 - training_loop - INFO - 
LatentTransformer - Step 11350/20000 - Val Loss: 1.050599 - Seq Acc: 5.65%
2025-03-25 14:59:08,760 - training_loop - INFO - 
SimpleTransformer - Step 11400/20000 - Val Loss: 1.106794 - Seq Acc: 11.60%
2025-03-25 14:59:12,049 - training_loop - INFO - 
LatentTransformer - Step 11400/20000 - Val Loss: 1.076012 - Seq Acc: 5.35%
2025-03-25 15:00:18,776 - training_loop - INFO - 
SimpleTransformer - Step 11450/20000 - Val Loss: 1.083291 - Seq Acc: 12.65%
2025-03-25 15:00:22,202 - training_loop - INFO - 
LatentTransformer - Step 11450/20000 - Val Loss: 1.062992 - Seq Acc: 5.15%
2025-03-25 15:01:17,449 - training_loop - INFO - 
SimpleTransformer - Step 11500/20000 - Val Loss: 1.096461 - Seq Acc: 12.60%
2025-03-25 15:01:21,533 - training_loop - INFO - 
LatentTransformer - Step 11500/20000 - Val Loss: 1.109352 - Seq Acc: 5.30%
2025-03-25 15:02:24,688 - training_loop - INFO - 
SimpleTransformer - Step 11550/20000 - Val Loss: 1.089124 - Seq Acc: 11.65%
2025-03-25 15:02:28,174 - training_loop - INFO - 
LatentTransformer - Step 11550/20000 - Val Loss: 1.077946 - Seq Acc: 4.85%
2025-03-25 15:03:35,146 - training_loop - INFO - 
SimpleTransformer - Step 11600/20000 - Val Loss: 1.081861 - Seq Acc: 11.85%
2025-03-25 15:03:38,581 - training_loop - INFO - 
LatentTransformer - Step 11600/20000 - Val Loss: 1.074786 - Seq Acc: 5.60%
2025-03-25 15:29:36,433 - __main__ - INFO - Using device: cuda
2025-03-25 15:29:36,433 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 15:29:36,433 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 15:29:36,433 - __main__ - INFO - Using train dataset with range 10-999
2025-03-25 15:29:37,811 - __main__ - INFO - Using val dataset with range 10-999
2025-03-25 15:29:39,793 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 15:29:39,796 - __main__ - INFO - 
Model Parameters:
2025-03-25 15:29:39,796 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 15:29:39,796 - __main__ - INFO - LatentTransformer: 138,862,091
2025-03-25 15:29:39,796 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 15:29:39,796 - __main__ - INFO - Difference: 6,509,568 parameters (4.9%)
2025-03-25 15:29:39,796 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 15:29:39,796 - training_loop - INFO - Using max_steps from args: 20000
2025-03-25 15:29:39,801 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 15:29:42,587 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 15:29:42,589 - training_loop - INFO - Created 26 evaluation examples
2025-03-25 15:29:42,592 - training_loop - INFO - Starting: Training (steps)
2025-03-25 15:31:56,296 - training_loop - INFO - 
SimpleTransformer - Step 50/20000 - Val Loss: 1.635306 - Seq Acc: 0.50%
2025-03-25 15:32:05,584 - training_loop - INFO - 
LatentTransformer - Step 50/20000 - Val Loss: 1.696002 - Seq Acc: 0.55%
2025-03-25 15:32:39,334 - training_loop - INFO - 
SimpleTransformer - Step 100/20000 - Val Loss: 1.629219 - Seq Acc: 0.50%
2025-03-25 15:32:45,041 - training_loop - INFO - 
LatentTransformer - Step 100/20000 - Val Loss: 1.691651 - Seq Acc: 0.45%
2025-03-25 15:33:19,384 - training_loop - INFO - 
SimpleTransformer - Step 150/20000 - Val Loss: 1.626537 - Seq Acc: 0.40%
2025-03-25 15:33:25,635 - training_loop - INFO - 
LatentTransformer - Step 150/20000 - Val Loss: 1.688178 - Seq Acc: 0.45%
2025-03-25 15:34:00,789 - training_loop - INFO - 
SimpleTransformer - Step 200/20000 - Val Loss: 1.622880 - Seq Acc: 0.60%
2025-03-25 15:34:06,497 - training_loop - INFO - 
LatentTransformer - Step 200/20000 - Val Loss: 1.687254 - Seq Acc: 0.60%
2025-03-25 15:34:40,202 - training_loop - INFO - 
SimpleTransformer - Step 250/20000 - Val Loss: 1.610890 - Seq Acc: 0.50%
2025-03-25 15:34:45,959 - training_loop - INFO - 
LatentTransformer - Step 250/20000 - Val Loss: 1.664923 - Seq Acc: 0.50%
2025-03-25 15:36:00,345 - training_loop - INFO - 
SimpleTransformer - Step 300/20000 - Val Loss: 1.580944 - Seq Acc: 0.55%
2025-03-25 15:36:06,225 - training_loop - INFO - 
LatentTransformer - Step 300/20000 - Val Loss: 1.615404 - Seq Acc: 0.55%
2025-03-25 15:36:40,450 - training_loop - INFO - 
SimpleTransformer - Step 350/20000 - Val Loss: 1.559047 - Seq Acc: 0.50%
2025-03-25 15:36:46,171 - training_loop - INFO - 
LatentTransformer - Step 350/20000 - Val Loss: 1.596402 - Seq Acc: 0.45%
2025-03-25 15:37:52,752 - training_loop - INFO - 
SimpleTransformer - Step 400/20000 - Val Loss: 1.527110 - Seq Acc: 0.40%
2025-03-25 15:37:58,280 - training_loop - INFO - 
LatentTransformer - Step 400/20000 - Val Loss: 1.581407 - Seq Acc: 0.65%
2025-03-25 15:38:32,879 - training_loop - INFO - 
SimpleTransformer - Step 450/20000 - Val Loss: 1.512221 - Seq Acc: 0.65%
2025-03-25 15:38:38,639 - training_loop - INFO - 
LatentTransformer - Step 450/20000 - Val Loss: 1.558749 - Seq Acc: 0.55%
2025-03-25 15:39:12,184 - training_loop - INFO - 
SimpleTransformer - Step 500/20000 - Val Loss: 1.473111 - Seq Acc: 0.65%
2025-03-25 15:39:17,963 - training_loop - INFO - 
LatentTransformer - Step 500/20000 - Val Loss: 1.526234 - Seq Acc: 0.50%
2025-03-25 15:39:51,920 - training_loop - INFO - 
SimpleTransformer - Step 550/20000 - Val Loss: 1.414028 - Seq Acc: 0.95%
2025-03-25 15:39:57,728 - training_loop - INFO - 
LatentTransformer - Step 550/20000 - Val Loss: 1.501042 - Seq Acc: 0.45%
2025-03-25 15:40:31,109 - training_loop - INFO - 
SimpleTransformer - Step 600/20000 - Val Loss: 1.375732 - Seq Acc: 0.85%
2025-03-25 15:40:36,591 - training_loop - INFO - 
LatentTransformer - Step 600/20000 - Val Loss: 1.459539 - Seq Acc: 0.70%
2025-03-25 15:41:10,098 - training_loop - INFO - 
SimpleTransformer - Step 650/20000 - Val Loss: 1.343681 - Seq Acc: 0.65%
2025-03-25 15:41:15,904 - training_loop - INFO - 
LatentTransformer - Step 650/20000 - Val Loss: 1.415869 - Seq Acc: 0.65%
2025-03-25 15:41:50,494 - training_loop - INFO - 
SimpleTransformer - Step 700/20000 - Val Loss: 1.318868 - Seq Acc: 1.40%
2025-03-25 15:41:56,244 - training_loop - INFO - 
LatentTransformer - Step 700/20000 - Val Loss: 1.376698 - Seq Acc: 0.90%
2025-03-25 15:42:32,891 - training_loop - INFO - 
SimpleTransformer - Step 750/20000 - Val Loss: 1.303421 - Seq Acc: 1.40%
2025-03-25 15:42:38,669 - training_loop - INFO - 
LatentTransformer - Step 750/20000 - Val Loss: 1.353404 - Seq Acc: 0.70%
2025-03-25 15:43:13,858 - training_loop - INFO - 
SimpleTransformer - Step 800/20000 - Val Loss: 1.288075 - Seq Acc: 1.30%
2025-03-25 15:43:19,265 - training_loop - INFO - 
LatentTransformer - Step 800/20000 - Val Loss: 1.337299 - Seq Acc: 1.15%
2025-03-25 15:43:55,177 - training_loop - INFO - 
SimpleTransformer - Step 850/20000 - Val Loss: 1.278487 - Seq Acc: 1.20%
2025-03-25 15:43:59,154 - training_loop - INFO - 
LatentTransformer - Step 850/20000 - Val Loss: 1.372871 - Seq Acc: 0.80%
2025-03-25 15:44:34,440 - training_loop - INFO - 
SimpleTransformer - Step 900/20000 - Val Loss: 1.278427 - Seq Acc: 1.30%
2025-03-25 15:44:40,279 - training_loop - INFO - 
LatentTransformer - Step 900/20000 - Val Loss: 1.331737 - Seq Acc: 0.75%
2025-03-25 15:45:15,432 - training_loop - INFO - 
SimpleTransformer - Step 950/20000 - Val Loss: 1.276970 - Seq Acc: 1.15%
2025-03-25 15:45:21,152 - training_loop - INFO - 
LatentTransformer - Step 950/20000 - Val Loss: 1.326096 - Seq Acc: 0.75%
2025-03-25 15:45:54,088 - training_loop - INFO - 
SimpleTransformer - Step 1000/20000 - Val Loss: 1.286031 - Seq Acc: 1.20%
2025-03-25 15:45:57,256 - training_loop - INFO - 
LatentTransformer - Step 1000/20000 - Val Loss: 1.354970 - Seq Acc: 1.00%
2025-03-25 15:46:33,810 - training_loop - INFO - 
SimpleTransformer - Step 1050/20000 - Val Loss: 1.275645 - Seq Acc: 0.95%
2025-03-25 15:46:39,619 - training_loop - INFO - 
LatentTransformer - Step 1050/20000 - Val Loss: 1.320661 - Seq Acc: 0.85%
2025-03-25 15:47:16,169 - training_loop - INFO - 
SimpleTransformer - Step 1100/20000 - Val Loss: 1.270461 - Seq Acc: 1.50%
2025-03-25 15:47:19,523 - training_loop - INFO - 
LatentTransformer - Step 1100/20000 - Val Loss: 1.339944 - Seq Acc: 1.00%
2025-03-25 15:47:54,459 - training_loop - INFO - 
SimpleTransformer - Step 1150/20000 - Val Loss: 1.280963 - Seq Acc: 1.10%
2025-03-25 15:47:57,802 - training_loop - INFO - 
LatentTransformer - Step 1150/20000 - Val Loss: 1.330920 - Seq Acc: 0.65%
2025-03-25 15:48:31,972 - training_loop - INFO - 
SimpleTransformer - Step 1200/20000 - Val Loss: 1.273658 - Seq Acc: 1.30%
2025-03-25 15:48:35,151 - training_loop - INFO - 
LatentTransformer - Step 1200/20000 - Val Loss: 1.343330 - Seq Acc: 0.95%
2025-03-25 15:49:14,187 - training_loop - INFO - 
SimpleTransformer - Step 1250/20000 - Val Loss: 1.266762 - Seq Acc: 1.25%
2025-03-25 15:49:17,590 - training_loop - INFO - 
LatentTransformer - Step 1250/20000 - Val Loss: 1.329632 - Seq Acc: 1.00%
2025-03-25 15:49:53,589 - training_loop - INFO - 
SimpleTransformer - Step 1300/20000 - Val Loss: 1.254049 - Seq Acc: 1.25%
2025-03-25 15:49:56,926 - training_loop - INFO - 
LatentTransformer - Step 1300/20000 - Val Loss: 1.325270 - Seq Acc: 0.95%
2025-03-25 15:50:33,420 - training_loop - INFO - 
SimpleTransformer - Step 1350/20000 - Val Loss: 1.235750 - Seq Acc: 1.35%
2025-03-25 15:50:39,233 - training_loop - INFO - 
LatentTransformer - Step 1350/20000 - Val Loss: 1.320283 - Seq Acc: 0.85%
2025-03-25 15:51:17,043 - training_loop - INFO - 
SimpleTransformer - Step 1400/20000 - Val Loss: 1.222263 - Seq Acc: 1.15%
2025-03-25 15:51:20,237 - training_loop - INFO - 
LatentTransformer - Step 1400/20000 - Val Loss: 1.379101 - Seq Acc: 0.85%
2025-03-25 15:51:56,238 - training_loop - INFO - 
SimpleTransformer - Step 1450/20000 - Val Loss: 1.228399 - Seq Acc: 1.30%
2025-03-25 15:52:01,891 - training_loop - INFO - 
LatentTransformer - Step 1450/20000 - Val Loss: 1.300076 - Seq Acc: 1.55%
2025-03-25 15:52:43,888 - training_loop - INFO - 
SimpleTransformer - Step 1500/20000 - Val Loss: 1.202087 - Seq Acc: 1.60%
2025-03-25 15:52:49,573 - training_loop - INFO - 
LatentTransformer - Step 1500/20000 - Val Loss: 1.298316 - Seq Acc: 0.90%
2025-03-25 15:53:26,585 - training_loop - INFO - 
SimpleTransformer - Step 1550/20000 - Val Loss: 1.190036 - Seq Acc: 1.50%
2025-03-25 15:53:32,310 - training_loop - INFO - 
LatentTransformer - Step 1550/20000 - Val Loss: 1.276339 - Seq Acc: 0.90%
2025-03-25 15:54:07,498 - training_loop - INFO - 
SimpleTransformer - Step 1600/20000 - Val Loss: 1.157767 - Seq Acc: 1.80%
2025-03-25 15:54:10,653 - training_loop - INFO - 
LatentTransformer - Step 1600/20000 - Val Loss: 1.284686 - Seq Acc: 1.05%
2025-03-25 15:54:45,862 - training_loop - INFO - 
SimpleTransformer - Step 1650/20000 - Val Loss: 1.145107 - Seq Acc: 1.70%
2025-03-25 15:54:49,192 - training_loop - INFO - 
LatentTransformer - Step 1650/20000 - Val Loss: 1.340702 - Seq Acc: 1.05%
2025-03-25 15:55:25,825 - training_loop - INFO - 
SimpleTransformer - Step 1700/20000 - Val Loss: 1.139125 - Seq Acc: 1.70%
2025-03-25 15:55:31,470 - training_loop - INFO - 
LatentTransformer - Step 1700/20000 - Val Loss: 1.267080 - Seq Acc: 1.35%
2025-03-25 15:56:09,344 - training_loop - INFO - 
SimpleTransformer - Step 1750/20000 - Val Loss: 1.128687 - Seq Acc: 1.60%
2025-03-25 15:56:12,654 - training_loop - INFO - 
LatentTransformer - Step 1750/20000 - Val Loss: 1.270595 - Seq Acc: 1.20%
2025-03-25 15:56:53,266 - training_loop - INFO - 
SimpleTransformer - Step 1800/20000 - Val Loss: 1.161222 - Seq Acc: 1.95%
2025-03-25 15:56:56,400 - training_loop - INFO - 
LatentTransformer - Step 1800/20000 - Val Loss: 1.381902 - Seq Acc: 0.95%
2025-03-25 15:57:33,539 - training_loop - INFO - 
SimpleTransformer - Step 1850/20000 - Val Loss: 1.216806 - Seq Acc: 2.10%
2025-03-25 15:57:36,937 - training_loop - INFO - 
LatentTransformer - Step 1850/20000 - Val Loss: 1.275378 - Seq Acc: 1.45%
2025-03-25 15:58:17,875 - training_loop - INFO - 
SimpleTransformer - Step 1900/20000 - Val Loss: 1.106291 - Seq Acc: 2.00%
2025-03-25 15:58:23,680 - training_loop - INFO - 
LatentTransformer - Step 1900/20000 - Val Loss: 1.266854 - Seq Acc: 1.45%
2025-03-25 15:59:02,619 - training_loop - INFO - 
SimpleTransformer - Step 1950/20000 - Val Loss: 1.098927 - Seq Acc: 2.15%
2025-03-25 15:59:08,539 - training_loop - INFO - 
LatentTransformer - Step 1950/20000 - Val Loss: 1.266393 - Seq Acc: 1.00%
2025-03-25 15:59:44,840 - training_loop - INFO - 
SimpleTransformer - Step 2000/20000 - Val Loss: 1.087406 - Seq Acc: 2.80%
2025-03-25 15:59:48,126 - training_loop - INFO - 
LatentTransformer - Step 2000/20000 - Val Loss: 1.273617 - Seq Acc: 1.55%
2025-03-25 16:00:27,165 - training_loop - INFO - 
SimpleTransformer - Step 2050/20000 - Val Loss: 1.078417 - Seq Acc: 2.50%
2025-03-25 16:00:33,696 - training_loop - INFO - 
LatentTransformer - Step 2050/20000 - Val Loss: 1.261244 - Seq Acc: 1.40%
2025-03-25 16:01:18,406 - training_loop - INFO - 
SimpleTransformer - Step 2100/20000 - Val Loss: 1.072985 - Seq Acc: 2.45%
2025-03-25 16:01:21,838 - training_loop - INFO - 
LatentTransformer - Step 2100/20000 - Val Loss: 1.266064 - Seq Acc: 1.25%
2025-03-25 16:02:00,739 - training_loop - INFO - 
SimpleTransformer - Step 2150/20000 - Val Loss: 1.070372 - Seq Acc: 2.35%
2025-03-25 16:02:06,537 - training_loop - INFO - 
LatentTransformer - Step 2150/20000 - Val Loss: 1.260841 - Seq Acc: 1.20%
2025-03-25 16:02:43,570 - training_loop - INFO - 
SimpleTransformer - Step 2200/20000 - Val Loss: 1.083035 - Seq Acc: 2.55%
2025-03-25 16:02:49,121 - training_loop - INFO - 
LatentTransformer - Step 2200/20000 - Val Loss: 1.260251 - Seq Acc: 1.25%
2025-03-25 16:03:28,747 - training_loop - INFO - 
SimpleTransformer - Step 2250/20000 - Val Loss: 1.066569 - Seq Acc: 2.20%
2025-03-25 16:03:34,530 - training_loop - INFO - 
LatentTransformer - Step 2250/20000 - Val Loss: 1.259264 - Seq Acc: 1.35%
2025-03-25 16:04:14,118 - training_loop - INFO - 
SimpleTransformer - Step 2300/20000 - Val Loss: 1.088843 - Seq Acc: 2.25%
2025-03-25 16:04:17,555 - training_loop - INFO - 
LatentTransformer - Step 2300/20000 - Val Loss: 1.259286 - Seq Acc: 1.15%
2025-03-25 16:04:54,844 - training_loop - INFO - 
SimpleTransformer - Step 2350/20000 - Val Loss: 1.067195 - Seq Acc: 2.40%
2025-03-25 16:04:58,385 - training_loop - INFO - 
LatentTransformer - Step 2350/20000 - Val Loss: 1.261030 - Seq Acc: 1.30%
2025-03-25 16:05:40,938 - training_loop - INFO - 
SimpleTransformer - Step 2400/20000 - Val Loss: 1.229309 - Seq Acc: 2.00%
2025-03-25 16:05:44,218 - training_loop - INFO - 
LatentTransformer - Step 2400/20000 - Val Loss: 1.262104 - Seq Acc: 1.00%
2025-03-25 16:06:21,558 - training_loop - INFO - 
SimpleTransformer - Step 2450/20000 - Val Loss: 1.073027 - Seq Acc: 2.20%
2025-03-25 16:06:27,412 - training_loop - INFO - 
LatentTransformer - Step 2450/20000 - Val Loss: 1.256416 - Seq Acc: 1.50%
2025-03-25 16:07:06,114 - training_loop - INFO - 
SimpleTransformer - Step 2500/20000 - Val Loss: 1.068608 - Seq Acc: 2.75%
2025-03-25 16:07:09,566 - training_loop - INFO - 
LatentTransformer - Step 2500/20000 - Val Loss: 1.269786 - Seq Acc: 1.25%
2025-03-25 16:07:51,217 - training_loop - INFO - 
SimpleTransformer - Step 2550/20000 - Val Loss: 1.062251 - Seq Acc: 2.30%
2025-03-25 16:07:54,680 - training_loop - INFO - 
LatentTransformer - Step 2550/20000 - Val Loss: 1.269491 - Seq Acc: 1.15%
2025-03-25 16:08:33,459 - training_loop - INFO - 
SimpleTransformer - Step 2600/20000 - Val Loss: 1.059229 - Seq Acc: 3.05%
2025-03-25 16:08:36,601 - training_loop - INFO - 
LatentTransformer - Step 2600/20000 - Val Loss: 1.273041 - Seq Acc: 1.00%
2025-03-25 16:09:17,910 - training_loop - INFO - 
SimpleTransformer - Step 2650/20000 - Val Loss: 1.061155 - Seq Acc: 2.85%
2025-03-25 16:09:21,352 - training_loop - INFO - 
LatentTransformer - Step 2650/20000 - Val Loss: 1.259697 - Seq Acc: 1.10%
2025-03-25 16:10:03,603 - training_loop - INFO - 
SimpleTransformer - Step 2700/20000 - Val Loss: 1.046628 - Seq Acc: 3.05%
2025-03-25 16:10:07,018 - training_loop - INFO - 
LatentTransformer - Step 2700/20000 - Val Loss: 1.264822 - Seq Acc: 1.25%
2025-03-25 16:10:51,427 - training_loop - INFO - 
SimpleTransformer - Step 2750/20000 - Val Loss: 1.057718 - Seq Acc: 2.65%
2025-03-25 16:10:54,845 - training_loop - INFO - 
LatentTransformer - Step 2750/20000 - Val Loss: 1.266316 - Seq Acc: 1.15%
2025-03-25 16:11:33,378 - training_loop - INFO - 
SimpleTransformer - Step 2800/20000 - Val Loss: 1.052129 - Seq Acc: 2.90%
2025-03-25 16:11:36,576 - training_loop - INFO - 
LatentTransformer - Step 2800/20000 - Val Loss: 1.263265 - Seq Acc: 1.20%
2025-03-25 16:12:19,114 - training_loop - INFO - 
SimpleTransformer - Step 2850/20000 - Val Loss: 1.045533 - Seq Acc: 2.90%
2025-03-25 16:12:23,231 - training_loop - INFO - 
LatentTransformer - Step 2850/20000 - Val Loss: 1.275790 - Seq Acc: 1.20%
2025-03-25 16:13:05,727 - training_loop - INFO - 
SimpleTransformer - Step 2900/20000 - Val Loss: 1.087014 - Seq Acc: 2.75%
2025-03-25 16:13:09,128 - training_loop - INFO - 
LatentTransformer - Step 2900/20000 - Val Loss: 1.259343 - Seq Acc: 1.15%
2025-03-25 16:13:52,067 - training_loop - INFO - 
SimpleTransformer - Step 2950/20000 - Val Loss: 1.037067 - Seq Acc: 3.05%
2025-03-25 16:13:55,497 - training_loop - INFO - 
LatentTransformer - Step 2950/20000 - Val Loss: 1.260620 - Seq Acc: 1.25%
2025-03-25 16:14:39,553 - training_loop - INFO - 
SimpleTransformer - Step 3000/20000 - Val Loss: 1.041251 - Seq Acc: 2.80%
2025-03-25 16:14:42,827 - training_loop - INFO - 
LatentTransformer - Step 3000/20000 - Val Loss: 1.268686 - Seq Acc: 1.25%
2025-03-25 16:15:23,314 - training_loop - INFO - 
SimpleTransformer - Step 3050/20000 - Val Loss: 1.043830 - Seq Acc: 3.30%
2025-03-25 16:15:26,800 - training_loop - INFO - 
LatentTransformer - Step 3050/20000 - Val Loss: 1.266505 - Seq Acc: 1.25%
2025-03-25 16:16:08,980 - training_loop - INFO - 
SimpleTransformer - Step 3100/20000 - Val Loss: 1.030046 - Seq Acc: 2.70%
2025-03-25 16:16:12,512 - training_loop - INFO - 
LatentTransformer - Step 3100/20000 - Val Loss: 1.264073 - Seq Acc: 1.40%
2025-03-25 16:16:54,604 - training_loop - INFO - 
SimpleTransformer - Step 3150/20000 - Val Loss: 1.027931 - Seq Acc: 3.10%
2025-03-25 16:16:57,967 - training_loop - INFO - 
LatentTransformer - Step 3150/20000 - Val Loss: 1.273140 - Seq Acc: 1.15%
2025-03-25 16:17:44,363 - training_loop - INFO - 
SimpleTransformer - Step 3200/20000 - Val Loss: 1.021868 - Seq Acc: 3.45%
2025-03-25 16:17:47,655 - training_loop - INFO - 
LatentTransformer - Step 3200/20000 - Val Loss: 1.276872 - Seq Acc: 1.15%
2025-03-25 16:18:36,508 - training_loop - INFO - 
SimpleTransformer - Step 3250/20000 - Val Loss: 1.020867 - Seq Acc: 3.60%
2025-03-25 16:18:40,721 - training_loop - INFO - 
LatentTransformer - Step 3250/20000 - Val Loss: 1.265270 - Seq Acc: 1.25%
2025-03-25 16:19:29,231 - training_loop - INFO - 
SimpleTransformer - Step 3300/20000 - Val Loss: 1.009306 - Seq Acc: 3.35%
2025-03-25 16:19:32,783 - training_loop - INFO - 
LatentTransformer - Step 3300/20000 - Val Loss: 1.258546 - Seq Acc: 1.40%
2025-03-25 16:20:16,038 - training_loop - INFO - 
SimpleTransformer - Step 3350/20000 - Val Loss: 1.005547 - Seq Acc: 3.35%
2025-03-25 16:20:19,554 - training_loop - INFO - 
LatentTransformer - Step 3350/20000 - Val Loss: 1.262154 - Seq Acc: 0.90%
2025-03-25 16:21:02,322 - training_loop - INFO - 
SimpleTransformer - Step 3400/20000 - Val Loss: 1.009276 - Seq Acc: 4.10%
2025-03-25 16:21:05,775 - training_loop - INFO - 
LatentTransformer - Step 3400/20000 - Val Loss: 1.260565 - Seq Acc: 1.45%
2025-03-25 16:21:49,194 - training_loop - INFO - 
SimpleTransformer - Step 3450/20000 - Val Loss: 0.995906 - Seq Acc: 3.75%
2025-03-25 16:21:53,402 - training_loop - INFO - 
LatentTransformer - Step 3450/20000 - Val Loss: 1.264753 - Seq Acc: 1.25%
2025-03-25 16:22:35,507 - training_loop - INFO - 
SimpleTransformer - Step 3500/20000 - Val Loss: 0.993253 - Seq Acc: 4.00%
2025-03-25 16:22:39,099 - training_loop - INFO - 
LatentTransformer - Step 3500/20000 - Val Loss: 1.257065 - Seq Acc: 1.50%
2025-03-25 16:23:25,590 - training_loop - INFO - 
SimpleTransformer - Step 3550/20000 - Val Loss: 0.980365 - Seq Acc: 4.20%
2025-03-25 16:23:29,163 - training_loop - INFO - 
LatentTransformer - Step 3550/20000 - Val Loss: 1.264091 - Seq Acc: 1.10%
2025-03-25 16:24:12,244 - training_loop - INFO - 
SimpleTransformer - Step 3600/20000 - Val Loss: 0.973938 - Seq Acc: 3.40%
2025-03-25 16:24:15,601 - training_loop - INFO - 
LatentTransformer - Step 3600/20000 - Val Loss: 1.265137 - Seq Acc: 1.00%
2025-03-25 16:24:59,427 - training_loop - INFO - 
SimpleTransformer - Step 3650/20000 - Val Loss: 0.968803 - Seq Acc: 3.60%
2025-03-25 16:25:02,949 - training_loop - INFO - 
LatentTransformer - Step 3650/20000 - Val Loss: 1.266977 - Seq Acc: 1.50%
2025-03-25 16:25:45,897 - training_loop - INFO - 
SimpleTransformer - Step 3700/20000 - Val Loss: 0.947843 - Seq Acc: 4.40%
2025-03-25 16:25:49,409 - training_loop - INFO - 
LatentTransformer - Step 3700/20000 - Val Loss: 1.257063 - Seq Acc: 1.35%
2025-03-25 16:26:37,234 - training_loop - INFO - 
SimpleTransformer - Step 3750/20000 - Val Loss: 0.937615 - Seq Acc: 4.90%
2025-03-25 16:26:40,799 - training_loop - INFO - 
LatentTransformer - Step 3750/20000 - Val Loss: 1.256443 - Seq Acc: 1.10%
2025-03-25 16:27:20,874 - training_loop - INFO - 
SimpleTransformer - Step 3800/20000 - Val Loss: 0.939833 - Seq Acc: 4.15%
2025-03-25 16:27:24,275 - training_loop - INFO - 
LatentTransformer - Step 3800/20000 - Val Loss: 1.262031 - Seq Acc: 1.25%
2025-03-25 16:28:10,300 - training_loop - INFO - 
SimpleTransformer - Step 3850/20000 - Val Loss: 0.919479 - Seq Acc: 4.80%
2025-03-25 16:28:16,230 - training_loop - INFO - 
LatentTransformer - Step 3850/20000 - Val Loss: 1.255605 - Seq Acc: 1.35%
2025-03-25 16:29:03,622 - training_loop - INFO - 
SimpleTransformer - Step 3900/20000 - Val Loss: 0.902774 - Seq Acc: 5.20%
2025-03-25 16:29:07,241 - training_loop - INFO - 
LatentTransformer - Step 3900/20000 - Val Loss: 1.259910 - Seq Acc: 1.35%
2025-03-25 16:29:50,973 - training_loop - INFO - 
SimpleTransformer - Step 3950/20000 - Val Loss: 0.914461 - Seq Acc: 5.25%
2025-03-25 16:29:54,610 - training_loop - INFO - 
LatentTransformer - Step 3950/20000 - Val Loss: 1.260971 - Seq Acc: 1.25%
2025-03-25 16:30:38,018 - training_loop - INFO - 
SimpleTransformer - Step 4000/20000 - Val Loss: 0.904689 - Seq Acc: 4.65%
2025-03-25 16:30:43,866 - training_loop - INFO - 
LatentTransformer - Step 4000/20000 - Val Loss: 1.254584 - Seq Acc: 1.05%
2025-03-25 16:31:34,857 - training_loop - INFO - 
SimpleTransformer - Step 4050/20000 - Val Loss: 0.888261 - Seq Acc: 5.45%
2025-03-25 16:31:39,182 - training_loop - INFO - 
LatentTransformer - Step 4050/20000 - Val Loss: 1.260325 - Seq Acc: 1.35%
2025-03-25 16:32:26,141 - training_loop - INFO - 
SimpleTransformer - Step 4100/20000 - Val Loss: 0.888579 - Seq Acc: 4.85%
2025-03-25 16:32:29,721 - training_loop - INFO - 
LatentTransformer - Step 4100/20000 - Val Loss: 1.256013 - Seq Acc: 1.50%
2025-03-25 16:33:16,485 - training_loop - INFO - 
SimpleTransformer - Step 4150/20000 - Val Loss: 0.870575 - Seq Acc: 5.65%
2025-03-25 16:33:20,079 - training_loop - INFO - 
LatentTransformer - Step 4150/20000 - Val Loss: 1.260595 - Seq Acc: 1.10%
2025-03-25 16:34:05,497 - training_loop - INFO - 
SimpleTransformer - Step 4200/20000 - Val Loss: 0.882822 - Seq Acc: 5.10%
2025-03-25 16:34:08,924 - training_loop - INFO - 
LatentTransformer - Step 4200/20000 - Val Loss: 1.257481 - Seq Acc: 1.40%
2025-03-25 16:34:55,790 - training_loop - INFO - 
SimpleTransformer - Step 4250/20000 - Val Loss: 0.910912 - Seq Acc: 4.50%
2025-03-25 16:34:59,971 - training_loop - INFO - 
LatentTransformer - Step 4250/20000 - Val Loss: 1.297240 - Seq Acc: 1.30%
2025-03-25 16:35:43,610 - training_loop - INFO - 
SimpleTransformer - Step 4300/20000 - Val Loss: 0.878067 - Seq Acc: 5.50%
2025-03-25 16:35:47,273 - training_loop - INFO - 
LatentTransformer - Step 4300/20000 - Val Loss: 1.263418 - Seq Acc: 0.95%
2025-03-25 16:36:35,761 - training_loop - INFO - 
SimpleTransformer - Step 4350/20000 - Val Loss: 0.867563 - Seq Acc: 5.40%
2025-03-25 16:36:42,913 - training_loop - INFO - 
LatentTransformer - Step 4350/20000 - Val Loss: 1.250348 - Seq Acc: 1.15%
2025-03-25 16:37:32,231 - training_loop - INFO - 
SimpleTransformer - Step 4400/20000 - Val Loss: 0.867192 - Seq Acc: 5.15%
2025-03-25 16:37:35,688 - training_loop - INFO - 
LatentTransformer - Step 4400/20000 - Val Loss: 1.255775 - Seq Acc: 1.50%
2025-03-25 16:38:27,952 - training_loop - INFO - 
SimpleTransformer - Step 4450/20000 - Val Loss: 0.875509 - Seq Acc: 5.60%
2025-03-25 16:38:31,780 - training_loop - INFO - 
LatentTransformer - Step 4450/20000 - Val Loss: 1.251284 - Seq Acc: 1.20%
2025-03-25 16:39:19,310 - training_loop - INFO - 
SimpleTransformer - Step 4500/20000 - Val Loss: 0.867474 - Seq Acc: 5.35%
2025-03-25 16:39:23,156 - training_loop - INFO - 
LatentTransformer - Step 4500/20000 - Val Loss: 1.251576 - Seq Acc: 1.05%
2025-03-25 16:40:14,687 - training_loop - INFO - 
SimpleTransformer - Step 4550/20000 - Val Loss: 0.864409 - Seq Acc: 6.00%
2025-03-25 16:40:21,459 - training_loop - INFO - 
LatentTransformer - Step 4550/20000 - Val Loss: 1.248041 - Seq Acc: 1.70%
2025-03-25 16:41:08,584 - training_loop - INFO - 
SimpleTransformer - Step 4600/20000 - Val Loss: 0.869225 - Seq Acc: 5.70%
2025-03-25 16:41:12,140 - training_loop - INFO - 
LatentTransformer - Step 4600/20000 - Val Loss: 1.259372 - Seq Acc: 1.80%
2025-03-25 16:42:02,621 - training_loop - INFO - 
SimpleTransformer - Step 4650/20000 - Val Loss: 0.869253 - Seq Acc: 5.30%
2025-03-25 16:42:09,847 - training_loop - INFO - 
LatentTransformer - Step 4650/20000 - Val Loss: 1.243158 - Seq Acc: 1.25%
2025-03-25 16:42:55,268 - training_loop - INFO - 
SimpleTransformer - Step 4700/20000 - Val Loss: 0.868739 - Seq Acc: 5.45%
2025-03-25 16:42:58,898 - training_loop - INFO - 
LatentTransformer - Step 4700/20000 - Val Loss: 1.244314 - Seq Acc: 1.35%
2025-03-25 16:43:45,418 - training_loop - INFO - 
SimpleTransformer - Step 4750/20000 - Val Loss: 0.866710 - Seq Acc: 5.60%
2025-03-25 16:43:51,558 - training_loop - INFO - 
LatentTransformer - Step 4750/20000 - Val Loss: 1.239711 - Seq Acc: 1.55%
2025-03-25 16:44:33,165 - training_loop - INFO - 
SimpleTransformer - Step 4800/20000 - Val Loss: 0.865655 - Seq Acc: 5.45%
2025-03-25 16:44:36,562 - training_loop - INFO - 
LatentTransformer - Step 4800/20000 - Val Loss: 1.242347 - Seq Acc: 1.60%
2025-03-25 16:45:23,747 - training_loop - INFO - 
SimpleTransformer - Step 4850/20000 - Val Loss: 0.866347 - Seq Acc: 5.00%
2025-03-25 16:45:27,364 - training_loop - INFO - 
LatentTransformer - Step 4850/20000 - Val Loss: 1.244488 - Seq Acc: 1.35%
2025-03-25 16:46:06,585 - training_loop - INFO - 
SimpleTransformer - Step 4900/20000 - Val Loss: 0.864889 - Seq Acc: 5.30%
2025-03-25 16:46:12,770 - training_loop - INFO - 
LatentTransformer - Step 4900/20000 - Val Loss: 1.228235 - Seq Acc: 1.35%
2025-03-25 16:47:02,691 - training_loop - INFO - 
SimpleTransformer - Step 4950/20000 - Val Loss: 0.859270 - Seq Acc: 5.85%
2025-03-25 16:47:07,020 - training_loop - INFO - 
LatentTransformer - Step 4950/20000 - Val Loss: 1.235936 - Seq Acc: 1.35%
2025-03-25 16:47:55,217 - training_loop - INFO - 
SimpleTransformer - Step 5000/20000 - Val Loss: 0.863369 - Seq Acc: 5.40%
2025-03-25 16:47:58,685 - training_loop - INFO - 
LatentTransformer - Step 5000/20000 - Val Loss: 1.244850 - Seq Acc: 1.25%
2025-03-25 16:48:42,704 - training_loop - INFO - 
SimpleTransformer - Step 5050/20000 - Val Loss: 0.865605 - Seq Acc: 5.40%
2025-03-25 16:48:46,292 - training_loop - INFO - 
LatentTransformer - Step 5050/20000 - Val Loss: 1.244535 - Seq Acc: 1.45%
2025-03-25 16:49:30,613 - training_loop - INFO - 
SimpleTransformer - Step 5100/20000 - Val Loss: 0.862708 - Seq Acc: 5.70%
2025-03-25 16:49:34,138 - training_loop - INFO - 
LatentTransformer - Step 5100/20000 - Val Loss: 1.242361 - Seq Acc: 1.50%
2025-03-25 16:50:24,055 - training_loop - INFO - 
SimpleTransformer - Step 5150/20000 - Val Loss: 0.862355 - Seq Acc: 5.85%
2025-03-25 16:50:27,911 - training_loop - INFO - 
LatentTransformer - Step 5150/20000 - Val Loss: 1.241961 - Seq Acc: 1.80%
2025-03-25 16:51:17,508 - training_loop - INFO - 
SimpleTransformer - Step 5200/20000 - Val Loss: 0.859990 - Seq Acc: 5.35%
2025-03-25 16:51:20,764 - training_loop - INFO - 
LatentTransformer - Step 5200/20000 - Val Loss: 1.251670 - Seq Acc: 1.40%
2025-03-25 16:52:07,428 - training_loop - INFO - 
SimpleTransformer - Step 5250/20000 - Val Loss: 0.871968 - Seq Acc: 5.40%
2025-03-25 16:52:10,937 - training_loop - INFO - 
LatentTransformer - Step 5250/20000 - Val Loss: 1.241515 - Seq Acc: 1.50%
2025-03-25 16:52:56,316 - training_loop - INFO - 
SimpleTransformer - Step 5300/20000 - Val Loss: 0.859198 - Seq Acc: 5.55%
2025-03-25 16:52:59,793 - training_loop - INFO - 
LatentTransformer - Step 5300/20000 - Val Loss: 1.246461 - Seq Acc: 1.65%
2025-03-25 16:53:49,427 - training_loop - INFO - 
SimpleTransformer - Step 5350/20000 - Val Loss: 0.852518 - Seq Acc: 5.95%
2025-03-25 16:53:53,104 - training_loop - INFO - 
LatentTransformer - Step 5350/20000 - Val Loss: 1.235844 - Seq Acc: 1.50%
2025-03-25 16:54:42,795 - training_loop - INFO - 
SimpleTransformer - Step 5400/20000 - Val Loss: 0.855307 - Seq Acc: 5.60%
2025-03-25 16:54:46,214 - training_loop - INFO - 
LatentTransformer - Step 5400/20000 - Val Loss: 1.240341 - Seq Acc: 1.50%
2025-03-25 16:55:31,135 - training_loop - INFO - 
SimpleTransformer - Step 5450/20000 - Val Loss: 0.864845 - Seq Acc: 5.70%
2025-03-25 16:55:34,702 - training_loop - INFO - 
LatentTransformer - Step 5450/20000 - Val Loss: 1.235845 - Seq Acc: 1.45%
2025-03-25 16:56:29,525 - training_loop - INFO - 
SimpleTransformer - Step 5500/20000 - Val Loss: 0.850728 - Seq Acc: 5.95%
2025-03-25 16:56:33,202 - training_loop - INFO - 
LatentTransformer - Step 5500/20000 - Val Loss: 1.228996 - Seq Acc: 1.70%
2025-03-25 16:57:23,259 - training_loop - INFO - 
SimpleTransformer - Step 5550/20000 - Val Loss: 0.842698 - Seq Acc: 6.00%
2025-03-25 16:57:29,893 - training_loop - INFO - 
LatentTransformer - Step 5550/20000 - Val Loss: 1.227900 - Seq Acc: 1.90%
2025-03-25 16:58:14,970 - training_loop - INFO - 
SimpleTransformer - Step 5600/20000 - Val Loss: 0.843446 - Seq Acc: 5.85%
2025-03-25 16:58:18,342 - training_loop - INFO - 
LatentTransformer - Step 5600/20000 - Val Loss: 1.229998 - Seq Acc: 1.95%
2025-03-25 16:59:10,901 - training_loop - INFO - 
SimpleTransformer - Step 5650/20000 - Val Loss: 0.857216 - Seq Acc: 5.95%
2025-03-25 16:59:14,863 - training_loop - INFO - 
LatentTransformer - Step 5650/20000 - Val Loss: 1.236731 - Seq Acc: 2.10%
2025-03-25 17:00:05,005 - training_loop - INFO - 
SimpleTransformer - Step 5700/20000 - Val Loss: 0.830450 - Seq Acc: 6.65%
2025-03-25 17:00:09,419 - training_loop - INFO - 
LatentTransformer - Step 5700/20000 - Val Loss: 1.232143 - Seq Acc: 1.90%
2025-03-25 17:01:03,624 - training_loop - INFO - 
SimpleTransformer - Step 5750/20000 - Val Loss: 0.817358 - Seq Acc: 7.30%
2025-03-25 17:01:09,870 - training_loop - INFO - 
LatentTransformer - Step 5750/20000 - Val Loss: 1.225318 - Seq Acc: 1.50%
2025-03-25 17:02:02,232 - training_loop - INFO - 
SimpleTransformer - Step 5800/20000 - Val Loss: 0.801737 - Seq Acc: 7.20%
2025-03-25 17:02:05,833 - training_loop - INFO - 
LatentTransformer - Step 5800/20000 - Val Loss: 1.226028 - Seq Acc: 1.75%
2025-03-25 17:02:57,550 - training_loop - INFO - 
SimpleTransformer - Step 5850/20000 - Val Loss: 0.832087 - Seq Acc: 6.75%
2025-03-25 17:03:01,063 - training_loop - INFO - 
LatentTransformer - Step 5850/20000 - Val Loss: 1.238002 - Seq Acc: 2.00%
2025-03-25 17:03:52,177 - training_loop - INFO - 
SimpleTransformer - Step 5900/20000 - Val Loss: 0.795619 - Seq Acc: 7.50%
2025-03-25 17:03:58,058 - training_loop - INFO - 
LatentTransformer - Step 5900/20000 - Val Loss: 1.218922 - Seq Acc: 2.30%
2025-03-25 17:04:51,123 - training_loop - INFO - 
SimpleTransformer - Step 5950/20000 - Val Loss: 0.767443 - Seq Acc: 8.35%
2025-03-25 17:04:57,611 - training_loop - INFO - 
LatentTransformer - Step 5950/20000 - Val Loss: 1.212086 - Seq Acc: 1.50%
2025-03-25 17:05:53,589 - training_loop - INFO - 
SimpleTransformer - Step 6000/20000 - Val Loss: 0.766612 - Seq Acc: 9.10%
2025-03-25 17:05:57,120 - training_loop - INFO - 
LatentTransformer - Step 6000/20000 - Val Loss: 1.232002 - Seq Acc: 1.10%
2025-03-25 17:06:52,864 - training_loop - INFO - 
SimpleTransformer - Step 6050/20000 - Val Loss: 0.757765 - Seq Acc: 8.45%
2025-03-25 17:06:57,090 - training_loop - INFO - 
LatentTransformer - Step 6050/20000 - Val Loss: 1.219884 - Seq Acc: 1.85%
2025-03-25 17:07:52,230 - training_loop - INFO - 
SimpleTransformer - Step 6100/20000 - Val Loss: 0.738261 - Seq Acc: 9.30%
2025-03-25 17:07:55,755 - training_loop - INFO - 
LatentTransformer - Step 6100/20000 - Val Loss: 1.253175 - Seq Acc: 1.60%
2025-03-25 17:08:48,134 - training_loop - INFO - 
SimpleTransformer - Step 6150/20000 - Val Loss: 0.730004 - Seq Acc: 10.25%
2025-03-25 17:08:51,629 - training_loop - INFO - 
LatentTransformer - Step 6150/20000 - Val Loss: 1.231319 - Seq Acc: 1.90%
2025-03-25 17:09:47,945 - training_loop - INFO - 
SimpleTransformer - Step 6200/20000 - Val Loss: 0.716110 - Seq Acc: 10.00%
2025-03-25 17:09:52,287 - training_loop - INFO - 
LatentTransformer - Step 6200/20000 - Val Loss: 1.220802 - Seq Acc: 1.40%
2025-03-25 17:10:40,193 - training_loop - INFO - 
SimpleTransformer - Step 6250/20000 - Val Loss: 0.727425 - Seq Acc: 9.90%
2025-03-25 17:10:47,038 - training_loop - INFO - 
LatentTransformer - Step 6250/20000 - Val Loss: 1.211883 - Seq Acc: 1.65%
2025-03-25 17:11:40,447 - training_loop - INFO - 
SimpleTransformer - Step 6300/20000 - Val Loss: 0.735104 - Seq Acc: 10.00%
2025-03-25 17:11:45,025 - training_loop - INFO - 
LatentTransformer - Step 6300/20000 - Val Loss: 1.218943 - Seq Acc: 1.90%
2025-03-25 17:12:41,016 - training_loop - INFO - 
SimpleTransformer - Step 6350/20000 - Val Loss: 0.707042 - Seq Acc: 9.90%
2025-03-25 17:12:47,157 - training_loop - INFO - 
LatentTransformer - Step 6350/20000 - Val Loss: 1.204479 - Seq Acc: 1.95%
2025-03-25 17:13:34,399 - training_loop - INFO - 
SimpleTransformer - Step 6400/20000 - Val Loss: 0.732526 - Seq Acc: 8.30%
2025-03-25 17:13:37,780 - training_loop - INFO - 
LatentTransformer - Step 6400/20000 - Val Loss: 1.213020 - Seq Acc: 1.60%
2025-03-25 17:14:28,597 - training_loop - INFO - 
SimpleTransformer - Step 6450/20000 - Val Loss: 0.727797 - Seq Acc: 9.35%
2025-03-25 17:14:32,133 - training_loop - INFO - 
LatentTransformer - Step 6450/20000 - Val Loss: 1.206344 - Seq Acc: 1.90%
2025-03-25 17:15:18,587 - training_loop - INFO - 
SimpleTransformer - Step 6500/20000 - Val Loss: 0.724123 - Seq Acc: 11.35%
2025-03-25 17:15:24,547 - training_loop - INFO - 
LatentTransformer - Step 6500/20000 - Val Loss: 1.204157 - Seq Acc: 1.85%
2025-03-25 17:16:16,381 - training_loop - INFO - 
SimpleTransformer - Step 6550/20000 - Val Loss: 0.697588 - Seq Acc: 10.85%
2025-03-25 17:16:20,094 - training_loop - INFO - 
LatentTransformer - Step 6550/20000 - Val Loss: 1.215306 - Seq Acc: 2.00%
2025-03-25 17:17:19,731 - training_loop - INFO - 
SimpleTransformer - Step 6600/20000 - Val Loss: 0.708240 - Seq Acc: 10.70%
2025-03-25 17:17:23,190 - training_loop - INFO - 
LatentTransformer - Step 6600/20000 - Val Loss: 1.205036 - Seq Acc: 1.55%
2025-03-25 17:18:13,499 - training_loop - INFO - 
SimpleTransformer - Step 6650/20000 - Val Loss: 0.723809 - Seq Acc: 9.65%
2025-03-25 17:18:20,280 - training_loop - INFO - 
LatentTransformer - Step 6650/20000 - Val Loss: 1.200338 - Seq Acc: 1.85%
2025-03-25 17:19:11,325 - training_loop - INFO - 
SimpleTransformer - Step 6700/20000 - Val Loss: 0.729648 - Seq Acc: 9.95%
2025-03-25 17:19:15,168 - training_loop - INFO - 
LatentTransformer - Step 6700/20000 - Val Loss: 1.204279 - Seq Acc: 2.05%
2025-03-25 17:20:06,099 - training_loop - INFO - 
SimpleTransformer - Step 6750/20000 - Val Loss: 0.696941 - Seq Acc: 11.00%
2025-03-25 17:20:11,986 - training_loop - INFO - 
LatentTransformer - Step 6750/20000 - Val Loss: 1.188327 - Seq Acc: 2.00%
2025-03-25 17:20:59,607 - training_loop - INFO - 
SimpleTransformer - Step 6800/20000 - Val Loss: 0.721748 - Seq Acc: 10.50%
2025-03-25 17:21:05,541 - training_loop - INFO - 
LatentTransformer - Step 6800/20000 - Val Loss: 1.185933 - Seq Acc: 2.25%
2025-03-25 17:21:58,030 - training_loop - INFO - 
SimpleTransformer - Step 6850/20000 - Val Loss: 0.729755 - Seq Acc: 10.35%
2025-03-25 17:22:01,713 - training_loop - INFO - 
LatentTransformer - Step 6850/20000 - Val Loss: 1.186398 - Seq Acc: 2.35%
2025-03-25 17:22:48,066 - training_loop - INFO - 
SimpleTransformer - Step 6900/20000 - Val Loss: 0.717695 - Seq Acc: 11.20%
2025-03-25 17:22:51,595 - training_loop - INFO - 
LatentTransformer - Step 6900/20000 - Val Loss: 1.186513 - Seq Acc: 2.05%
2025-03-25 17:23:45,628 - training_loop - INFO - 
SimpleTransformer - Step 6950/20000 - Val Loss: 0.697966 - Seq Acc: 11.25%
2025-03-25 17:23:49,125 - training_loop - INFO - 
LatentTransformer - Step 6950/20000 - Val Loss: 1.185966 - Seq Acc: 1.65%
2025-03-25 17:24:40,650 - training_loop - INFO - 
SimpleTransformer - Step 7000/20000 - Val Loss: 0.706251 - Seq Acc: 10.65%
2025-03-25 17:24:43,900 - training_loop - INFO - 
LatentTransformer - Step 7000/20000 - Val Loss: 1.188786 - Seq Acc: 1.45%
2025-03-25 17:25:36,028 - training_loop - INFO - 
SimpleTransformer - Step 7050/20000 - Val Loss: 0.719075 - Seq Acc: 11.25%
2025-03-25 17:25:42,616 - training_loop - INFO - 
LatentTransformer - Step 7050/20000 - Val Loss: 1.182270 - Seq Acc: 2.20%
2025-03-25 17:26:36,356 - training_loop - INFO - 
SimpleTransformer - Step 7100/20000 - Val Loss: 0.725726 - Seq Acc: 10.90%
2025-03-25 17:26:40,723 - training_loop - INFO - 
LatentTransformer - Step 7100/20000 - Val Loss: 1.192304 - Seq Acc: 2.25%
2025-03-25 17:27:31,094 - training_loop - INFO - 
SimpleTransformer - Step 7150/20000 - Val Loss: 0.707565 - Seq Acc: 11.50%
2025-03-25 17:27:35,502 - training_loop - INFO - 
LatentTransformer - Step 7150/20000 - Val Loss: 1.186614 - Seq Acc: 1.90%
2025-03-25 17:28:28,437 - training_loop - INFO - 
SimpleTransformer - Step 7200/20000 - Val Loss: 0.724486 - Seq Acc: 10.90%
2025-03-25 17:28:31,809 - training_loop - INFO - 
LatentTransformer - Step 7200/20000 - Val Loss: 1.225671 - Seq Acc: 1.85%
2025-03-25 17:29:28,347 - training_loop - INFO - 
SimpleTransformer - Step 7250/20000 - Val Loss: 0.732667 - Seq Acc: 11.20%
2025-03-25 17:29:32,800 - training_loop - INFO - 
LatentTransformer - Step 7250/20000 - Val Loss: 1.185714 - Seq Acc: 2.25%
2025-03-25 17:30:31,324 - training_loop - INFO - 
SimpleTransformer - Step 7300/20000 - Val Loss: 0.787015 - Seq Acc: 10.20%
2025-03-25 17:30:35,676 - training_loop - INFO - 
LatentTransformer - Step 7300/20000 - Val Loss: 1.183591 - Seq Acc: 2.60%
2025-03-25 17:31:19,891 - training_loop - INFO - 
SimpleTransformer - Step 7350/20000 - Val Loss: 0.736286 - Seq Acc: 10.70%
2025-03-25 17:31:24,024 - training_loop - INFO - 
LatentTransformer - Step 7350/20000 - Val Loss: 1.187061 - Seq Acc: 2.30%
2025-03-25 17:32:17,349 - training_loop - INFO - 
SimpleTransformer - Step 7400/20000 - Val Loss: 0.721468 - Seq Acc: 11.30%
2025-03-25 17:32:20,646 - training_loop - INFO - 
LatentTransformer - Step 7400/20000 - Val Loss: 1.206657 - Seq Acc: 1.65%
2025-03-25 17:33:09,889 - training_loop - INFO - 
SimpleTransformer - Step 7450/20000 - Val Loss: 0.726425 - Seq Acc: 11.30%
2025-03-25 17:33:14,044 - training_loop - INFO - 
LatentTransformer - Step 7450/20000 - Val Loss: 1.191994 - Seq Acc: 2.65%
2025-03-25 17:34:11,931 - training_loop - INFO - 
SimpleTransformer - Step 7500/20000 - Val Loss: 0.756454 - Seq Acc: 11.10%
2025-03-25 17:34:15,502 - training_loop - INFO - 
LatentTransformer - Step 7500/20000 - Val Loss: 1.183289 - Seq Acc: 2.50%
2025-03-25 17:35:09,939 - training_loop - INFO - 
SimpleTransformer - Step 7550/20000 - Val Loss: 0.744123 - Seq Acc: 11.20%
2025-03-25 17:35:16,706 - training_loop - INFO - 
LatentTransformer - Step 7550/20000 - Val Loss: 1.180414 - Seq Acc: 2.10%
2025-03-25 17:36:12,382 - training_loop - INFO - 
SimpleTransformer - Step 7600/20000 - Val Loss: 0.732467 - Seq Acc: 11.60%
2025-03-25 17:36:13,574 - __main__ - INFO - Using device: cuda
2025-03-25 17:36:13,574 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 17:36:13,575 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 17:36:15,906 - training_loop - INFO - 
LatentTransformer - Step 7600/20000 - Val Loss: 1.197034 - Seq Acc: 2.00%
2025-03-25 17:37:09,454 - training_loop - INFO - 
SimpleTransformer - Step 7650/20000 - Val Loss: 0.750427 - Seq Acc: 11.00%
2025-03-25 17:37:13,101 - training_loop - INFO - 
LatentTransformer - Step 7650/20000 - Val Loss: 1.188275 - Seq Acc: 2.05%
2025-03-25 17:38:14,422 - training_loop - INFO - 
SimpleTransformer - Step 7700/20000 - Val Loss: 0.766349 - Seq Acc: 11.20%
2025-03-25 17:38:18,114 - training_loop - INFO - 
LatentTransformer - Step 7700/20000 - Val Loss: 1.183845 - Seq Acc: 2.45%
2025-03-25 17:39:13,077 - training_loop - INFO - 
SimpleTransformer - Step 7750/20000 - Val Loss: 0.751626 - Seq Acc: 11.60%
2025-03-25 17:39:13,263 - __main__ - INFO - Using device: cuda
2025-03-25 17:39:13,263 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 17:39:13,263 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 17:39:13,264 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 17:39:13,265 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 17:39:13,707 - __main__ - INFO - 
Model Parameters:
2025-03-25 17:39:13,707 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 17:39:13,707 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 17:39:13,708 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 17:39:13,708 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 17:39:13,708 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 17:39:13,708 - run_management - INFO - Registered run: 20250325-173913_d64_l2_n4
2025-03-25 17:39:13,708 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-173913_d64_l2_n4
2025-03-25 17:39:13,709 - training_loop - INFO - Using max_steps from args: 20
2025-03-25 17:39:13,711 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 17:39:15,950 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 17:39:15,952 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 17:39:15,954 - training_loop - INFO - Starting: Training (steps)
2025-03-25 17:39:20,493 - training_loop - INFO - 
LatentTransformer - Step 7750/20000 - Val Loss: 1.176999 - Seq Acc: 2.10%
2025-03-25 17:40:22,685 - training_loop - INFO - 
SimpleTransformer - Step 7800/20000 - Val Loss: 0.729619 - Seq Acc: 12.15%
2025-03-25 17:40:27,496 - training_loop - INFO - 
LatentTransformer - Step 7800/20000 - Val Loss: 1.188331 - Seq Acc: 2.55%
2025-03-25 17:40:28,115 - training_loop - INFO - 
SimpleTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:28,392 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 0.000000)
2025-03-25 17:40:32,867 - training_loop - INFO - 
LatentTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:33,165 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 0.000000)
2025-03-25 17:40:33,823 - training_loop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:34,185 - training_loop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:34,781 - training_loop - INFO - 
SimpleTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:35,091 - training_loop - INFO - 
LatentTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:35,615 - training_loop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:35,896 - training_loop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:40:36,365 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 17:40:36,365 - training_loop - INFO - Steps completed: 20/20
2025-03-25 17:40:36,365 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:40:36,365 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:40:36,365 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:40:36,365 - training_loop - INFO - Final digit accuracy: 9.09%
2025-03-25 17:40:36,365 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 17:40:36,365 - training_loop - INFO - Steps completed: 20/20
2025-03-25 17:40:36,365 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:40:36,365 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:40:36,365 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:40:36,366 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-25 17:40:36,368 - __main__ - INFO - 
Final Comparison:
2025-03-25 17:40:36,368 - __main__ - INFO - ==================================================
2025-03-25 17:40:36,368 - __main__ - INFO - Training time: 80.41s
2025-03-25 17:40:36,368 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 17:40:36,368 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-25 17:40:36,368 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 17:40:36,368 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 17:40:36,368 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-173913_d64_l2_n4
2025-03-25 17:40:41,638 - __main__ - INFO - Using device: cuda
2025-03-25 17:40:41,639 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 17:40:41,639 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 17:40:41,639 - __main__ - INFO - Attempting to resume from run ID: 20250325-173913_d64_l2_n4
2025-03-25 17:40:41,639 - __main__ - INFO - Found run: 20250325-173913_d64_l2_n4
2025-03-25 17:40:41,639 - __main__ - INFO - Using d_model=64 from run config (override 768)
2025-03-25 17:40:41,639 - __main__ - INFO - Using num_layers=2 from run config (override 8)
2025-03-25 17:40:41,640 - __main__ - INFO - Using num_latent=4 from run config (override 16)
2025-03-25 17:40:41,640 - __main__ - INFO - Using min_digits=1 from run config (override 3)
2025-03-25 17:40:41,640 - __main__ - INFO - Using max_digits=1 from run config (override 2)
2025-03-25 17:40:41,640 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 17:40:41,641 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 17:40:41,904 - __main__ - INFO - Enabling gradient checkpointing for memory efficiency
2025-03-25 17:40:41,905 - __main__ - INFO - 
Model Parameters:
2025-03-25 17:40:41,905 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 17:40:41,905 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 17:40:41,905 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 17:40:41,905 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 17:40:41,905 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 17:40:41,906 - run_management - INFO - Registered run: 20250325-174041_d64_l2_n4
2025-03-25 17:40:41,906 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-174041_d64_l2_n4
2025-03-25 17:40:41,906 - __main__ - INFO - Using checkpoint paths from run 20250325-173913_d64_l2_n4
2025-03-25 17:40:42,002 - __main__ - INFO - Resuming from step 20/20000
2025-03-25 17:40:42,002 - training_loop - INFO - Using max_steps from args: 20000
2025-03-25 17:40:42,004 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 17:40:43,935 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 17:40:43,937 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 17:40:43,940 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 17:40:43,949 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 17:40:43,949 - training_loop - INFO - Starting: Training (steps)
2025-03-25 17:41:22,770 - training_loop - INFO - 
SimpleTransformer - Step 50/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:25,113 - training_loop - INFO - 
LatentTransformer - Step 50/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:28,389 - training_loop - INFO - 
SimpleTransformer - Step 100/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:28,671 - training_loop - INFO - 
LatentTransformer - Step 100/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:32,016 - training_loop - INFO - 
SimpleTransformer - Step 150/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:32,301 - training_loop - INFO - 
LatentTransformer - Step 150/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:35,610 - training_loop - INFO - 
SimpleTransformer - Step 200/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:35,894 - training_loop - INFO - 
LatentTransformer - Step 200/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:39,203 - training_loop - INFO - 
SimpleTransformer - Step 250/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:39,423 - training_loop - INFO - 
LatentTransformer - Step 250/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:42,001 - training_loop - INFO - 
SimpleTransformer - Step 7850/20000 - Val Loss: 0.752088 - Seq Acc: 11.20%
2025-03-25 17:41:42,316 - training_loop - INFO - 
SimpleTransformer - Step 300/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:42,683 - training_loop - INFO - 
LatentTransformer - Step 300/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:45,854 - training_loop - INFO - 
SimpleTransformer - Step 350/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:46,168 - training_loop - INFO - 
LatentTransformer - Step 350/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:47,731 - training_loop - INFO - 
LatentTransformer - Step 7850/20000 - Val Loss: 1.195663 - Seq Acc: 2.60%
2025-03-25 17:41:49,131 - training_loop - INFO - 
SimpleTransformer - Step 400/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:49,436 - training_loop - INFO - 
LatentTransformer - Step 400/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:52,889 - training_loop - INFO - 
SimpleTransformer - Step 450/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:53,181 - training_loop - INFO - 
LatentTransformer - Step 450/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:56,491 - training_loop - INFO - 
SimpleTransformer - Step 500/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:56,788 - training_loop - INFO - 
LatentTransformer - Step 500/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:41:59,989 - training_loop - INFO - 
SimpleTransformer - Step 550/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:42:00,287 - training_loop - INFO - 
LatentTransformer - Step 550/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:42:03,596 - training_loop - INFO - 
SimpleTransformer - Step 600/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:42:03,878 - training_loop - INFO - 
LatentTransformer - Step 600/20000 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:42:52,807 - training_loop - INFO - 
SimpleTransformer - Step 7900/20000 - Val Loss: 0.781725 - Seq Acc: 11.35%
2025-03-25 17:42:56,527 - training_loop - INFO - 
LatentTransformer - Step 7900/20000 - Val Loss: 1.188501 - Seq Acc: 2.55%
2025-03-25 17:43:49,826 - __main__ - INFO - Using device: cuda
2025-03-25 17:43:49,827 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 17:43:49,827 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 17:43:49,828 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 17:43:49,830 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 17:43:50,023 - __main__ - INFO - 
Model Parameters:
2025-03-25 17:43:50,023 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 17:43:50,024 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 17:43:50,024 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 17:43:50,024 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 17:43:50,024 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 17:43:50,025 - run_management - INFO - Registered run: 20250325-174350_d64_l2_n4
2025-03-25 17:43:50,026 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-174350_d64_l2_n4
2025-03-25 17:43:50,026 - training_loop - INFO - Using max_steps from args: 20
2025-03-25 17:43:50,029 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 17:43:51,734 - training_loop - INFO - 
SimpleTransformer - Step 7950/20000 - Val Loss: 0.761133 - Seq Acc: 11.75%
2025-03-25 17:43:51,963 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 17:43:51,969 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 17:43:51,970 - training_loop - INFO - Starting: Training (steps)
2025-03-25 17:43:55,487 - training_loop - INFO - 
LatentTransformer - Step 7950/20000 - Val Loss: 1.183969 - Seq Acc: 2.25%
2025-03-25 17:44:11,940 - training_loop - INFO - 
SimpleTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:11,972 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 0.000000)
2025-03-25 17:44:13,941 - training_loop - INFO - 
LatentTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:13,983 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 0.000000)
2025-03-25 17:44:14,599 - training_loop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:14,888 - training_loop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:15,410 - training_loop - INFO - 
SimpleTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:15,737 - training_loop - INFO - 
LatentTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:16,360 - training_loop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:16,681 - training_loop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:17,140 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 17:44:17,140 - training_loop - INFO - Steps completed: 20/20
2025-03-25 17:44:17,140 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:44:17,140 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:44:17,140 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:44:17,140 - training_loop - INFO - Final digit accuracy: 9.09%
2025-03-25 17:44:17,140 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 17:44:17,140 - training_loop - INFO - Steps completed: 20/20
2025-03-25 17:44:17,141 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:44:17,141 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:44:17,141 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:44:17,141 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-25 17:44:17,143 - __main__ - INFO - 
Final Comparison:
2025-03-25 17:44:17,143 - __main__ - INFO - ==================================================
2025-03-25 17:44:17,143 - __main__ - INFO - Training time: 25.18s
2025-03-25 17:44:17,143 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 17:44:17,144 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-25 17:44:17,144 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 17:44:17,144 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 17:44:17,144 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-174350_d64_l2_n4
2025-03-25 17:44:21,275 - __main__ - INFO - Using device: cuda
2025-03-25 17:44:21,275 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 17:44:21,275 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 17:44:21,275 - __main__ - INFO - Attempting to resume from run ID: 20250325-174350_d64_l2_n4
2025-03-25 17:44:21,276 - __main__ - INFO - Found run: 20250325-174350_d64_l2_n4
2025-03-25 17:44:21,276 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 17:44:21,277 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 17:44:21,502 - __main__ - INFO - 
Model Parameters:
2025-03-25 17:44:21,502 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 17:44:21,502 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 17:44:21,503 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 17:44:21,503 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 17:44:21,503 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 17:44:21,503 - run_management - INFO - Registered run: 20250325-174421_d64_l2_n4
2025-03-25 17:44:21,503 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-174421_d64_l2_n4
2025-03-25 17:44:21,504 - __main__ - INFO - Using checkpoint paths from run 20250325-174350_d64_l2_n4
2025-03-25 17:44:21,599 - __main__ - INFO - Found config in simple_checkpoint
2025-03-25 17:44:21,600 - __main__ - INFO - Found config in latent_checkpoint
2025-03-25 17:44:21,605 - __main__ - INFO - Resuming from step 20/40
2025-03-25 17:44:21,605 - training_loop - INFO - Using max_steps from args: 40
2025-03-25 17:44:21,607 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 17:44:23,553 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 17:44:23,556 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 17:44:23,559 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 17:44:23,567 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 17:44:23,568 - training_loop - INFO - Starting: Training (steps)
2025-03-25 17:44:45,077 - training_loop - INFO - 
SimpleTransformer - Step 25/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:47,218 - training_loop - INFO - 
LatentTransformer - Step 25/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:47,747 - training_loop - INFO - 
SimpleTransformer - Step 30/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:48,009 - training_loop - INFO - 
LatentTransformer - Step 30/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:48,539 - training_loop - INFO - 
SimpleTransformer - Step 35/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:48,846 - training_loop - INFO - 
LatentTransformer - Step 35/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:49,268 - training_loop - INFO - 
SimpleTransformer - Step 40/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:49,466 - training_loop - INFO - 
LatentTransformer - Step 40/40 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:44:49,858 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 17:44:49,859 - training_loop - INFO - Steps completed: 40/40
2025-03-25 17:44:49,859 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:44:49,859 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:44:49,859 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:44:49,859 - training_loop - INFO - Final digit accuracy: 0.00%
2025-03-25 17:44:49,859 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 17:44:49,859 - training_loop - INFO - Steps completed: 40/40
2025-03-25 17:44:49,859 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:44:49,859 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:44:49,859 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:44:49,859 - training_loop - INFO - Final digit accuracy: 0.00%
2025-03-25 17:44:49,863 - __main__ - INFO - 
Final Comparison:
2025-03-25 17:44:49,863 - __main__ - INFO - ==================================================
2025-03-25 17:44:49,863 - __main__ - INFO - Training time: 26.30s
2025-03-25 17:44:49,863 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 17:44:49,863 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,507 parameters
2025-03-25 17:44:49,864 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 17:44:49,864 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 17:44:49,864 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-174421_d64_l2_n4
2025-03-25 17:44:51,996 - training_loop - INFO - 
SimpleTransformer - Step 8000/20000 - Val Loss: 0.747570 - Seq Acc: 11.45%
2025-03-25 17:44:55,525 - training_loop - INFO - 
LatentTransformer - Step 8000/20000 - Val Loss: 1.206889 - Seq Acc: 1.70%
2025-03-25 17:45:53,068 - training_loop - INFO - 
SimpleTransformer - Step 8050/20000 - Val Loss: 0.781265 - Seq Acc: 11.70%
2025-03-25 17:45:56,716 - training_loop - INFO - 
LatentTransformer - Step 8050/20000 - Val Loss: 1.201178 - Seq Acc: 2.35%
2025-03-25 17:46:55,059 - training_loop - INFO - 
SimpleTransformer - Step 8100/20000 - Val Loss: 0.826774 - Seq Acc: 11.00%
2025-03-25 17:46:59,325 - training_loop - INFO - 
LatentTransformer - Step 8100/20000 - Val Loss: 1.197598 - Seq Acc: 2.75%
2025-03-25 17:47:53,690 - training_loop - INFO - 
SimpleTransformer - Step 8150/20000 - Val Loss: 0.787787 - Seq Acc: 11.20%
2025-03-25 17:47:57,234 - training_loop - INFO - 
LatentTransformer - Step 8150/20000 - Val Loss: 1.181399 - Seq Acc: 2.40%
2025-03-25 17:48:50,704 - training_loop - INFO - 
SimpleTransformer - Step 8200/20000 - Val Loss: 0.760584 - Seq Acc: 11.10%
2025-03-25 17:48:54,221 - training_loop - INFO - 
LatentTransformer - Step 8200/20000 - Val Loss: 1.187221 - Seq Acc: 2.50%
2025-03-25 17:49:55,079 - training_loop - INFO - 
SimpleTransformer - Step 8250/20000 - Val Loss: 0.768088 - Seq Acc: 12.00%
2025-03-25 17:49:58,702 - training_loop - INFO - 
LatentTransformer - Step 8250/20000 - Val Loss: 1.206558 - Seq Acc: 2.25%
2025-03-25 17:50:54,476 - training_loop - INFO - 
SimpleTransformer - Step 8300/20000 - Val Loss: 0.822571 - Seq Acc: 11.55%
2025-03-25 17:51:00,945 - training_loop - INFO - 
LatentTransformer - Step 8300/20000 - Val Loss: 1.168195 - Seq Acc: 2.35%
2025-03-25 17:51:58,159 - training_loop - INFO - 
SimpleTransformer - Step 8350/20000 - Val Loss: 0.811577 - Seq Acc: 11.35%
2025-03-25 17:52:01,714 - training_loop - INFO - 
LatentTransformer - Step 8350/20000 - Val Loss: 1.175812 - Seq Acc: 2.40%
2025-03-25 17:53:00,005 - training_loop - INFO - 
SimpleTransformer - Step 8400/20000 - Val Loss: 0.790891 - Seq Acc: 12.15%
2025-03-25 17:53:03,461 - training_loop - INFO - 
LatentTransformer - Step 8400/20000 - Val Loss: 1.171576 - Seq Acc: 2.40%
2025-03-25 17:53:44,592 - __main__ - INFO - Using device: cuda
2025-03-25 17:53:44,593 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 17:53:44,593 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 17:53:44,593 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 17:53:44,594 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 17:53:44,852 - __main__ - INFO - 
Model Parameters:
2025-03-25 17:53:44,853 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 17:53:44,853 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 17:53:44,853 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 17:53:44,853 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 17:53:44,853 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 17:53:44,854 - run_management - INFO - Registered run: 20250325-175344_d64_l2_n4
2025-03-25 17:53:44,854 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-175344_d64_l2_n4
2025-03-25 17:53:44,854 - training_loop - INFO - Using max_steps from args: 20
2025-03-25 17:53:44,856 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 17:53:46,942 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 17:53:46,948 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 17:53:46,949 - training_loop - INFO - Starting: Training (steps)
2025-03-25 17:53:59,079 - training_loop - INFO - 
SimpleTransformer - Step 8450/20000 - Val Loss: 0.798845 - Seq Acc: 11.10%
2025-03-25 17:54:05,325 - training_loop - INFO - 
LatentTransformer - Step 8450/20000 - Val Loss: 1.158292 - Seq Acc: 2.45%
2025-03-25 17:54:07,848 - training_loop - INFO - 
SimpleTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:07,891 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 0.000000)
2025-03-25 17:54:09,851 - training_loop - INFO - 
LatentTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:10,135 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 0.000000)
2025-03-25 17:54:10,772 - training_loop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:11,090 - training_loop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:11,644 - training_loop - INFO - 
SimpleTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:11,943 - training_loop - INFO - 
LatentTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:12,486 - training_loop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:12,788 - training_loop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 17:54:13,277 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 17:54:13,278 - training_loop - INFO - Steps completed: 20/20
2025-03-25 17:54:13,278 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:54:13,278 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:54:13,278 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:54:13,278 - training_loop - INFO - Final digit accuracy: 9.09%
2025-03-25 17:54:13,278 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 17:54:13,278 - training_loop - INFO - Steps completed: 20/20
2025-03-25 17:54:13,278 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:54:13,278 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:54:13,278 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:54:13,278 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-25 17:54:13,281 - __main__ - INFO - 
Final Comparison:
2025-03-25 17:54:13,281 - __main__ - INFO - ==================================================
2025-03-25 17:54:13,281 - __main__ - INFO - Training time: 26.34s
2025-03-25 17:54:13,281 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 17:54:13,281 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-25 17:54:13,281 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 17:54:13,281 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 17:54:13,281 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-175344_d64_l2_n4
2025-03-25 17:54:17,573 - __main__ - INFO - Using device: cuda
2025-03-25 17:54:17,573 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 17:54:17,573 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 17:54:17,573 - __main__ - INFO - Attempting to resume from run ID: 20250325-175344_d64_l2_n4
2025-03-25 17:54:17,573 - __main__ - INFO - Found run: 20250325-175344_d64_l2_n4
2025-03-25 17:54:17,574 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 17:54:17,575 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 17:54:17,808 - __main__ - INFO - 
Model Parameters:
2025-03-25 17:54:17,808 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 17:54:17,808 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 17:54:17,809 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 17:54:17,809 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 17:54:17,809 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 17:54:17,810 - run_management - INFO - Registered run: 20250325-175417_d64_l2_n4
2025-03-25 17:54:17,810 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-175417_d64_l2_n4
2025-03-25 17:54:17,810 - __main__ - INFO - Using checkpoint paths from run 20250325-175344_d64_l2_n4
2025-03-25 17:54:18,171 - __main__ - INFO - Found config in simple_checkpoint
2025-03-25 17:54:18,171 - __main__ - INFO - Found config in latent_checkpoint
2025-03-25 17:54:18,176 - __main__ - INFO - Resuming from step 20/40
2025-03-25 17:54:18,176 - training_loop - INFO - Using max_steps from args: 40
2025-03-25 17:54:18,178 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 17:54:20,027 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 17:54:20,030 - training_loop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 17:54:20,030 - training_loop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 17:54:20,030 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 17:54:20,033 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 17:54:20,033 - training_loop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 17:54:20,034 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 17:54:20,041 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 17:54:20,042 - training_loop - INFO - Starting: Training (steps)
2025-03-25 17:54:24,464 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 17:54:27,623 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 17:54:27,661 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 17:54:27,702 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 17:54:27,738 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 17:54:27,783 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 17:54:32,790 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 17:54:38,839 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 17:54:38,879 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 17:54:38,918 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 17:54:38,955 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 17:54:38,996 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 17:54:39,031 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 17:54:39,072 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 17:54:39,110 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 17:54:39,158 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 17:54:39,193 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 17:54:39,242 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 17:54:39,274 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 17:54:39,319 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 17:54:39,356 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 17:54:39,402 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 17:54:39,442 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 17:54:39,483 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 17:54:39,517 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 17:54:39,556 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 17:54:39,591 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 17:54:39,636 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 17:54:39,671 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 17:54:39,712 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 17:54:39,753 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 17:54:39,795 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 17:54:39,830 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 17:54:39,866 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 17:54:39,902 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 17:54:39,943 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 17:54:39,979 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 17:54:40,020 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 17:54:40,054 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 17:54:40,092 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 17:54:43,443 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 17:54:43,443 - training_loop - INFO - Steps completed: 20/40
2025-03-25 17:54:43,443 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:54:43,443 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:54:43,444 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:54:43,444 - training_loop - INFO - Final digit accuracy: 9.09%
2025-03-25 17:54:43,444 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 17:54:43,444 - training_loop - INFO - Steps completed: 20/40
2025-03-25 17:54:43,444 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 17:54:43,444 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 17:54:43,444 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 17:54:43,444 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-25 17:54:43,447 - __main__ - INFO - 
Final Comparison:
2025-03-25 17:54:43,447 - __main__ - INFO - ==================================================
2025-03-25 17:54:43,447 - __main__ - INFO - Training time: 23.41s
2025-03-25 17:54:43,448 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 17:54:43,448 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-25 17:54:43,448 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 17:54:43,448 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 17:54:43,448 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-175417_d64_l2_n4
2025-03-25 17:55:04,542 - training_loop - INFO - 
SimpleTransformer - Step 8500/20000 - Val Loss: 0.811720 - Seq Acc: 13.05%
2025-03-25 17:55:10,783 - training_loop - INFO - 
LatentTransformer - Step 8500/20000 - Val Loss: 1.128316 - Seq Acc: 2.95%
2025-03-25 17:56:08,177 - training_loop - INFO - 
SimpleTransformer - Step 8550/20000 - Val Loss: 0.831962 - Seq Acc: 11.65%
2025-03-25 17:56:14,739 - training_loop - INFO - 
LatentTransformer - Step 8550/20000 - Val Loss: 1.120431 - Seq Acc: 2.85%
2025-03-25 17:57:11,370 - training_loop - INFO - 
SimpleTransformer - Step 8600/20000 - Val Loss: 0.797427 - Seq Acc: 12.30%
2025-03-25 17:57:17,033 - training_loop - INFO - 
LatentTransformer - Step 8600/20000 - Val Loss: 1.109717 - Seq Acc: 2.85%
2025-03-25 17:58:08,086 - training_loop - INFO - 
SimpleTransformer - Step 8650/20000 - Val Loss: 0.805759 - Seq Acc: 11.55%
2025-03-25 17:58:12,580 - training_loop - INFO - 
LatentTransformer - Step 8650/20000 - Val Loss: 1.115082 - Seq Acc: 3.05%
2025-03-25 17:59:12,587 - training_loop - INFO - 
SimpleTransformer - Step 8700/20000 - Val Loss: 0.862036 - Seq Acc: 13.00%
2025-03-25 17:59:19,285 - training_loop - INFO - 
LatentTransformer - Step 8700/20000 - Val Loss: 1.107477 - Seq Acc: 2.95%
2025-03-25 18:00:19,659 - training_loop - INFO - 
SimpleTransformer - Step 8750/20000 - Val Loss: 0.861224 - Seq Acc: 11.70%
2025-03-25 18:00:23,820 - training_loop - INFO - 
LatentTransformer - Step 8750/20000 - Val Loss: 1.113482 - Seq Acc: 3.05%
2025-03-25 18:01:23,202 - training_loop - INFO - 
SimpleTransformer - Step 8800/20000 - Val Loss: 0.817255 - Seq Acc: 12.10%
2025-03-25 18:01:26,631 - training_loop - INFO - 
LatentTransformer - Step 8800/20000 - Val Loss: 1.108687 - Seq Acc: 3.30%
2025-03-25 18:02:31,780 - training_loop - INFO - 
SimpleTransformer - Step 8850/20000 - Val Loss: 0.836564 - Seq Acc: 11.80%
2025-03-25 18:02:38,620 - training_loop - INFO - 
LatentTransformer - Step 8850/20000 - Val Loss: 1.103305 - Seq Acc: 3.40%
2025-03-25 18:03:36,273 - training_loop - INFO - 
SimpleTransformer - Step 8900/20000 - Val Loss: 0.882912 - Seq Acc: 12.25%
2025-03-25 18:03:39,932 - training_loop - INFO - 
LatentTransformer - Step 8900/20000 - Val Loss: 1.113292 - Seq Acc: 3.45%
2025-03-25 18:04:42,666 - training_loop - INFO - 
SimpleTransformer - Step 8950/20000 - Val Loss: 0.867195 - Seq Acc: 12.35%
2025-03-25 18:04:46,257 - training_loop - INFO - 
LatentTransformer - Step 8950/20000 - Val Loss: 1.122926 - Seq Acc: 3.10%
2025-03-25 18:05:44,917 - training_loop - INFO - 
SimpleTransformer - Step 9000/20000 - Val Loss: 0.856462 - Seq Acc: 11.45%
2025-03-25 18:05:50,838 - training_loop - INFO - 
LatentTransformer - Step 9000/20000 - Val Loss: 1.101949 - Seq Acc: 2.85%
2025-03-25 18:06:50,745 - training_loop - INFO - 
SimpleTransformer - Step 9050/20000 - Val Loss: 0.848896 - Seq Acc: 11.95%
2025-03-25 18:06:54,430 - training_loop - INFO - 
LatentTransformer - Step 9050/20000 - Val Loss: 1.116666 - Seq Acc: 3.60%
2025-03-25 18:07:57,073 - training_loop - INFO - 
SimpleTransformer - Step 9100/20000 - Val Loss: 0.884304 - Seq Acc: 12.65%
2025-03-25 18:08:01,344 - training_loop - INFO - 
LatentTransformer - Step 9100/20000 - Val Loss: 1.111447 - Seq Acc: 3.55%
2025-03-25 18:09:03,675 - training_loop - INFO - 
SimpleTransformer - Step 9150/20000 - Val Loss: 0.891114 - Seq Acc: 12.60%
2025-03-25 18:09:10,167 - training_loop - INFO - 
LatentTransformer - Step 9150/20000 - Val Loss: 1.083242 - Seq Acc: 3.40%
2025-03-25 18:09:12,855 - __main__ - INFO - Using device: cuda
2025-03-25 18:09:12,855 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:09:12,855 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:09:12,856 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 18:09:12,857 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 18:09:13,095 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:09:13,095 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:09:13,096 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 18:09:13,096 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:09:13,096 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 18:09:13,096 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:09:13,097 - run_management - INFO - Registered run: 20250325-180913_d64_l2_n4
2025-03-25 18:09:13,097 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-180913_d64_l2_n4
2025-03-25 18:09:13,098 - training_loop - INFO - Using max_steps from args: 20
2025-03-25 18:09:13,100 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 18:09:14,974 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 18:09:14,980 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 18:09:14,981 - training_loop - INFO - Starting: Training (steps)
2025-03-25 18:09:32,970 - __main__ - INFO - Using device: cuda
2025-03-25 18:09:32,971 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:09:32,971 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:09:32,971 - __main__ - INFO - Attempting to resume from run ID: 20250325-180913_d64_l2_n4
2025-03-25 18:09:32,971 - __main__ - INFO - Found run: 20250325-180913_d64_l2_n4
2025-03-25 18:09:32,972 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 18:09:32,973 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 18:09:33,192 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:09:33,192 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:09:33,192 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 18:09:33,192 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:09:33,192 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 18:09:33,192 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:09:33,194 - run_management - INFO - Registered run: 20250325-180933_d64_l2_n4
2025-03-25 18:09:33,194 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-180933_d64_l2_n4
2025-03-25 18:09:33,195 - __main__ - INFO - Using checkpoint paths from run 20250325-180913_d64_l2_n4
2025-03-25 18:10:13,591 - training_loop - INFO - 
SimpleTransformer - Step 9200/20000 - Val Loss: 0.865332 - Seq Acc: 12.45%
2025-03-25 18:10:17,389 - training_loop - INFO - 
LatentTransformer - Step 9200/20000 - Val Loss: 1.119596 - Seq Acc: 2.95%
2025-03-25 18:11:06,078 - __main__ - INFO - Using device: cuda
2025-03-25 18:11:06,078 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:11:06,078 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:11:06,079 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 18:11:06,080 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 18:11:06,323 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:11:06,324 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:11:06,324 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 18:11:06,324 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:11:06,324 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 18:11:06,324 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:11:06,325 - run_management - INFO - Registered run: 20250325-181106_d64_l2_n4
2025-03-25 18:11:06,325 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-181106_d64_l2_n4
2025-03-25 18:11:06,325 - training_loop - INFO - Using max_steps from args: 20
2025-03-25 18:11:06,327 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 18:11:08,230 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 18:11:08,236 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 18:11:08,237 - training_loop - INFO - Starting: Training (steps)
2025-03-25 18:11:18,846 - training_loop - INFO - 
SimpleTransformer - Step 9250/20000 - Val Loss: 0.860092 - Seq Acc: 12.00%
2025-03-25 18:11:22,562 - training_loop - INFO - 
LatentTransformer - Step 9250/20000 - Val Loss: 1.117002 - Seq Acc: 3.35%
2025-03-25 18:11:28,925 - training_loop - INFO - 
SimpleTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:28,957 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 0.000000)
2025-03-25 18:11:30,969 - training_loop - INFO - 
LatentTransformer - Step 5/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:31,266 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 0.000000)
2025-03-25 18:11:31,945 - training_loop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:32,274 - training_loop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:32,835 - training_loop - INFO - 
SimpleTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:33,132 - training_loop - INFO - 
LatentTransformer - Step 15/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:33,674 - training_loop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:34,001 - training_loop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 18:11:34,046 - training_loop - INFO - Reached target steps: 20/20
2025-03-25 18:11:34,491 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 18:11:34,491 - training_loop - INFO - Steps completed: 20/20
2025-03-25 18:11:34,491 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 18:11:34,491 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 18:11:34,491 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 18:11:34,491 - training_loop - INFO - Final digit accuracy: 9.09%
2025-03-25 18:11:34,491 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 18:11:34,491 - training_loop - INFO - Steps completed: 20/20
2025-03-25 18:11:34,492 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 18:11:34,492 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 18:11:34,492 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 18:11:34,492 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-25 18:11:34,494 - __main__ - INFO - 
Final Comparison:
2025-03-25 18:11:34,494 - __main__ - INFO - ==================================================
2025-03-25 18:11:34,494 - __main__ - INFO - Training time: 26.26s
2025-03-25 18:11:34,494 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 18:11:34,495 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-25 18:11:34,495 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 18:11:34,495 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 18:11:34,495 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-181106_d64_l2_n4
2025-03-25 18:11:38,843 - __main__ - INFO - Using device: cuda
2025-03-25 18:11:38,843 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:11:38,843 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:11:38,844 - __main__ - INFO - Attempting to resume from run ID: 20250325-181106_d64_l2_n4
2025-03-25 18:11:38,844 - __main__ - INFO - Found run: 20250325-181106_d64_l2_n4
2025-03-25 18:11:38,844 - __main__ - INFO - Using d_model=64 from run config (override 384)
2025-03-25 18:11:38,844 - __main__ - INFO - Using num_layers=2 from run config (override 4)
2025-03-25 18:11:38,844 - __main__ - INFO - Using num_latent=4 from run config (override 8)
2025-03-25 18:11:38,844 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 18:11:38,845 - __main__ - INFO - Using max_digits=1 from run config (override 2)
2025-03-25 18:11:38,845 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 18:11:38,846 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 18:11:39,082 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:11:39,082 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:11:39,082 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 18:11:39,082 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:11:39,082 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 18:11:39,082 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:11:39,083 - run_management - INFO - Registered run: 20250325-181139_d64_l2_n4
2025-03-25 18:11:39,084 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-181139_d64_l2_n4
2025-03-25 18:11:39,084 - __main__ - INFO - Using checkpoint paths from run 20250325-181106_d64_l2_n4
2025-03-25 18:11:39,461 - __main__ - INFO - Resuming from step 20/40
2025-03-25 18:11:39,461 - training_loop - INFO - Using max_steps from args: 40
2025-03-25 18:11:39,463 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 18:11:41,427 - training_loop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 18:11:41,431 - training_loop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 18:11:41,431 - training_loop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 18:11:41,431 - training_loop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 18:11:41,435 - training_loop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 18:11:41,435 - training_loop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 18:11:41,435 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 18:11:41,441 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 18:11:41,442 - training_loop - INFO - Starting: Training (steps)
2025-03-25 18:11:45,864 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 18:11:49,336 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 18:11:49,371 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 18:11:49,410 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 18:11:49,440 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 18:11:49,479 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 18:11:49,513 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 18:11:49,553 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 18:11:49,582 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 18:11:49,626 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 18:11:49,670 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 18:11:49,709 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 18:11:49,743 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 18:11:49,781 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 18:11:49,816 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 18:11:49,858 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 18:11:49,889 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 18:11:49,933 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 18:11:49,970 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 18:11:50,012 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 18:11:50,049 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 18:11:50,089 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 18:11:50,126 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 18:11:50,165 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 18:11:50,199 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 18:11:50,237 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 18:11:50,272 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 18:11:50,313 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 18:11:50,348 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 18:11:50,388 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 18:11:50,424 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 18:11:50,464 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 18:11:50,500 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 18:11:50,540 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 18:11:50,578 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 18:11:50,616 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 18:11:50,653 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 18:11:50,696 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 18:11:50,740 - training_loop - ERROR - Error in training step for SimpleTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 18:11:50,781 - training_loop - ERROR - Error in training step for LatentTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 18:11:50,782 - training_loop - INFO - Reached target steps: 40/40
2025-03-25 18:11:54,450 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 18:11:54,451 - training_loop - INFO - Steps completed: 20/40
2025-03-25 18:11:54,451 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 18:11:54,451 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 18:11:54,451 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 18:11:54,451 - training_loop - INFO - Final digit accuracy: 9.09%
2025-03-25 18:11:54,452 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 18:11:54,452 - training_loop - INFO - Steps completed: 20/40
2025-03-25 18:11:54,452 - training_loop - INFO - Best validation loss: 0.000000
2025-03-25 18:11:54,452 - training_loop - INFO - Final validation loss: 0.000000
2025-03-25 18:11:54,452 - training_loop - INFO - Final sequence accuracy: 0.00%
2025-03-25 18:11:54,452 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-25 18:11:54,454 - __main__ - INFO - 
Final Comparison:
2025-03-25 18:11:54,454 - __main__ - INFO - ==================================================
2025-03-25 18:11:54,454 - __main__ - INFO - Training time: 13.02s
2025-03-25 18:11:54,454 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 18:11:54,454 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-25 18:11:54,454 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 18:11:54,454 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 18:11:54,454 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-181139_d64_l2_n4
2025-03-25 18:12:25,406 - training_loop - INFO - 
SimpleTransformer - Step 9300/20000 - Val Loss: 0.892170 - Seq Acc: 12.70%
2025-03-25 18:12:29,615 - training_loop - INFO - 
LatentTransformer - Step 9300/20000 - Val Loss: 1.103879 - Seq Acc: 3.50%
2025-03-25 18:13:28,599 - training_loop - INFO - 
SimpleTransformer - Step 9350/20000 - Val Loss: 0.910940 - Seq Acc: 12.70%
2025-03-25 18:13:32,298 - training_loop - INFO - 
LatentTransformer - Step 9350/20000 - Val Loss: 1.097930 - Seq Acc: 3.35%
2025-03-25 18:14:25,264 - training_loop - INFO - 
SimpleTransformer - Step 9400/20000 - Val Loss: 0.884142 - Seq Acc: 11.95%
2025-03-25 18:14:28,804 - training_loop - INFO - 
LatentTransformer - Step 9400/20000 - Val Loss: 1.094980 - Seq Acc: 3.15%
2025-03-25 18:15:38,614 - training_loop - INFO - 
SimpleTransformer - Step 9450/20000 - Val Loss: 0.882955 - Seq Acc: 11.95%
2025-03-25 18:15:42,277 - training_loop - INFO - 
LatentTransformer - Step 9450/20000 - Val Loss: 1.139610 - Seq Acc: 3.30%
2025-03-25 18:16:43,114 - training_loop - INFO - 
SimpleTransformer - Step 9500/20000 - Val Loss: 0.912530 - Seq Acc: 12.90%
2025-03-25 18:16:46,673 - training_loop - INFO - 
LatentTransformer - Step 9500/20000 - Val Loss: 1.104799 - Seq Acc: 3.40%
2025-03-25 18:17:52,674 - training_loop - INFO - 
SimpleTransformer - Step 9550/20000 - Val Loss: 0.920181 - Seq Acc: 12.30%
2025-03-25 18:17:57,157 - training_loop - INFO - 
LatentTransformer - Step 9550/20000 - Val Loss: 1.108694 - Seq Acc: 3.65%
2025-03-25 18:18:19,404 - __main__ - INFO - Using device: cuda
2025-03-25 18:18:19,404 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:18:19,404 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:18:19,404 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 18:18:20,924 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 18:18:21,243 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:18:21,243 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:18:21,244 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 18:18:21,244 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:18:21,244 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 18:18:21,244 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:18:21,245 - run_management - INFO - Registered run: 20250325-181821_d64_l2_n2
2025-03-25 18:18:21,245 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-181821_d64_l2_n2
2025-03-25 18:18:21,246 - training_loop - INFO - Using max_steps from args: 20
2025-03-25 18:18:21,248 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 18:18:23,550 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 18:18:23,557 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 18:18:23,558 - training_loop - INFO - Starting: Training (steps)
2025-03-25 18:19:02,895 - training_loop - INFO - 
SimpleTransformer - Step 5/20 - Val Loss: 1.814288 - Seq Acc: 0.25%
2025-03-25 18:19:02,940 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.814288)
2025-03-25 18:19:04,509 - training_loop - INFO - 
SimpleTransformer - Step 9600/20000 - Val Loss: 0.912348 - Seq Acc: 12.75%
2025-03-25 18:19:08,795 - training_loop - INFO - 
LatentTransformer - Step 9600/20000 - Val Loss: 1.094521 - Seq Acc: 3.55%
2025-03-25 18:19:12,880 - training_loop - INFO - 
LatentTransformer - Step 5/20 - Val Loss: 1.881390 - Seq Acc: 0.15%
2025-03-25 18:19:12,923 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.881390)
2025-03-25 18:19:15,001 - training_loop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 1.806648 - Seq Acc: 0.35%
2025-03-25 18:19:15,031 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.806648)
2025-03-25 18:19:16,963 - training_loop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 1.871163 - Seq Acc: 0.15%
2025-03-25 18:19:17,025 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.871163)
2025-03-25 18:19:19,186 - training_loop - INFO - 
SimpleTransformer - Step 15/20 - Val Loss: 1.803480 - Seq Acc: 0.35%
2025-03-25 18:19:19,218 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.803480)
2025-03-25 18:19:21,028 - training_loop - INFO - 
LatentTransformer - Step 15/20 - Val Loss: 1.866019 - Seq Acc: 0.15%
2025-03-25 18:19:21,065 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.866019)
2025-03-25 18:19:23,055 - training_loop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 1.802966 - Seq Acc: 0.35%
2025-03-25 18:19:23,086 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.802966)
2025-03-25 18:19:24,992 - training_loop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 1.865285 - Seq Acc: 0.15%
2025-03-25 18:19:25,029 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.865285)
2025-03-25 18:19:25,065 - training_loop - INFO - Target steps reached: 20/20. Breaking training loop.
2025-03-25 18:19:28,649 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 18:19:28,649 - training_loop - INFO - Steps completed: 20/20
2025-03-25 18:19:28,649 - training_loop - INFO - Best validation loss: 1.802966
2025-03-25 18:19:28,649 - training_loop - INFO - Final validation loss: 1.802966
2025-03-25 18:19:28,649 - training_loop - INFO - Final sequence accuracy: 0.35%
2025-03-25 18:19:28,649 - training_loop - INFO - Final digit accuracy: 0.00%
2025-03-25 18:19:28,649 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 18:19:28,649 - training_loop - INFO - Steps completed: 20/20
2025-03-25 18:19:28,650 - training_loop - INFO - Best validation loss: 1.865285
2025-03-25 18:19:28,650 - training_loop - INFO - Final validation loss: 1.865285
2025-03-25 18:19:28,650 - training_loop - INFO - Final sequence accuracy: 0.15%
2025-03-25 18:19:28,650 - training_loop - INFO - Final digit accuracy: 18.18%
2025-03-25 18:19:28,651 - __main__ - INFO - 
Final Comparison:
2025-03-25 18:19:28,652 - __main__ - INFO - ==================================================
2025-03-25 18:19:28,652 - __main__ - INFO - Training time: 65.10s
2025-03-25 18:19:28,652 - __main__ - INFO - SimpleTransformer: 1.802966 loss, 0.35% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 18:19:28,652 - __main__ - INFO - LatentTransformer: 1.865285 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 18:19:28,652 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 18:19:28,652 - __main__ - INFO - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-25 18:19:28,652 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 18:19:28,652 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 18:19:28,653 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-181821_d64_l2_n2
2025-03-25 18:19:34,165 - __main__ - INFO - Using device: cuda
2025-03-25 18:19:34,165 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:19:34,165 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:19:34,166 - __main__ - INFO - Attempting to resume from run ID: 20250325-181821_d64_l2_n2
2025-03-25 18:19:34,166 - __main__ - INFO - Found run: 20250325-181821_d64_l2_n2
2025-03-25 18:19:34,166 - __main__ - INFO - Using d_model=64 from run config (override 384)
2025-03-25 18:19:34,166 - __main__ - INFO - Using num_layers=2 from run config (override 4)
2025-03-25 18:19:34,166 - __main__ - INFO - Using num_latent=2 from run config (override 8)
2025-03-25 18:19:34,167 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 18:19:34,167 - __main__ - INFO - Using max_digits=3 from run config (override 2)
2025-03-25 18:19:34,167 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 18:19:35,757 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 18:19:36,065 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:19:36,065 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:19:36,065 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 18:19:36,065 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:19:36,065 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 18:19:36,065 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:19:36,067 - run_management - INFO - Registered run: 20250325-181936_d64_l2_n2
2025-03-25 18:19:36,067 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-181936_d64_l2_n2
2025-03-25 18:19:36,067 - training_loop - INFO - Using max_steps from args: 40
2025-03-25 18:19:36,069 - training_loop - INFO - Using torch.compile to optimize models
2025-03-25 18:19:38,553 - training_loop - INFO - Precomputing val set with range 10-5
2025-03-25 18:19:38,559 - training_loop - INFO - Created 10 evaluation examples
2025-03-25 18:19:38,560 - training_loop - INFO - Starting: Training (steps)
2025-03-25 18:20:21,988 - training_loop - INFO - 
SimpleTransformer - Step 5/40 - Val Loss: 1.813127 - Seq Acc: 0.25%
2025-03-25 18:20:22,022 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.813127)
2025-03-25 18:20:31,460 - training_loop - INFO - 
SimpleTransformer - Step 9650/20000 - Val Loss: 0.888055 - Seq Acc: 12.80%
2025-03-25 18:20:33,114 - training_loop - INFO - 
LatentTransformer - Step 5/40 - Val Loss: 1.879259 - Seq Acc: 0.15%
2025-03-25 18:20:33,197 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.879259)
2025-03-25 18:20:33,842 - training_loop - INFO - 
SimpleTransformer - Step 10/40 - Val Loss: 1.800891 - Seq Acc: 0.35%
2025-03-25 18:20:33,887 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.800891)
2025-03-25 18:20:34,356 - training_loop - INFO - 
LatentTransformer - Step 10/40 - Val Loss: 1.859434 - Seq Acc: 0.15%
2025-03-25 18:20:34,413 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.859434)
2025-03-25 18:20:35,651 - training_loop - INFO - 
SimpleTransformer - Step 15/40 - Val Loss: 1.790418 - Seq Acc: 0.35%
2025-03-25 18:20:35,686 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.790418)
2025-03-25 18:20:35,849 - training_loop - INFO - 
LatentTransformer - Step 9650/20000 - Val Loss: 1.119057 - Seq Acc: 3.85%
2025-03-25 18:20:36,119 - training_loop - INFO - 
LatentTransformer - Step 15/40 - Val Loss: 1.838924 - Seq Acc: 0.40%
2025-03-25 18:20:36,157 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.838924)
2025-03-25 18:20:37,067 - training_loop - INFO - 
SimpleTransformer - Step 20/40 - Val Loss: 1.781354 - Seq Acc: 0.35%
2025-03-25 18:20:37,099 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.781354)
2025-03-25 18:20:37,561 - training_loop - INFO - 
LatentTransformer - Step 20/40 - Val Loss: 1.824494 - Seq Acc: 0.35%
2025-03-25 18:20:37,598 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.824494)
2025-03-25 18:20:38,393 - training_loop - INFO - 
SimpleTransformer - Step 25/40 - Val Loss: 1.773888 - Seq Acc: 0.35%
2025-03-25 18:20:38,423 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.773888)
2025-03-25 18:20:38,888 - training_loop - INFO - 
LatentTransformer - Step 25/40 - Val Loss: 1.813049 - Seq Acc: 0.20%
2025-03-25 18:20:38,923 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.813049)
2025-03-25 18:20:39,699 - training_loop - INFO - 
SimpleTransformer - Step 30/40 - Val Loss: 1.770161 - Seq Acc: 0.35%
2025-03-25 18:20:39,735 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.770161)
2025-03-25 18:20:40,206 - training_loop - INFO - 
LatentTransformer - Step 30/40 - Val Loss: 1.806658 - Seq Acc: 0.15%
2025-03-25 18:20:40,241 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.806658)
2025-03-25 18:20:41,042 - training_loop - INFO - 
SimpleTransformer - Step 35/40 - Val Loss: 1.768831 - Seq Acc: 0.35%
2025-03-25 18:20:41,073 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.768831)
2025-03-25 18:20:41,624 - training_loop - INFO - 
LatentTransformer - Step 35/40 - Val Loss: 1.804913 - Seq Acc: 0.15%
2025-03-25 18:20:41,667 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.804913)
2025-03-25 18:20:42,471 - training_loop - INFO - 
SimpleTransformer - Step 40/40 - Val Loss: 1.768634 - Seq Acc: 0.35%
2025-03-25 18:20:42,502 - training_loop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.768634)
2025-03-25 18:20:42,984 - training_loop - INFO - 
LatentTransformer - Step 40/40 - Val Loss: 1.804584 - Seq Acc: 0.15%
2025-03-25 18:20:43,022 - training_loop - INFO - Saved new best model for LatentTransformer (val_loss: 1.804584)
2025-03-25 18:20:43,067 - training_loop - INFO - Target steps reached: 40/40. Breaking training loop.
2025-03-25 18:20:43,817 - training_loop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 18:20:43,817 - training_loop - INFO - Steps completed: 40/40
2025-03-25 18:20:43,818 - training_loop - INFO - Best validation loss: 1.768634
2025-03-25 18:20:43,818 - training_loop - INFO - Final validation loss: 1.768634
2025-03-25 18:20:43,818 - training_loop - INFO - Final sequence accuracy: 0.35%
2025-03-25 18:20:43,818 - training_loop - INFO - Final digit accuracy: 9.09%
2025-03-25 18:20:43,818 - training_loop - INFO - 
LatentTransformer Training Summary:
2025-03-25 18:20:43,818 - training_loop - INFO - Steps completed: 40/40
2025-03-25 18:20:43,818 - training_loop - INFO - Best validation loss: 1.804584
2025-03-25 18:20:43,818 - training_loop - INFO - Final validation loss: 1.804584
2025-03-25 18:20:43,818 - training_loop - INFO - Final sequence accuracy: 0.15%
2025-03-25 18:20:43,818 - training_loop - INFO - Final digit accuracy: 27.27%
2025-03-25 18:20:43,820 - __main__ - INFO - 
Final Comparison:
2025-03-25 18:20:43,820 - __main__ - INFO - ==================================================
2025-03-25 18:20:43,821 - __main__ - INFO - Training time: 65.26s
2025-03-25 18:20:43,821 - __main__ - INFO - SimpleTransformer: 1.768634 loss, 0.35% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 18:20:43,821 - __main__ - INFO - LatentTransformer: 1.804584 loss, 0.15% sequence accuracy, 27.27% digit accuracy, 282,379 parameters
2025-03-25 18:20:43,821 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 18:20:43,821 - __main__ - INFO - SimpleTransformer is 1.22x more parameter-efficient (loss*params)
2025-03-25 18:20:43,822 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 18:20:43,822 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 18:20:43,822 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-181936_d64_l2_n2
2025-03-25 18:21:40,225 - training_loop - INFO - 
SimpleTransformer - Step 9700/20000 - Val Loss: 0.925248 - Seq Acc: 13.15%
2025-03-25 18:21:44,410 - training_loop - INFO - 
LatentTransformer - Step 9700/20000 - Val Loss: 1.094577 - Seq Acc: 3.30%
2025-03-25 18:22:43,645 - training_loop - INFO - 
SimpleTransformer - Step 9750/20000 - Val Loss: 0.943068 - Seq Acc: 12.60%
2025-03-25 18:22:47,409 - training_loop - INFO - 
LatentTransformer - Step 9750/20000 - Val Loss: 1.094856 - Seq Acc: 3.65%
2025-03-25 18:23:45,605 - training_loop - INFO - 
SimpleTransformer - Step 9800/20000 - Val Loss: 0.927690 - Seq Acc: 13.10%
2025-03-25 18:23:48,987 - training_loop - INFO - 
LatentTransformer - Step 9800/20000 - Val Loss: 1.094023 - Seq Acc: 3.20%
2025-03-25 18:24:50,035 - training_loop - INFO - 
SimpleTransformer - Step 9850/20000 - Val Loss: 0.925674 - Seq Acc: 12.90%
2025-03-25 18:24:54,230 - training_loop - INFO - 
LatentTransformer - Step 9850/20000 - Val Loss: 1.130426 - Seq Acc: 3.75%
2025-03-25 18:25:56,034 - training_loop - INFO - 
SimpleTransformer - Step 9900/20000 - Val Loss: 0.931496 - Seq Acc: 12.40%
2025-03-25 18:26:00,296 - training_loop - INFO - 
LatentTransformer - Step 9900/20000 - Val Loss: 1.114525 - Seq Acc: 3.35%
2025-03-25 18:26:59,300 - training_loop - INFO - 
SimpleTransformer - Step 9950/20000 - Val Loss: 0.971674 - Seq Acc: 12.30%
2025-03-25 18:27:03,614 - training_loop - INFO - 
LatentTransformer - Step 9950/20000 - Val Loss: 1.132126 - Seq Acc: 3.15%
2025-03-25 18:27:59,477 - training_loop - INFO - 
SimpleTransformer - Step 10000/20000 - Val Loss: 0.947557 - Seq Acc: 13.50%
2025-03-25 18:28:02,950 - training_loop - INFO - 
LatentTransformer - Step 10000/20000 - Val Loss: 1.111318 - Seq Acc: 4.00%
2025-03-25 18:29:05,248 - training_loop - INFO - 
SimpleTransformer - Step 10050/20000 - Val Loss: 0.926449 - Seq Acc: 12.25%
2025-03-25 18:29:09,568 - training_loop - INFO - 
LatentTransformer - Step 10050/20000 - Val Loss: 1.106503 - Seq Acc: 4.00%
2025-03-25 18:30:10,602 - training_loop - INFO - 
SimpleTransformer - Step 10100/20000 - Val Loss: 0.942119 - Seq Acc: 13.50%
2025-03-25 18:30:14,921 - training_loop - INFO - 
LatentTransformer - Step 10100/20000 - Val Loss: 1.095736 - Seq Acc: 3.90%
2025-03-25 18:31:14,311 - training_loop - INFO - 
SimpleTransformer - Step 10150/20000 - Val Loss: 0.987463 - Seq Acc: 12.45%
2025-03-25 18:31:17,884 - training_loop - INFO - 
LatentTransformer - Step 10150/20000 - Val Loss: 1.109789 - Seq Acc: 3.70%
2025-03-25 18:32:18,867 - training_loop - INFO - 
SimpleTransformer - Step 10200/20000 - Val Loss: 0.987078 - Seq Acc: 12.05%
2025-03-25 18:32:22,473 - training_loop - INFO - 
LatentTransformer - Step 10200/20000 - Val Loss: 1.165010 - Seq Acc: 3.60%
2025-03-25 18:33:25,387 - training_loop - INFO - 
SimpleTransformer - Step 10250/20000 - Val Loss: 0.943453 - Seq Acc: 12.75%
2025-03-25 18:33:29,964 - training_loop - INFO - 
LatentTransformer - Step 10250/20000 - Val Loss: 1.098255 - Seq Acc: 4.00%
2025-03-25 18:34:33,499 - training_loop - INFO - 
SimpleTransformer - Step 10300/20000 - Val Loss: 0.973283 - Seq Acc: 12.25%
2025-03-25 18:34:38,098 - training_loop - INFO - 
LatentTransformer - Step 10300/20000 - Val Loss: 1.115333 - Seq Acc: 3.95%
2025-03-25 18:35:43,569 - training_loop - INFO - 
SimpleTransformer - Step 10350/20000 - Val Loss: 0.993773 - Seq Acc: 13.00%
2025-03-25 18:35:47,899 - training_loop - INFO - 
LatentTransformer - Step 10350/20000 - Val Loss: 1.119946 - Seq Acc: 3.50%
2025-03-25 18:36:52,473 - training_loop - INFO - 
SimpleTransformer - Step 10400/20000 - Val Loss: 1.006031 - Seq Acc: 12.00%
2025-03-25 18:36:55,886 - training_loop - INFO - 
LatentTransformer - Step 10400/20000 - Val Loss: 1.127525 - Seq Acc: 4.20%
2025-03-25 18:37:57,928 - training_loop - INFO - 
SimpleTransformer - Step 10450/20000 - Val Loss: 0.955928 - Seq Acc: 13.25%
2025-03-25 18:38:02,217 - training_loop - INFO - 
LatentTransformer - Step 10450/20000 - Val Loss: 1.114550 - Seq Acc: 3.95%
2025-03-25 18:39:10,390 - training_loop - INFO - 
SimpleTransformer - Step 10500/20000 - Val Loss: 0.978003 - Seq Acc: 12.30%
2025-03-25 18:39:14,887 - training_loop - INFO - 
LatentTransformer - Step 10500/20000 - Val Loss: 1.102872 - Seq Acc: 3.95%
2025-03-25 18:40:20,039 - training_loop - INFO - 
SimpleTransformer - Step 10550/20000 - Val Loss: 1.013561 - Seq Acc: 12.55%
2025-03-25 18:40:24,537 - training_loop - INFO - 
LatentTransformer - Step 10550/20000 - Val Loss: 1.108549 - Seq Acc: 3.65%
2025-03-25 18:41:26,482 - training_loop - INFO - 
SimpleTransformer - Step 10600/20000 - Val Loss: 1.020352 - Seq Acc: 12.60%
2025-03-25 18:41:30,173 - training_loop - INFO - 
LatentTransformer - Step 10600/20000 - Val Loss: 1.121318 - Seq Acc: 3.65%
2025-03-25 18:42:35,566 - training_loop - INFO - 
SimpleTransformer - Step 10650/20000 - Val Loss: 0.986139 - Seq Acc: 12.30%
2025-03-25 18:42:40,110 - training_loop - INFO - 
LatentTransformer - Step 10650/20000 - Val Loss: 1.120225 - Seq Acc: 4.10%
2025-03-25 18:43:40,030 - training_loop - INFO - 
SimpleTransformer - Step 10700/20000 - Val Loss: 1.003391 - Seq Acc: 12.25%
2025-03-25 18:43:44,653 - training_loop - INFO - 
LatentTransformer - Step 10700/20000 - Val Loss: 1.158569 - Seq Acc: 3.95%
2025-03-25 18:44:55,138 - training_loop - INFO - 
SimpleTransformer - Step 10750/20000 - Val Loss: 1.020052 - Seq Acc: 12.70%
2025-03-25 18:44:59,952 - training_loop - INFO - 
LatentTransformer - Step 10750/20000 - Val Loss: 1.091757 - Seq Acc: 4.10%
2025-03-25 18:46:08,265 - training_loop - INFO - 
SimpleTransformer - Step 10800/20000 - Val Loss: 1.050800 - Seq Acc: 12.35%
2025-03-25 18:46:12,012 - training_loop - INFO - 
LatentTransformer - Step 10800/20000 - Val Loss: 1.097334 - Seq Acc: 4.50%
2025-03-25 18:47:17,665 - training_loop - INFO - 
SimpleTransformer - Step 10850/20000 - Val Loss: 1.015904 - Seq Acc: 12.30%
2025-03-25 18:47:21,574 - training_loop - INFO - 
LatentTransformer - Step 10850/20000 - Val Loss: 1.136316 - Seq Acc: 5.00%
2025-03-25 18:48:28,706 - training_loop - INFO - 
SimpleTransformer - Step 10900/20000 - Val Loss: 0.999385 - Seq Acc: 13.55%
2025-03-25 18:48:32,393 - training_loop - INFO - 
LatentTransformer - Step 10900/20000 - Val Loss: 1.104824 - Seq Acc: 4.05%
2025-03-25 18:49:41,565 - training_loop - INFO - 
SimpleTransformer - Step 10950/20000 - Val Loss: 1.025241 - Seq Acc: 12.65%
2025-03-25 18:49:46,029 - training_loop - INFO - 
LatentTransformer - Step 10950/20000 - Val Loss: 1.110427 - Seq Acc: 3.75%
2025-03-25 18:50:56,570 - training_loop - INFO - 
SimpleTransformer - Step 11000/20000 - Val Loss: 1.033830 - Seq Acc: 12.85%
2025-03-25 18:51:00,034 - training_loop - INFO - 
LatentTransformer - Step 11000/20000 - Val Loss: 1.112626 - Seq Acc: 4.30%
2025-03-25 18:52:01,990 - training_loop - INFO - 
SimpleTransformer - Step 11050/20000 - Val Loss: 1.030266 - Seq Acc: 12.90%
2025-03-25 18:52:06,333 - training_loop - INFO - 
LatentTransformer - Step 11050/20000 - Val Loss: 1.134810 - Seq Acc: 4.15%
2025-03-25 18:53:11,742 - training_loop - INFO - 
SimpleTransformer - Step 11100/20000 - Val Loss: 1.019886 - Seq Acc: 13.15%
2025-03-25 18:53:16,117 - training_loop - INFO - 
LatentTransformer - Step 11100/20000 - Val Loss: 1.108900 - Seq Acc: 4.25%
2025-03-25 18:54:18,450 - training_loop - INFO - 
SimpleTransformer - Step 11150/20000 - Val Loss: 1.034770 - Seq Acc: 12.55%
2025-03-25 18:54:22,125 - training_loop - INFO - 
LatentTransformer - Step 11150/20000 - Val Loss: 1.118722 - Seq Acc: 4.55%
2025-03-25 18:55:19,906 - training_loop - INFO - 
SimpleTransformer - Step 11200/20000 - Val Loss: 1.047037 - Seq Acc: 12.90%
2025-03-25 18:55:23,836 - training_loop - INFO - 
LatentTransformer - Step 11200/20000 - Val Loss: 1.110354 - Seq Acc: 4.50%
2025-03-25 18:56:34,476 - training_loop - INFO - 
SimpleTransformer - Step 11250/20000 - Val Loss: 1.051343 - Seq Acc: 12.45%
2025-03-25 18:56:39,175 - training_loop - INFO - 
LatentTransformer - Step 11250/20000 - Val Loss: 1.122835 - Seq Acc: 4.40%
2025-03-25 18:56:52,011 - __main__ - INFO - Using device: cuda
2025-03-25 18:56:52,011 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:56:52,011 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:56:52,012 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 18:56:53,883 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 18:56:54,445 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:56:54,446 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:56:54,446 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 18:56:54,446 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:56:54,446 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 18:56:54,446 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:56:54,447 - src.RunManagement - INFO - Registered run: 20250325-185654_d64_l2_n2
2025-03-25 18:56:54,447 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-185654_d64_l2_n2
2025-03-25 18:56:54,447 - src.TrainingLoop - INFO - Using max_steps from args: 20
2025-03-25 18:56:54,450 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 18:56:57,063 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 18:56:57,070 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 18:56:57,073 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 18:57:12,055 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 5/20 - Val Loss: 1.813895 - Seq Acc: 0.25%
2025-03-25 18:57:12,103 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.813895)
2025-03-25 18:57:17,363 - src.TrainingLoop - INFO - 
LatentTransformer - Step 5/20 - Val Loss: 1.882305 - Seq Acc: 0.15%
2025-03-25 18:57:17,417 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.882305)
2025-03-25 18:57:19,530 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 1.806727 - Seq Acc: 0.30%
2025-03-25 18:57:19,560 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.806727)
2025-03-25 18:57:21,397 - src.TrainingLoop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 1.870290 - Seq Acc: 0.15%
2025-03-25 18:57:21,431 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.870290)
2025-03-25 18:57:23,485 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 15/20 - Val Loss: 1.802761 - Seq Acc: 0.35%
2025-03-25 18:57:23,514 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.802761)
2025-03-25 18:57:25,369 - src.TrainingLoop - INFO - 
LatentTransformer - Step 15/20 - Val Loss: 1.864739 - Seq Acc: 0.15%
2025-03-25 18:57:25,408 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.864739)
2025-03-25 18:57:27,404 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 1.802273 - Seq Acc: 0.35%
2025-03-25 18:57:27,436 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.802273)
2025-03-25 18:57:29,366 - src.TrainingLoop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 1.863990 - Seq Acc: 0.15%
2025-03-25 18:57:29,417 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.863990)
2025-03-25 18:57:29,472 - src.TrainingLoop - INFO - Target steps reached: 20/20. Breaking training loop.
2025-03-25 18:57:32,970 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 18:57:32,970 - src.TrainingLoop - INFO - Steps completed: 20/20
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Best validation loss: 1.802273
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Final validation loss: 1.802273
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Final digit accuracy: 0.00%
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Steps completed: 20/20
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Best validation loss: 1.863990
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Final validation loss: 1.863990
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 18:57:32,971 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 18:57:32,974 - __main__ - INFO - 
Final Comparison:
2025-03-25 18:57:32,975 - __main__ - INFO - ==================================================
2025-03-25 18:57:32,975 - __main__ - INFO - Training time: 35.91s
2025-03-25 18:57:32,975 - __main__ - INFO - SimpleTransformer: 1.802273 loss, 0.35% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 18:57:32,975 - __main__ - INFO - LatentTransformer: 1.863990 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 18:57:32,975 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 18:57:32,975 - __main__ - INFO - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-25 18:57:32,975 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 18:57:32,976 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 18:57:32,976 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-185654_d64_l2_n2
2025-03-25 18:57:42,899 - __main__ - INFO - Using device: cuda
2025-03-25 18:57:42,899 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:57:42,899 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:57:42,899 - __main__ - INFO - Attempting to resume from run ID: 20250325-185654_d64_l2_n2
2025-03-25 18:57:42,900 - __main__ - INFO - Found run: 20250325-185654_d64_l2_n2
2025-03-25 18:57:42,900 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 18:57:42,900 - __main__ - INFO - Using d_model=64 from run config (override 384)
2025-03-25 18:57:42,900 - __main__ - INFO - Using num_layers=2 from run config (override 4)
2025-03-25 18:57:42,900 - __main__ - INFO - Using num_latent=2 from run config (override 8)
2025-03-25 18:57:42,900 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 18:57:42,900 - __main__ - INFO - Using max_digits=3 from run config (override 2)
2025-03-25 18:57:42,901 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 18:57:44,527 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 18:57:44,818 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:57:44,819 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 18:57:44,819 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 18:57:44,819 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 18:57:44,819 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 18:57:44,819 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:57:44,822 - src.RunManagement - INFO - Registered run: 20250325-185744_d64_l2_n2
2025-03-25 18:57:44,822 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-185744_d64_l2_n2
2025-03-25 18:57:44,823 - __main__ - INFO - Using checkpoint paths from run 20250325-185654_d64_l2_n2
2025-03-25 18:57:45,272 - __main__ - INFO - Calculating continuation steps for resumed training
2025-03-25 18:57:45,272 - __main__ - INFO - Original max_steps: 40, start_step: 20
2025-03-25 18:57:45,272 - __main__ - INFO - No continuation steps needed, continuing to target 40
2025-03-25 18:57:45,272 - __main__ - INFO - Resuming from step 20/40
2025-03-25 18:57:45,272 - src.TrainingLoop - INFO - Using max_steps from args: 40
2025-03-25 18:57:45,276 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 18:57:47,830 - src.TrainingLoop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 18:57:47,833 - src.TrainingLoop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 18:57:47,833 - src.TrainingLoop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 18:57:47,833 - src.TrainingLoop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 18:57:47,838 - src.TrainingLoop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 18:57:47,838 - src.TrainingLoop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 18:57:47,838 - src.TrainingLoop - INFO - Resetting seed after loading checkpoint to ensure reproducibility
2025-03-25 18:57:47,839 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 18:57:47,845 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 18:57:47,845 - src.TrainingLoop - INFO - Setting consistent RNG state for resuming
2025-03-25 18:57:47,846 - src.TrainingLoop - INFO - Using seed 42 for consistent data ordering
2025-03-25 18:57:47,846 - src.TrainingLoop - INFO - Recreating training DataLoader with fixed seed
2025-03-25 18:57:47,847 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 18:57:48,448 - src.TrainingLoop - INFO - Skipping 20 steps to resume from checkpoint position
2025-03-25 18:57:52,967 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 18:57:56,265 - training_loop - INFO - 
SimpleTransformer - Step 11300/20000 - Val Loss: 1.012176 - Seq Acc: 12.85%
2025-03-25 18:57:57,243 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 18:57:57,290 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 18:57:57,342 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 18:57:57,389 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 18:57:57,448 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 18:57:57,489 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 18:57:57,527 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 18:57:57,560 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 18:57:57,604 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 18:57:57,634 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 18:57:57,672 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 18:57:57,705 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 18:57:57,742 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 18:57:57,774 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 18:57:57,808 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 18:57:57,853 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 18:57:57,886 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 18:57:57,916 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 18:57:57,948 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 18:57:57,983 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 18:57:58,015 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 18:57:58,046 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 18:57:58,079 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 18:57:58,118 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 18:57:58,153 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 18:57:58,184 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 18:57:58,216 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 18:57:58,268 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 18:57:58,302 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 18:57:58,334 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 18:57:58,370 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 18:57:58,403 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 18:57:58,444 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 18:57:58,477 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 18:57:58,513 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 18:57:58,545 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 18:57:58,577 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 18:57:58,625 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 18:57:58,671 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 18:57:58,672 - src.TrainingLoop - INFO - Target steps reached: 40/40. Breaking training loop.
2025-03-25 18:58:00,624 - training_loop - INFO - 
LatentTransformer - Step 11300/20000 - Val Loss: 1.121787 - Seq Acc: 4.35%
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - Steps completed: 20/40
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - Best validation loss: 1.802273
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - Final validation loss: 1.801861
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - Final digit accuracy: 0.00%
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 18:58:07,234 - src.TrainingLoop - INFO - Steps completed: 20/40
2025-03-25 18:58:07,235 - src.TrainingLoop - INFO - Best validation loss: 1.863990
2025-03-25 18:58:07,235 - src.TrainingLoop - INFO - Final validation loss: 1.863085
2025-03-25 18:58:07,235 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 18:58:07,235 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 18:58:07,237 - __main__ - INFO - 
Final Comparison:
2025-03-25 18:58:07,237 - __main__ - INFO - ==================================================
2025-03-25 18:58:07,237 - __main__ - INFO - Training time: 19.39s
2025-03-25 18:58:07,237 - __main__ - INFO - SimpleTransformer: 1.801861 loss, 0.35% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 18:58:07,237 - __main__ - INFO - LatentTransformer: 1.863085 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 18:58:07,238 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 18:58:07,238 - __main__ - INFO - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-25 18:58:07,238 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 18:58:07,238 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 18:58:07,238 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-185744_d64_l2_n2
2025-03-25 18:59:07,187 - training_loop - INFO - 
SimpleTransformer - Step 11350/20000 - Val Loss: 1.047495 - Seq Acc: 12.30%
2025-03-25 18:59:11,096 - training_loop - INFO - 
LatentTransformer - Step 11350/20000 - Val Loss: 1.107219 - Seq Acc: 4.45%
2025-03-25 18:59:20,260 - __main__ - INFO - Using device: cuda
2025-03-25 18:59:20,260 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:59:20,260 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:59:20,260 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 18:59:20,271 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 18:59:20,485 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:59:20,485 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 18:59:20,485 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 18:59:20,485 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 18:59:20,485 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 18:59:20,485 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:59:20,487 - src.RunManagement - INFO - Registered run: 20250325-185920_d32_l1_n1
2025-03-25 18:59:20,487 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-185920_d32_l1_n1
2025-03-25 18:59:20,488 - src.TrainingLoop - INFO - Using max_steps from args: 10
2025-03-25 18:59:20,488 - src.TrainingLoop - INFO - Target steps for full training: 10 (max_steps=10, continuation=0)
2025-03-25 18:59:20,490 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 18:59:26,625 - __main__ - INFO - Using device: cuda
2025-03-25 18:59:26,625 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 18:59:26,625 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 18:59:26,626 - __main__ - INFO - Attempting to resume from run ID: 20250325-185920_d32_l1_n1
2025-03-25 18:59:26,626 - __main__ - INFO - Found run: 20250325-185920_d32_l1_n1
2025-03-25 18:59:26,626 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 18:59:26,626 - __main__ - INFO - Using d_model=32 from run config (override 384)
2025-03-25 18:59:26,627 - __main__ - INFO - Using num_layers=1 from run config (override 4)
2025-03-25 18:59:26,627 - __main__ - INFO - Using num_latent=1 from run config (override 8)
2025-03-25 18:59:26,627 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 18:59:26,627 - __main__ - INFO - Using max_digits=2 from run config (override 2)
2025-03-25 18:59:26,627 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 18:59:26,640 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 18:59:26,850 - __main__ - INFO - 
Model Parameters:
2025-03-25 18:59:26,850 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 18:59:26,850 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 18:59:26,850 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 18:59:26,850 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 18:59:26,850 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 18:59:26,851 - src.RunManagement - INFO - Registered run: 20250325-185926_d32_l1_n1
2025-03-25 18:59:26,852 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-185926_d32_l1_n1
2025-03-25 18:59:26,852 - __main__ - INFO - Using checkpoint paths from run 20250325-185920_d32_l1_n1
2025-03-25 19:00:00,514 - __main__ - INFO - Using device: cuda
2025-03-25 19:00:00,514 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:00:00,514 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:00:00,514 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:00:02,244 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:00:02,547 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:00:02,547 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:00:02,547 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:00:02,547 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:00:02,547 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:00:02,547 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:00:02,548 - src.RunManagement - INFO - Registered run: 20250325-190002_d64_l2_n2
2025-03-25 19:00:02,548 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190002_d64_l2_n2
2025-03-25 19:00:02,549 - src.TrainingLoop - INFO - Using max_steps from args: 20
2025-03-25 19:00:02,549 - src.TrainingLoop - INFO - Target steps for full training: 20 (max_steps=20, continuation=0)
2025-03-25 19:00:02,551 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:00:04,999 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:00:05,006 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:00:05,007 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:00:18,295 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 5/20 - Val Loss: 1.813895 - Seq Acc: 0.25%
2025-03-25 19:00:18,330 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.813895)
2025-03-25 19:00:19,413 - training_loop - INFO - 
SimpleTransformer - Step 11400/20000 - Val Loss: 1.048506 - Seq Acc: 12.75%
2025-03-25 19:00:23,760 - training_loop - INFO - 
LatentTransformer - Step 11400/20000 - Val Loss: 1.127789 - Seq Acc: 4.40%
2025-03-25 19:00:24,060 - src.TrainingLoop - INFO - 
LatentTransformer - Step 5/20 - Val Loss: 1.882305 - Seq Acc: 0.15%
2025-03-25 19:00:24,100 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.882305)
2025-03-25 19:00:26,240 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 1.806727 - Seq Acc: 0.30%
2025-03-25 19:00:26,277 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.806727)
2025-03-25 19:00:28,311 - src.TrainingLoop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 1.870290 - Seq Acc: 0.15%
2025-03-25 19:00:28,350 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.870290)
2025-03-25 19:00:30,392 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 15/20 - Val Loss: 1.802761 - Seq Acc: 0.35%
2025-03-25 19:00:30,426 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.802761)
2025-03-25 19:00:32,355 - src.TrainingLoop - INFO - 
LatentTransformer - Step 15/20 - Val Loss: 1.864739 - Seq Acc: 0.15%
2025-03-25 19:00:32,405 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.864739)
2025-03-25 19:00:34,511 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 1.802273 - Seq Acc: 0.35%
2025-03-25 19:00:34,540 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.802273)
2025-03-25 19:00:36,440 - src.TrainingLoop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 1.863990 - Seq Acc: 0.15%
2025-03-25 19:00:36,474 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.863990)
2025-03-25 19:00:36,509 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 20/20, LatentTransformer: 20/20
2025-03-25 19:00:40,037 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:00:40,037 - src.TrainingLoop - INFO - Steps completed: 20/20
2025-03-25 19:00:40,037 - src.TrainingLoop - INFO - Best validation loss: 1.802273
2025-03-25 19:00:40,037 - src.TrainingLoop - INFO - Final validation loss: 1.802273
2025-03-25 19:00:40,037 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 19:00:40,037 - src.TrainingLoop - INFO - Final digit accuracy: 0.00%
2025-03-25 19:00:40,038 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:00:40,038 - src.TrainingLoop - INFO - Steps completed: 20/20
2025-03-25 19:00:40,038 - src.TrainingLoop - INFO - Best validation loss: 1.863990
2025-03-25 19:00:40,038 - src.TrainingLoop - INFO - Final validation loss: 1.863990
2025-03-25 19:00:40,038 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:00:40,038 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:00:40,040 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:00:40,040 - __main__ - INFO - ==================================================
2025-03-25 19:00:40,041 - __main__ - INFO - Training time: 35.04s
2025-03-25 19:00:40,041 - __main__ - INFO - SimpleTransformer: 1.802273 loss, 0.35% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 19:00:40,041 - __main__ - INFO - LatentTransformer: 1.863990 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:00:40,041 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:00:40,041 - __main__ - INFO - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-25 19:00:40,042 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 19:00:40,042 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:00:40,042 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-190002_d64_l2_n2
2025-03-25 19:00:44,913 - __main__ - INFO - Using device: cuda
2025-03-25 19:00:44,913 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:00:44,913 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:00:44,913 - __main__ - INFO - Attempting to resume from run ID: 20250325-190002_d64_l2_n2
2025-03-25 19:00:44,914 - __main__ - INFO - Found run: 20250325-190002_d64_l2_n2
2025-03-25 19:00:44,914 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:00:46,689 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:00:47,002 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:00:47,002 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:00:47,002 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:00:47,002 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:00:47,002 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:00:47,003 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:00:47,004 - src.RunManagement - INFO - Registered run: 20250325-190046_d64_l2_n2
2025-03-25 19:00:47,004 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190046_d64_l2_n2
2025-03-25 19:00:47,004 - __main__ - INFO - Using checkpoint paths from run 20250325-190002_d64_l2_n2
2025-03-25 19:00:47,432 - __main__ - INFO - Found config in simple_checkpoint
2025-03-25 19:00:47,432 - __main__ - INFO - Found config in latent_checkpoint
2025-03-25 19:00:47,437 - __main__ - INFO - Calculating continuation steps for resumed training
2025-03-25 19:00:47,438 - __main__ - INFO - Original max_steps: 40, start_step: 20
2025-03-25 19:00:47,438 - __main__ - INFO - No continuation steps needed, continuing to target 40
2025-03-25 19:00:47,438 - __main__ - INFO - Resuming from step 20/40
2025-03-25 19:00:47,438 - src.TrainingLoop - INFO - Using max_steps from args: 40
2025-03-25 19:00:47,438 - src.TrainingLoop - INFO - Target steps for full training: 40 (max_steps=40, continuation=0)
2025-03-25 19:00:47,438 - src.TrainingLoop - INFO - Resuming training from checkpoints - adjusting target steps
2025-03-25 19:00:47,438 - src.TrainingLoop - INFO - SimpleTransformer resuming from step 20
2025-03-25 19:00:47,438 - src.TrainingLoop - INFO - SimpleTransformer target steps: 40
2025-03-25 19:00:47,438 - src.TrainingLoop - INFO - LatentTransformer resuming from step 20
2025-03-25 19:00:47,438 - src.TrainingLoop - INFO - LatentTransformer target steps: 40
2025-03-25 19:00:47,441 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:00:50,073 - src.TrainingLoop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 19:00:50,078 - src.TrainingLoop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 19:00:50,078 - src.TrainingLoop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 19:00:50,078 - src.TrainingLoop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 19:00:50,083 - src.TrainingLoop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 19:00:50,083 - src.TrainingLoop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 19:00:50,084 - src.TrainingLoop - INFO - Resetting seed after loading checkpoint to ensure reproducibility
2025-03-25 19:00:50,085 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:00:50,091 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:00:50,091 - src.TrainingLoop - INFO - Setting consistent RNG state for resuming
2025-03-25 19:00:50,091 - src.TrainingLoop - INFO - Using seed 42 for consistent data ordering
2025-03-25 19:00:50,091 - src.TrainingLoop - INFO - Recreating training DataLoader with fixed seed
2025-03-25 19:00:50,093 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:00:52,929 - src.TrainingLoop - INFO - Skipping 20 steps to resume from checkpoint position
2025-03-25 19:00:57,435 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 19:01:01,234 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 21 times. The specified number of total steps is 20
2025-03-25 19:01:01,277 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 19:01:01,319 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 22 times. The specified number of total steps is 20
2025-03-25 19:01:01,362 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 19:01:01,403 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 23 times. The specified number of total steps is 20
2025-03-25 19:01:01,441 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 19:01:01,494 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 24 times. The specified number of total steps is 20
2025-03-25 19:01:01,531 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 19:01:01,571 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 25 times. The specified number of total steps is 20
2025-03-25 19:01:01,608 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 19:01:01,649 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 26 times. The specified number of total steps is 20
2025-03-25 19:01:01,686 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 19:01:01,733 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 27 times. The specified number of total steps is 20
2025-03-25 19:01:01,772 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 19:01:01,812 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 28 times. The specified number of total steps is 20
2025-03-25 19:01:01,860 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 19:01:01,901 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 29 times. The specified number of total steps is 20
2025-03-25 19:01:01,948 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 19:01:01,990 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 30 times. The specified number of total steps is 20
2025-03-25 19:01:02,026 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 19:01:02,068 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 31 times. The specified number of total steps is 20
2025-03-25 19:01:02,112 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 19:01:02,160 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 32 times. The specified number of total steps is 20
2025-03-25 19:01:02,196 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 19:01:02,242 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 33 times. The specified number of total steps is 20
2025-03-25 19:01:02,278 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 19:01:02,318 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 34 times. The specified number of total steps is 20
2025-03-25 19:01:02,354 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 19:01:02,397 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 35 times. The specified number of total steps is 20
2025-03-25 19:01:02,437 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 19:01:02,480 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 36 times. The specified number of total steps is 20
2025-03-25 19:01:02,523 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 19:01:02,582 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 37 times. The specified number of total steps is 20
2025-03-25 19:01:02,619 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 19:01:02,672 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 38 times. The specified number of total steps is 20
2025-03-25 19:01:02,710 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 19:01:02,753 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 39 times. The specified number of total steps is 20
2025-03-25 19:01:02,791 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 19:01:02,832 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: Tried to step 40 times. The specified number of total steps is 20
2025-03-25 19:01:02,833 - src.TrainingLoop - INFO - Target steps reached: 40/40. Breaking training loop.
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - Steps completed: 20/40
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - Best validation loss: 1.802273
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - Final validation loss: 1.801895
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - Final digit accuracy: 0.00%
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:01:11,803 - src.TrainingLoop - INFO - Steps completed: 20/40
2025-03-25 19:01:11,804 - src.TrainingLoop - INFO - Best validation loss: 1.863990
2025-03-25 19:01:11,804 - src.TrainingLoop - INFO - Final validation loss: 1.863222
2025-03-25 19:01:11,804 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:01:11,804 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:01:11,811 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:01:11,811 - __main__ - INFO - ==================================================
2025-03-25 19:01:11,811 - __main__ - INFO - Training time: 21.72s
2025-03-25 19:01:11,811 - __main__ - INFO - SimpleTransformer: 1.801895 loss, 0.35% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 19:01:11,811 - __main__ - INFO - LatentTransformer: 1.863222 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:01:11,812 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:01:11,812 - __main__ - INFO - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-25 19:01:11,812 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 19:01:11,812 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:01:11,812 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-190046_d64_l2_n2
2025-03-25 19:01:43,095 - training_loop - INFO - 
SimpleTransformer - Step 11450/20000 - Val Loss: 1.041523 - Seq Acc: 12.55%
2025-03-25 19:01:46,977 - training_loop - INFO - 
LatentTransformer - Step 11450/20000 - Val Loss: 1.097617 - Seq Acc: 4.90%
2025-03-25 19:02:04,463 - __main__ - INFO - Using device: cuda
2025-03-25 19:02:04,463 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:02:04,463 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:02:04,464 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:02:04,474 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:02:04,697 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:02:04,697 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:02:04,698 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:02:04,698 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:02:04,698 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:02:04,698 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:02:04,700 - src.RunManagement - INFO - Registered run: 20250325-190204_d32_l1_n1
2025-03-25 19:02:04,700 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190204_d32_l1_n1
2025-03-25 19:02:04,700 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:02:04,701 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:02:04,703 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:02:06,727 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:02:06,734 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:02:06,734 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:02:51,636 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 5/5 - Val Loss: 1.731837 - Seq Acc: 5.41%
2025-03-25 19:02:51,654 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.731837)
2025-03-25 19:03:00,103 - training_loop - INFO - 
SimpleTransformer - Step 11500/20000 - Val Loss: 1.015029 - Seq Acc: 12.55%
2025-03-25 19:03:03,887 - src.TrainingLoop - INFO - 
LatentTransformer - Step 5/5 - Val Loss: 1.817689 - Seq Acc: 3.37%
2025-03-25 19:03:03,910 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.817689)
2025-03-25 19:03:04,024 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 5/5, LatentTransformer: 5/5
2025-03-25 19:03:05,116 - training_loop - INFO - 
LatentTransformer - Step 11500/20000 - Val Loss: 1.120028 - Seq Acc: 4.95%
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - Best validation loss: 1.731837
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - Final validation loss: 1.731837
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - Final sequence accuracy: 5.41%
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:03:06,692 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:03:06,693 - src.TrainingLoop - INFO - Best validation loss: 1.817689
2025-03-25 19:03:06,693 - src.TrainingLoop - INFO - Final validation loss: 1.817689
2025-03-25 19:03:06,693 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:03:06,693 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:03:06,695 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:03:06,695 - __main__ - INFO - ==================================================
2025-03-25 19:03:06,695 - __main__ - INFO - Training time: 59.96s
2025-03-25 19:03:06,696 - __main__ - INFO - SimpleTransformer: 1.731837 loss, 5.41% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:03:06,696 - __main__ - INFO - LatentTransformer: 1.817689 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:03:06,696 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:03:06,696 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:03:06,696 - __main__ - INFO - SimpleTransformer is 2.21x more accuracy-per-parameter efficient
2025-03-25 19:03:06,696 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:03:06,696 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-190204_d32_l1_n1
2025-03-25 19:03:10,038 - __main__ - INFO - Using device: cuda
2025-03-25 19:03:10,038 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:03:10,038 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:03:10,038 - __main__ - INFO - Attempting to resume from run ID: 20250325-190204_d32_l1_n1
2025-03-25 19:03:10,039 - __main__ - INFO - Found run: 20250325-190204_d32_l1_n1
2025-03-25 19:03:10,039 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:03:10,039 - __main__ - INFO - Using d_model=32 from run config (override 32)
2025-03-25 19:03:10,039 - __main__ - INFO - Using num_layers=1 from run config (override 1)
2025-03-25 19:03:10,040 - __main__ - INFO - Using num_latent=1 from run config (override 1)
2025-03-25 19:03:10,040 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:03:10,040 - __main__ - INFO - Using max_digits=2 from run config (override 2)
2025-03-25 19:03:10,040 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:03:10,052 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:03:10,270 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:03:10,270 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:03:10,271 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:03:10,271 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:03:10,271 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:03:10,271 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:03:10,273 - src.RunManagement - INFO - Registered run: 20250325-190310_d32_l1_n1
2025-03-25 19:03:10,273 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190310_d32_l1_n1
2025-03-25 19:03:10,274 - __main__ - INFO - Using checkpoint paths from run 20250325-190204_d32_l1_n1
2025-03-25 19:03:12,839 - __main__ - INFO - Using device: cuda
2025-03-25 19:03:12,839 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:03:12,839 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:03:12,840 - __main__ - INFO - Attempting to resume from run ID: 20250325-190310_d32_l1_n1
2025-03-25 19:03:12,840 - __main__ - INFO - Found run: 20250325-190310_d32_l1_n1
2025-03-25 19:03:12,840 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:03:12,840 - __main__ - INFO - Using d_model=32 from run config (override 32)
2025-03-25 19:03:12,840 - __main__ - INFO - Using num_layers=1 from run config (override 1)
2025-03-25 19:03:12,841 - __main__ - INFO - Using num_latent=1 from run config (override 1)
2025-03-25 19:03:12,841 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:03:12,841 - __main__ - INFO - Using max_digits=2 from run config (override 2)
2025-03-25 19:03:12,841 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:03:12,851 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:03:13,049 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:03:13,050 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:03:13,050 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:03:13,050 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:03:13,050 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:03:13,050 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:03:13,051 - src.RunManagement - INFO - Registered run: 20250325-190313_d32_l1_n1
2025-03-25 19:03:13,051 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190313_d32_l1_n1
2025-03-25 19:03:13,052 - __main__ - INFO - Using checkpoint paths from run 20250325-190310_d32_l1_n1
2025-03-25 19:04:14,767 - training_loop - INFO - 
SimpleTransformer - Step 11550/20000 - Val Loss: 1.041859 - Seq Acc: 13.05%
2025-03-25 19:04:18,762 - training_loop - INFO - 
LatentTransformer - Step 11550/20000 - Val Loss: 1.109741 - Seq Acc: 4.05%
2025-03-25 19:04:37,934 - __main__ - INFO - Using device: cuda
2025-03-25 19:04:37,934 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:04:37,934 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:04:37,934 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:04:39,605 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:04:39,910 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:04:39,910 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:04:39,910 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:04:39,910 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:04:39,910 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:04:39,911 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:04:39,912 - src.RunManagement - INFO - Registered run: 20250325-190439_d64_l2_n2
2025-03-25 19:04:39,912 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190439_d64_l2_n2
2025-03-25 19:04:39,913 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:04:39,913 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:04:39,915 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:04:42,367 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:04:42,374 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:04:42,375 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:04:55,923 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 5/5 - Val Loss: 1.804941 - Seq Acc: 0.35%
2025-03-25 19:04:55,963 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.804941)
2025-03-25 19:05:01,266 - src.TrainingLoop - INFO - 
LatentTransformer - Step 5/5 - Val Loss: 1.889959 - Seq Acc: 0.15%
2025-03-25 19:05:01,306 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.889959)
2025-03-25 19:05:01,439 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 5/5, LatentTransformer: 5/5
2025-03-25 19:05:05,008 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:05:05,008 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:05:05,008 - src.TrainingLoop - INFO - Best validation loss: 1.804941
2025-03-25 19:05:05,008 - src.TrainingLoop - INFO - Final validation loss: 1.804941
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - Best validation loss: 1.889959
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - Final validation loss: 1.889959
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:05:05,009 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:05:05,012 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:05:05,012 - __main__ - INFO - ==================================================
2025-03-25 19:05:05,012 - __main__ - INFO - Training time: 22.64s
2025-03-25 19:05:05,012 - __main__ - INFO - SimpleTransformer: 1.804941 loss, 0.35% sequence accuracy, 18.18% digit accuracy, 236,427 parameters
2025-03-25 19:05:05,012 - __main__ - INFO - LatentTransformer: 1.889959 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:05:05,012 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:05:05,012 - __main__ - INFO - SimpleTransformer is 1.25x more parameter-efficient (loss*params)
2025-03-25 19:05:05,013 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 19:05:05,013 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:05:05,013 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-190439_d64_l2_n2
2025-03-25 19:05:08,191 - __main__ - INFO - Using device: cuda
2025-03-25 19:05:08,192 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:05:08,192 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:05:08,192 - __main__ - INFO - Attempting to resume from run ID: 20250325-190439_d64_l2_n2
2025-03-25 19:05:08,192 - __main__ - INFO - Found run: 20250325-190439_d64_l2_n2
2025-03-25 19:05:08,192 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:05:08,193 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:05:08,193 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:05:08,193 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:05:08,193 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:05:08,193 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:05:08,193 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:05:09,898 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:05:10,208 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:05:10,208 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:05:10,208 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:05:10,209 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:05:10,209 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:05:10,209 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:05:10,210 - src.RunManagement - INFO - Registered run: 20250325-190510_d64_l2_n2
2025-03-25 19:05:10,210 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190510_d64_l2_n2
2025-03-25 19:05:10,211 - __main__ - INFO - Using checkpoint paths from run 20250325-190439_d64_l2_n2
2025-03-25 19:05:10,441 - __main__ - INFO - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 19:05:10,441 - __main__ - INFO - Resuming SimpleTransformer from step 5
2025-03-25 19:05:10,659 - __main__ - INFO - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 19:05:10,659 - __main__ - INFO - Resuming LatentTransformer from step 5
2025-03-25 19:05:10,660 - __main__ - INFO - Calculating continuation steps for resumed training
2025-03-25 19:05:10,660 - __main__ - INFO - Original max_steps: 15, start_step: 5
2025-03-25 19:05:10,660 - __main__ - INFO - No continuation steps needed, continuing to target 15
2025-03-25 19:05:10,660 - __main__ - INFO - Resuming from step 5/15
2025-03-25 19:05:10,660 - src.TrainingLoop - INFO - Using max_steps from args: 15
2025-03-25 19:05:10,660 - src.TrainingLoop - INFO - Target steps for full training: 15 (max_steps=15, continuation=0)
2025-03-25 19:05:10,660 - src.TrainingLoop - INFO - Resuming training from checkpoints - adjusting target steps
2025-03-25 19:05:10,660 - src.TrainingLoop - INFO - SimpleTransformer resuming from step 5
2025-03-25 19:05:10,661 - src.TrainingLoop - INFO - SimpleTransformer target steps: 15
2025-03-25 19:05:10,661 - src.TrainingLoop - INFO - LatentTransformer resuming from step 5
2025-03-25 19:05:10,661 - src.TrainingLoop - INFO - LatentTransformer target steps: 15
2025-03-25 19:05:10,664 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:05:13,312 - src.TrainingLoop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 19:05:13,316 - src.TrainingLoop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 19:05:13,316 - src.TrainingLoop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 19:05:13,316 - src.TrainingLoop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 19:05:13,320 - src.TrainingLoop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 19:05:13,320 - src.TrainingLoop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 19:05:13,320 - src.TrainingLoop - INFO - Resetting seed after loading checkpoint to ensure reproducibility
2025-03-25 19:05:13,322 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:05:13,329 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:05:13,329 - src.TrainingLoop - INFO - Setting consistent RNG state for resuming
2025-03-25 19:05:13,329 - src.TrainingLoop - INFO - Using seed 42 for consistent data ordering
2025-03-25 19:05:13,330 - src.TrainingLoop - INFO - Recreating training DataLoader with fixed seed
2025-03-25 19:05:13,331 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:05:16,211 - src.TrainingLoop - INFO - Skipping 5 steps to resume from checkpoint position
2025-03-25 19:05:25,444 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 15/15, LatentTransformer: 15/15
2025-03-25 19:05:33,664 - training_loop - INFO - 
SimpleTransformer - Step 11600/20000 - Val Loss: 1.061202 - Seq Acc: 12.40%
2025-03-25 19:05:34,572 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:05:34,572 - src.TrainingLoop - INFO - Steps completed: 15/15
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Best validation loss: 1.804941
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Final validation loss: 1.768566
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Steps completed: 15/15
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Best validation loss: 1.889959
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Final validation loss: 1.872949
2025-03-25 19:05:34,573 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:05:34,574 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:05:34,580 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:05:34,580 - __main__ - INFO - ==================================================
2025-03-25 19:05:34,581 - __main__ - INFO - Training time: 21.25s
2025-03-25 19:05:34,581 - __main__ - INFO - SimpleTransformer: 1.768566 loss, 0.35% sequence accuracy, 18.18% digit accuracy, 236,427 parameters
2025-03-25 19:05:34,581 - __main__ - INFO - LatentTransformer: 1.872949 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:05:34,581 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:05:34,581 - __main__ - INFO - SimpleTransformer is 1.26x more parameter-efficient (loss*params)
2025-03-25 19:05:34,581 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 19:05:34,581 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:05:34,581 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-190510_d64_l2_n2
2025-03-25 19:05:37,548 - training_loop - INFO - 
LatentTransformer - Step 11600/20000 - Val Loss: 1.111508 - Seq Acc: 5.00%
2025-03-25 19:06:12,844 - __main__ - INFO - Using device: cuda
2025-03-25 19:06:12,844 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:06:12,844 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:06:12,845 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:06:14,539 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:06:14,838 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:06:14,838 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:06:14,838 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:06:14,838 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:06:14,838 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:06:14,838 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:06:14,840 - src.RunManagement - INFO - Registered run: 20250325-190614_d64_l2_n2
2025-03-25 19:06:14,840 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190614_d64_l2_n2
2025-03-25 19:06:14,840 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:06:14,840 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:06:14,843 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:06:17,324 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:06:17,330 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:06:17,331 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:06:30,693 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 5/5 - Val Loss: 1.804941 - Seq Acc: 0.35%
2025-03-25 19:06:30,723 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.804941)
2025-03-25 19:06:35,968 - src.TrainingLoop - INFO - 
LatentTransformer - Step 5/5 - Val Loss: 1.889959 - Seq Acc: 0.15%
2025-03-25 19:06:36,016 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.889959)
2025-03-25 19:06:36,145 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 5/5, LatentTransformer: 5/5
2025-03-25 19:06:39,719 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:06:39,719 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:06:39,719 - src.TrainingLoop - INFO - Best validation loss: 1.804941
2025-03-25 19:06:39,719 - src.TrainingLoop - INFO - Final validation loss: 1.804941
2025-03-25 19:06:39,720 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 19:06:39,720 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:06:39,720 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:06:39,721 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:06:39,721 - src.TrainingLoop - INFO - Best validation loss: 1.889959
2025-03-25 19:06:39,721 - src.TrainingLoop - INFO - Final validation loss: 1.889959
2025-03-25 19:06:39,721 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:06:39,721 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:06:39,723 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:06:39,723 - __main__ - INFO - ==================================================
2025-03-25 19:06:39,724 - __main__ - INFO - Training time: 22.39s
2025-03-25 19:06:39,724 - __main__ - INFO - SimpleTransformer: 1.804941 loss, 0.35% sequence accuracy, 18.18% digit accuracy, 236,427 parameters
2025-03-25 19:06:39,724 - __main__ - INFO - LatentTransformer: 1.889959 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:06:39,724 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:06:39,724 - __main__ - INFO - SimpleTransformer is 1.25x more parameter-efficient (loss*params)
2025-03-25 19:06:39,724 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 19:06:39,725 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:06:39,725 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-190614_d64_l2_n2
2025-03-25 19:06:42,913 - __main__ - INFO - Using device: cuda
2025-03-25 19:06:42,913 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:06:42,913 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:06:42,914 - __main__ - INFO - Attempting to resume from run ID: 20250325-190614_d64_l2_n2
2025-03-25 19:06:42,914 - __main__ - INFO - Found run: 20250325-190614_d64_l2_n2
2025-03-25 19:06:42,914 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:06:42,914 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:06:42,915 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:06:42,915 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:06:42,915 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:06:42,915 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:06:42,915 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:06:44,741 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:06:45,009 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:06:45,009 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:06:45,010 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:06:45,010 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:06:45,010 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:06:45,010 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:06:45,013 - src.RunManagement - INFO - Registered run: 20250325-190645_d64_l2_n2
2025-03-25 19:06:45,013 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190645_d64_l2_n2
2025-03-25 19:06:45,014 - __main__ - INFO - Using checkpoint paths from run 20250325-190614_d64_l2_n2
2025-03-25 19:06:45,290 - __main__ - INFO - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 19:06:45,290 - __main__ - INFO - Resuming SimpleTransformer from step 5
2025-03-25 19:06:45,536 - __main__ - INFO - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 19:06:45,536 - __main__ - INFO - Resuming LatentTransformer from step 5
2025-03-25 19:06:45,536 - __main__ - INFO - Calculating continuation steps for resumed training
2025-03-25 19:06:45,536 - __main__ - INFO - Original max_steps: 10, start_step: 5
2025-03-25 19:06:45,536 - __main__ - INFO - No continuation steps needed, continuing to target 10
2025-03-25 19:06:45,537 - __main__ - INFO - Resuming from step 5/10
2025-03-25 19:06:45,537 - src.TrainingLoop - INFO - Using max_steps from args: 10
2025-03-25 19:06:45,537 - src.TrainingLoop - INFO - Target steps for full training: 10 (max_steps=10, continuation=0)
2025-03-25 19:06:45,537 - src.TrainingLoop - INFO - Resuming training from checkpoints - adjusting target steps
2025-03-25 19:06:45,537 - src.TrainingLoop - INFO - SimpleTransformer resuming from step 5
2025-03-25 19:06:45,537 - src.TrainingLoop - INFO - SimpleTransformer target steps: 10
2025-03-25 19:06:45,538 - src.TrainingLoop - INFO - LatentTransformer resuming from step 5
2025-03-25 19:06:45,538 - src.TrainingLoop - INFO - LatentTransformer target steps: 10
2025-03-25 19:06:45,540 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:06:49,576 - src.TrainingLoop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 19:06:49,580 - src.TrainingLoop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 19:06:49,580 - src.TrainingLoop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 19:06:49,581 - src.TrainingLoop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 19:06:49,586 - src.TrainingLoop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 19:06:49,586 - src.TrainingLoop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 19:06:49,586 - src.TrainingLoop - INFO - Resetting seed after loading checkpoint to ensure reproducibility
2025-03-25 19:06:49,587 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:06:49,588 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:06:49,588 - src.TrainingLoop - INFO - Setting consistent RNG state for resuming
2025-03-25 19:06:49,588 - src.TrainingLoop - INFO - Using seed 42 for consistent data ordering
2025-03-25 19:06:49,589 - src.TrainingLoop - INFO - Recreating training DataLoader with fixed seed
2025-03-25 19:06:49,590 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:06:51,798 - training_loop - INFO - 
SimpleTransformer - Step 11650/20000 - Val Loss: 1.043108 - Seq Acc: 13.15%
2025-03-25 19:06:52,655 - src.TrainingLoop - INFO - Skipping 5 steps to resume from checkpoint position
2025-03-25 19:06:56,858 - training_loop - INFO - 
LatentTransformer - Step 11650/20000 - Val Loss: 1.105525 - Seq Acc: 4.70%
2025-03-25 19:07:02,231 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 10/10, LatentTransformer: 10/10
2025-03-25 19:07:11,273 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:07:11,273 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 19:07:11,273 - src.TrainingLoop - INFO - Best validation loss: 1.804941
2025-03-25 19:07:11,273 - src.TrainingLoop - INFO - Final validation loss: 1.785618
2025-03-25 19:07:11,273 - src.TrainingLoop - INFO - Final sequence accuracy: 0.35%
2025-03-25 19:07:11,274 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:07:11,274 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:07:11,274 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 19:07:11,274 - src.TrainingLoop - INFO - Best validation loss: 1.889959
2025-03-25 19:07:11,274 - src.TrainingLoop - INFO - Final validation loss: 1.879044
2025-03-25 19:07:11,274 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:07:11,274 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:07:11,282 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:07:11,283 - __main__ - INFO - ==================================================
2025-03-25 19:07:11,283 - __main__ - INFO - Training time: 21.69s
2025-03-25 19:07:11,283 - __main__ - INFO - SimpleTransformer: 1.785618 loss, 0.35% sequence accuracy, 18.18% digit accuracy, 236,427 parameters
2025-03-25 19:07:11,283 - __main__ - INFO - LatentTransformer: 1.879044 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:07:11,283 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:07:11,283 - __main__ - INFO - SimpleTransformer is 1.26x more parameter-efficient (loss*params)
2025-03-25 19:07:11,283 - __main__ - INFO - SimpleTransformer is 2.79x more accuracy-per-parameter efficient
2025-03-25 19:07:11,283 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:07:11,284 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-190645_d64_l2_n2
2025-03-25 19:07:14,529 - __main__ - INFO - Using device: cuda
2025-03-25 19:07:14,529 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:07:14,529 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:07:14,530 - __main__ - INFO - Attempting to resume from run ID: 20250325-190645_d64_l2_n2
2025-03-25 19:07:14,530 - __main__ - INFO - Found run: 20250325-190645_d64_l2_n2
2025-03-25 19:07:14,530 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:07:14,530 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:07:14,530 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:07:14,531 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:07:14,531 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:07:14,531 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:07:14,531 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:07:16,244 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:07:16,545 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:07:16,546 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:07:16,546 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:07:16,546 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:07:16,546 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:07:16,546 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:07:16,548 - src.RunManagement - INFO - Registered run: 20250325-190716_d64_l2_n2
2025-03-25 19:07:16,548 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-190716_d64_l2_n2
2025-03-25 19:07:16,549 - __main__ - INFO - Using checkpoint paths from run 20250325-190645_d64_l2_n2
2025-03-25 19:07:17,040 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=64
2025-03-25 19:07:17,041 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:08:08,219 - training_loop - INFO - 
SimpleTransformer - Step 11700/20000 - Val Loss: 1.028794 - Seq Acc: 12.40%
2025-03-25 19:08:11,958 - training_loop - INFO - 
LatentTransformer - Step 11700/20000 - Val Loss: 1.111672 - Seq Acc: 4.65%
2025-03-25 19:09:22,523 - training_loop - INFO - 
SimpleTransformer - Step 11750/20000 - Val Loss: 1.037860 - Seq Acc: 12.80%
2025-03-25 19:09:26,702 - training_loop - INFO - 
LatentTransformer - Step 11750/20000 - Val Loss: 1.118315 - Seq Acc: 4.10%
2025-03-25 19:09:50,477 - __main__ - INFO - Using device: cuda
2025-03-25 19:09:50,477 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:09:50,477 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:09:50,478 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:09:52,172 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:09:52,495 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:09:52,495 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:09:52,495 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:09:52,495 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:09:52,495 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:09:54,802 - __main__ - INFO - Using device: cuda
2025-03-25 19:09:54,803 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:09:54,803 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:09:54,803 - __main__ - INFO - Attempting to resume from run ID: 20250325-190716_d64_l2_n2
2025-03-25 19:09:54,803 - __main__ - INFO - Found run: 20250325-190716_d64_l2_n2
2025-03-25 19:09:54,803 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:09:54,804 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:09:54,804 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:09:54,804 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:09:54,804 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:09:54,804 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:09:54,804 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:09:56,469 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:09:56,727 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:09:56,727 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:09:56,727 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:09:56,728 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:09:56,728 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:09:58,992 - __main__ - INFO - Using device: cuda
2025-03-25 19:09:58,992 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:09:58,992 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:09:58,993 - __main__ - INFO - Attempting to resume from run ID: 20250325-190716_d64_l2_n2
2025-03-25 19:09:58,993 - __main__ - INFO - Found run: 20250325-190716_d64_l2_n2
2025-03-25 19:09:58,993 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:09:58,994 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:09:58,994 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:09:58,994 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:09:58,994 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:09:58,994 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:09:58,994 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:10:00,693 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:10:00,950 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:10:00,950 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:10:00,950 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:10:00,950 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:10:00,950 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:10:40,661 - training_loop - INFO - 
SimpleTransformer - Step 11800/20000 - Val Loss: 1.073525 - Seq Acc: 12.60%
2025-03-25 19:10:44,339 - training_loop - INFO - 
LatentTransformer - Step 11800/20000 - Val Loss: 1.121143 - Seq Acc: 4.20%
2025-03-25 19:11:54,774 - training_loop - INFO - 
SimpleTransformer - Step 11850/20000 - Val Loss: 1.063009 - Seq Acc: 13.15%
2025-03-25 19:11:58,570 - __main__ - INFO - Using device: cuda
2025-03-25 19:11:58,570 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:11:58,570 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:11:58,570 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:11:59,639 - training_loop - INFO - 
LatentTransformer - Step 11850/20000 - Val Loss: 1.113181 - Seq Acc: 4.70%
2025-03-25 19:12:00,282 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:12:00,603 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:12:00,603 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:12:00,603 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:12:00,603 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:12:00,603 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:12:02,841 - __main__ - INFO - Using device: cuda
2025-03-25 19:12:02,841 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:12:02,842 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:12:02,842 - __main__ - INFO - Attempting to resume from run ID: 20250325-190716_d64_l2_n2
2025-03-25 19:12:02,842 - __main__ - INFO - Found run: 20250325-190716_d64_l2_n2
2025-03-25 19:12:02,842 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:12:02,842 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:12:02,842 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:12:02,843 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:12:02,843 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:12:02,843 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:12:02,843 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:12:04,560 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:12:04,862 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:12:04,862 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:12:04,862 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:12:04,862 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:12:04,862 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:12:07,194 - __main__ - INFO - Using device: cuda
2025-03-25 19:12:07,195 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:12:07,195 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:12:07,195 - __main__ - INFO - Attempting to resume from run ID: 20250325-190716_d64_l2_n2
2025-03-25 19:12:07,195 - __main__ - INFO - Found run: 20250325-190716_d64_l2_n2
2025-03-25 19:12:07,195 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:12:07,196 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:12:07,196 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:12:07,196 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:12:07,196 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:12:07,196 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:12:07,196 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:12:08,903 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:12:09,239 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:12:09,239 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:12:09,239 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:12:09,239 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:12:09,239 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:12:47,796 - __main__ - INFO - Using device: cuda
2025-03-25 19:12:47,796 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:12:47,796 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:12:47,796 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:12:49,618 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:12:50,039 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:12:50,040 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:12:50,040 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:12:50,040 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:12:50,040 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:12:50,044 - src.RunManagement - INFO - Registered run: 20250325-191250_d64_l2_n2
2025-03-25 19:12:50,045 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:12:50,045 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:12:52,817 - __main__ - INFO - Using device: cuda
2025-03-25 19:12:52,817 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:12:52,817 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:12:52,818 - __main__ - INFO - Attempting to resume from run ID: 20250325-190716_d64_l2_n2
2025-03-25 19:12:52,818 - __main__ - INFO - Found run: 20250325-190716_d64_l2_n2
2025-03-25 19:12:52,818 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:12:52,819 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:12:52,819 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:12:52,819 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:12:52,819 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:12:52,819 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:12:52,819 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:12:54,663 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:12:54,947 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:12:54,947 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:12:54,947 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:12:54,947 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:12:54,947 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:12:54,949 - src.RunManagement - INFO - Registered run: 20250325-191254_d64_l2_n2
2025-03-25 19:12:54,949 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:12:54,949 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:12:57,304 - __main__ - INFO - Using device: cuda
2025-03-25 19:12:57,305 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:12:57,305 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:12:57,305 - __main__ - INFO - Attempting to resume from run ID: 20250325-190716_d64_l2_n2
2025-03-25 19:12:57,305 - __main__ - INFO - Found run: 20250325-190716_d64_l2_n2
2025-03-25 19:12:57,305 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:12:57,306 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:12:57,306 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:12:57,306 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:12:57,306 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:12:57,306 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:12:57,306 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:12:59,016 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:12:59,322 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:12:59,322 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:12:59,323 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:12:59,323 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:12:59,323 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:12:59,324 - src.RunManagement - INFO - Registered run: 20250325-191259_d64_l2_n2
2025-03-25 19:12:59,324 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:12:59,324 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:13:13,435 - training_loop - INFO - 
SimpleTransformer - Step 11900/20000 - Val Loss: 1.033839 - Seq Acc: 13.15%
2025-03-25 19:13:17,669 - training_loop - INFO - 
LatentTransformer - Step 11900/20000 - Val Loss: 1.116400 - Seq Acc: 5.00%
2025-03-25 19:13:25,950 - __main__ - INFO - Using device: cuda
2025-03-25 19:13:25,950 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:13:25,950 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:13:25,950 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:13:27,657 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:13:27,972 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:13:27,972 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:13:27,973 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:13:27,973 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:13:27,973 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:13:27,976 - src.RunManagement - INFO - Registered run: 20250325-191327_d64_l2_n2
2025-03-25 19:13:27,977 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:13:27,977 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:13:27,979 - src.RunManagement - INFO - Registered run: 20250325-191327_d64_l2_n2
2025-03-25 19:13:27,979 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-191327_d64_l2_n2
2025-03-25 19:13:27,980 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:13:27,980 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:13:27,982 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:13:30,504 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:13:30,510 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:13:30,511 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:14:13,499 - __main__ - INFO - Using device: cuda
2025-03-25 19:14:13,499 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:14:13,499 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:14:13,499 - __main__ - INFO - Attempting to resume from run ID: 20250325-191327_d64_l2_n2
2025-03-25 19:14:13,500 - __main__ - INFO - Found run: 20250325-191327_d64_l2_n2
2025-03-25 19:14:13,500 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:14:13,500 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:14:13,500 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:14:13,500 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:14:13,500 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:14:13,501 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:14:13,501 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:14:15,228 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:14:15,536 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:14:15,536 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:14:15,536 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:14:15,537 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:14:15,537 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:14:15,538 - src.RunManagement - INFO - Registered run: 20250325-191415_d64_l2_n2
2025-03-25 19:14:15,538 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:14:15,538 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:14:15,540 - src.RunManagement - INFO - Registered run: 20250325-191415_d64_l2_n2
2025-03-25 19:14:15,540 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-191415_d64_l2_n2
2025-03-25 19:14:15,541 - __main__ - INFO - Using checkpoint paths from run 20250325-191327_d64_l2_n2
2025-03-25 19:14:15,989 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=64
2025-03-25 19:14:15,989 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:14:18,331 - __main__ - INFO - Using device: cuda
2025-03-25 19:14:18,331 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:14:18,331 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:14:18,332 - __main__ - INFO - Attempting to resume from run ID: 20250325-191415_d64_l2_n2
2025-03-25 19:14:18,332 - __main__ - INFO - Found run: 20250325-191415_d64_l2_n2
2025-03-25 19:14:18,332 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:14:18,333 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:14:18,333 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:14:18,333 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:14:18,333 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:14:18,333 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:14:18,333 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:14:20,085 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:14:20,391 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:14:20,391 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:14:20,391 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:14:20,391 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:14:20,391 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:14:20,393 - src.RunManagement - INFO - Registered run: 20250325-191420_d64_l2_n2
2025-03-25 19:14:20,393 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:14:20,393 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:14:20,394 - src.RunManagement - INFO - Registered run: 20250325-191420_d64_l2_n2
2025-03-25 19:14:20,394 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-191420_d64_l2_n2
2025-03-25 19:14:20,396 - __main__ - INFO - Using checkpoint paths from run 20250325-191415_d64_l2_n2
2025-03-25 19:14:20,900 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=64
2025-03-25 19:14:20,900 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:14:26,763 - training_loop - INFO - 
SimpleTransformer - Step 11950/20000 - Val Loss: 1.036039 - Seq Acc: 12.50%
2025-03-25 19:14:31,311 - training_loop - INFO - 
LatentTransformer - Step 11950/20000 - Val Loss: 1.128723 - Seq Acc: 4.30%
2025-03-25 19:15:40,110 - training_loop - INFO - 
SimpleTransformer - Step 12000/20000 - Val Loss: 1.056246 - Seq Acc: 12.55%
2025-03-25 19:15:43,759 - training_loop - INFO - 
LatentTransformer - Step 12000/20000 - Val Loss: 1.111525 - Seq Acc: 4.80%
2025-03-25 19:16:46,921 - training_loop - INFO - 
SimpleTransformer - Step 12050/20000 - Val Loss: 1.064868 - Seq Acc: 13.25%
2025-03-25 19:16:51,676 - training_loop - INFO - 
LatentTransformer - Step 12050/20000 - Val Loss: 1.109721 - Seq Acc: 5.30%
2025-03-25 19:17:54,054 - training_loop - INFO - 
SimpleTransformer - Step 12100/20000 - Val Loss: 1.042332 - Seq Acc: 12.80%
2025-03-25 19:17:54,885 - __main__ - INFO - Using device: cuda
2025-03-25 19:17:54,885 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:17:54,885 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:17:54,885 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:17:56,519 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:17:56,767 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:17:56,767 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:17:56,767 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:17:56,767 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:17:56,767 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:17:56,768 - src.RunManagement - INFO - Registered run: 20250325-191756_d64_l2_n2
2025-03-25 19:17:56,768 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:17:56,768 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:17:56,770 - src.RunManagement - INFO - Registered run: 20250325-191756_d64_l2_n2
2025-03-25 19:17:56,770 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-191756_d64_l2_n2
2025-03-25 19:17:56,770 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:17:56,770 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:17:56,773 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:17:58,396 - training_loop - INFO - 
LatentTransformer - Step 12100/20000 - Val Loss: 1.114528 - Seq Acc: 4.85%
2025-03-25 19:17:59,095 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:17:59,101 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:17:59,102 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:18:03,905 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:18:16,765 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:18:16,805 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:18:16,843 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:18:16,883 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:18:16,917 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:18:16,950 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:18:16,988 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:18:17,019 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:18:17,054 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:18:17,055 - src.TrainingLoop - INFO - Target steps reached: 5/5. Breaking training loop.
2025-03-25 19:18:26,128 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:18:26,128 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:18:26,128 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:18:26,128 - src.TrainingLoop - INFO - Final validation loss: 1.818252
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - Final sequence accuracy: 0.25%
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - Final digit accuracy: 0.00%
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - Final validation loss: 1.892532
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:18:26,129 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:18:26,133 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:18:26,134 - __main__ - INFO - ==================================================
2025-03-25 19:18:26,134 - __main__ - INFO - Training time: 27.03s
2025-03-25 19:18:26,134 - __main__ - INFO - SimpleTransformer: 1.818252 loss, 0.25% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 19:18:26,134 - __main__ - INFO - LatentTransformer: 1.892532 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:18:26,134 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:18:26,134 - __main__ - INFO - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-25 19:18:26,134 - __main__ - INFO - SimpleTransformer is 1.99x more accuracy-per-parameter efficient
2025-03-25 19:18:26,134 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:18:26,134 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-191756_d64_l2_n2
2025-03-25 19:18:29,477 - __main__ - INFO - Using device: cuda
2025-03-25 19:18:29,477 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:18:29,477 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:18:29,477 - __main__ - INFO - Attempting to resume from run ID: 20250325-191756_d64_l2_n2
2025-03-25 19:18:29,477 - __main__ - INFO - Found run: 20250325-191756_d64_l2_n2
2025-03-25 19:18:29,477 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:18:29,478 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:18:29,478 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:18:29,478 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:18:29,478 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:18:29,478 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:18:29,478 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:18:31,684 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:18:31,997 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:18:31,997 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:18:31,997 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:18:31,997 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:18:31,997 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:18:31,999 - src.RunManagement - INFO - Registered run: 20250325-191831_d64_l2_n2
2025-03-25 19:18:31,999 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:18:31,999 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:18:32,000 - src.RunManagement - INFO - Registered run: 20250325-191831_d64_l2_n2
2025-03-25 19:18:32,000 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-191831_d64_l2_n2
2025-03-25 19:18:32,001 - __main__ - INFO - Using checkpoint paths from run 20250325-191756_d64_l2_n2
2025-03-25 19:18:32,416 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=64
2025-03-25 19:18:32,416 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:18:34,603 - __main__ - INFO - Using device: cuda
2025-03-25 19:18:34,603 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:18:34,603 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:18:34,604 - __main__ - INFO - Attempting to resume from run ID: 20250325-191831_d64_l2_n2
2025-03-25 19:18:34,604 - __main__ - INFO - Found run: 20250325-191831_d64_l2_n2
2025-03-25 19:18:34,604 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:18:34,605 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:18:34,605 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:18:34,605 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:18:34,605 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:18:34,605 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:18:34,605 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:18:36,436 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:18:36,735 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:18:36,735 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:18:36,735 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:18:36,735 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:18:36,736 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:18:36,737 - src.RunManagement - INFO - Registered run: 20250325-191836_d64_l2_n2
2025-03-25 19:18:36,737 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:18:36,737 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:18:36,739 - src.RunManagement - INFO - Registered run: 20250325-191836_d64_l2_n2
2025-03-25 19:18:36,739 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-191836_d64_l2_n2
2025-03-25 19:18:36,739 - __main__ - INFO - Using checkpoint paths from run 20250325-191831_d64_l2_n2
2025-03-25 19:18:37,188 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=64
2025-03-25 19:18:37,189 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:19:08,014 - training_loop - INFO - 
SimpleTransformer - Step 12150/20000 - Val Loss: 1.055443 - Seq Acc: 12.20%
2025-03-25 19:19:11,608 - training_loop - INFO - 
LatentTransformer - Step 12150/20000 - Val Loss: 1.141950 - Seq Acc: 4.60%
2025-03-25 19:20:16,561 - training_loop - INFO - 
SimpleTransformer - Step 12200/20000 - Val Loss: 1.064306 - Seq Acc: 12.85%
2025-03-25 19:20:20,254 - training_loop - INFO - 
LatentTransformer - Step 12200/20000 - Val Loss: 1.109217 - Seq Acc: 4.95%
2025-03-25 19:21:13,302 - __main__ - INFO - Using device: cuda
2025-03-25 19:21:13,302 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:21:13,302 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:21:13,302 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:21:14,914 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:21:15,255 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:21:15,255 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:21:15,255 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:21:15,255 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:21:15,255 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:21:15,257 - src.RunManagement - INFO - Registered run: 20250325-192115_d64_l2_n2
2025-03-25 19:21:15,257 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:21:15,257 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:21:15,258 - src.RunManagement - INFO - Registered run: 20250325-192115_d64_l2_n2
2025-03-25 19:21:15,259 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-192115_d64_l2_n2
2025-03-25 19:21:15,259 - src.TrainingLoop - INFO - Using max_steps from args: 10
2025-03-25 19:21:15,259 - src.TrainingLoop - INFO - Target steps for full training: 10 (max_steps=10, continuation=0)
2025-03-25 19:21:15,261 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:21:17,634 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:21:17,641 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:21:17,642 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:21:23,014 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,138 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,174 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,208 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,241 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,278 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,311 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,345 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,380 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,414 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,448 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,489 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,530 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,569 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,602 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,637 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,671 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,722 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,753 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:21:27,792 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:21:27,793 - src.TrainingLoop - INFO - Target steps reached: 10/10. Breaking training loop.
2025-03-25 19:21:37,546 - training_loop - INFO - 
SimpleTransformer - Step 12250/20000 - Val Loss: 1.067413 - Seq Acc: 12.95%
2025-03-25 19:21:37,586 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:21:37,586 - src.TrainingLoop - INFO - Steps completed: 0/10
2025-03-25 19:21:37,586 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:21:37,586 - src.TrainingLoop - INFO - Final validation loss: 1.815556
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - Final sequence accuracy: 0.25%
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - Final digit accuracy: 0.00%
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - Steps completed: 0/10
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - Final validation loss: 1.890266
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - Final sequence accuracy: 0.15%
2025-03-25 19:21:37,587 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:21:37,590 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:21:37,591 - __main__ - INFO - ==================================================
2025-03-25 19:21:37,591 - __main__ - INFO - Training time: 19.95s
2025-03-25 19:21:37,591 - __main__ - INFO - SimpleTransformer: 1.815556 loss, 0.25% sequence accuracy, 0.00% digit accuracy, 236,427 parameters
2025-03-25 19:21:37,591 - __main__ - INFO - LatentTransformer: 1.890266 loss, 0.15% sequence accuracy, 18.18% digit accuracy, 282,379 parameters
2025-03-25 19:21:37,591 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:21:37,591 - __main__ - INFO - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-25 19:21:37,591 - __main__ - INFO - SimpleTransformer is 1.99x more accuracy-per-parameter efficient
2025-03-25 19:21:37,591 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:21:37,592 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-192115_d64_l2_n2
2025-03-25 19:21:40,949 - __main__ - INFO - Using device: cuda
2025-03-25 19:21:40,949 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:21:40,949 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:21:40,949 - __main__ - INFO - Attempting to resume from run ID: 20250325-192115_d64_l2_n2
2025-03-25 19:21:40,949 - __main__ - INFO - Found run: 20250325-192115_d64_l2_n2
2025-03-25 19:21:40,950 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:21:40,950 - __main__ - INFO - Using d_model=64 from run config (override 64)
2025-03-25 19:21:40,950 - __main__ - INFO - Using num_layers=2 from run config (override 2)
2025-03-25 19:21:40,950 - __main__ - INFO - Using num_latent=2 from run config (override 2)
2025-03-25 19:21:40,950 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:21:40,951 - __main__ - INFO - Using max_digits=3 from run config (override 3)
2025-03-25 19:21:40,951 - __main__ - INFO - Using train dataset with range 1-999
2025-03-25 19:21:42,458 - training_loop - INFO - 
LatentTransformer - Step 12250/20000 - Val Loss: 1.121030 - Seq Acc: 5.25%
2025-03-25 19:21:42,724 - __main__ - INFO - Using val dataset with range 1-999
2025-03-25 19:21:43,046 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:21:43,046 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:21:43,046 - __main__ - INFO - LatentTransformer: 282,379
2025-03-25 19:21:43,046 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:21:43,046 - __main__ - INFO - Difference: 45,952 parameters (19.4%)
2025-03-25 19:21:43,048 - src.RunManagement - INFO - Registered run: 20250325-192143_d64_l2_n2
2025-03-25 19:21:43,048 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:21:43,048 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:21:43,050 - src.RunManagement - INFO - Registered run: 20250325-192143_d64_l2_n2
2025-03-25 19:21:43,050 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-192143_d64_l2_n2
2025-03-25 19:21:43,050 - __main__ - INFO - Using checkpoint paths from run 20250325-192115_d64_l2_n2
2025-03-25 19:21:43,482 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=64
2025-03-25 19:21:43,482 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:22:15,240 - __main__ - INFO - Using device: cuda
2025-03-25 19:22:15,240 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:22:15,241 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:22:15,241 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:22:15,252 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:22:15,456 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:22:15,456 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:22:15,456 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:22:15,457 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:22:15,457 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:22:15,458 - src.RunManagement - INFO - Registered run: 20250325-192215_d32_l1_n1
2025-03-25 19:22:15,458 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:22:15,458 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:22:15,460 - src.RunManagement - INFO - Registered run: 20250325-192215_d32_l1_n1
2025-03-25 19:22:15,460 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-192215_d32_l1_n1
2025-03-25 19:22:15,460 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:22:15,460 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:22:15,463 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:22:17,520 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:22:17,521 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:22:17,521 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:22:22,154 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:22:32,897 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:22:32,924 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:22:32,951 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:22:32,976 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:22:33,002 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:22:33,029 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:22:33,056 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:22:33,089 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:22:33,115 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:22:33,116 - src.TrainingLoop - INFO - Target steps reached: 5/5. Breaking training loop.
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - Final validation loss: 1.736423
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - Final sequence accuracy: 5.00%
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:22:43,515 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:22:43,516 - src.TrainingLoop - INFO - Final validation loss: 1.818413
2025-03-25 19:22:43,516 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:22:43,516 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:22:43,518 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:22:43,518 - __main__ - INFO - ==================================================
2025-03-25 19:22:43,518 - __main__ - INFO - Training time: 25.99s
2025-03-25 19:22:43,518 - __main__ - INFO - SimpleTransformer: 1.736423 loss, 5.00% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:22:43,518 - __main__ - INFO - LatentTransformer: 1.818413 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:22:43,519 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:22:43,519 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:22:43,519 - __main__ - INFO - SimpleTransformer is 2.04x more accuracy-per-parameter efficient
2025-03-25 19:22:43,519 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:22:43,519 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-192215_d32_l1_n1
2025-03-25 19:22:46,657 - __main__ - INFO - Using device: cuda
2025-03-25 19:22:46,657 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:22:46,657 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:22:46,657 - __main__ - INFO - Attempting to resume from run ID: 20250325-192215_d32_l1_n1
2025-03-25 19:22:46,657 - __main__ - INFO - Found run: 20250325-192215_d32_l1_n1
2025-03-25 19:22:46,657 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:22:46,658 - __main__ - INFO - Using d_model=32 from run config (override 32)
2025-03-25 19:22:46,658 - __main__ - INFO - Using num_layers=1 from run config (override 1)
2025-03-25 19:22:46,658 - __main__ - INFO - Using num_latent=1 from run config (override 1)
2025-03-25 19:22:46,658 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:22:46,658 - __main__ - INFO - Using max_digits=2 from run config (override 2)
2025-03-25 19:22:46,658 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:22:46,669 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:22:46,879 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:22:46,879 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:22:46,880 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:22:46,880 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:22:46,880 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:22:46,881 - src.RunManagement - INFO - Registered run: 20250325-192246_d32_l1_n1
2025-03-25 19:22:46,881 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:22:46,882 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:22:46,884 - src.RunManagement - INFO - Registered run: 20250325-192246_d32_l1_n1
2025-03-25 19:22:46,884 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-192246_d32_l1_n1
2025-03-25 19:22:46,884 - __main__ - INFO - Using checkpoint paths from run 20250325-192215_d32_l1_n1
2025-03-25 19:22:47,295 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=32
2025-03-25 19:22:47,296 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:22:59,900 - training_loop - INFO - 
SimpleTransformer - Step 12300/20000 - Val Loss: 1.048895 - Seq Acc: 12.40%
2025-03-25 19:23:03,614 - training_loop - INFO - 
LatentTransformer - Step 12300/20000 - Val Loss: 1.133430 - Seq Acc: 4.95%
2025-03-25 19:24:10,729 - training_loop - INFO - 
SimpleTransformer - Step 12350/20000 - Val Loss: 1.047353 - Seq Acc: 12.50%
2025-03-25 19:24:15,204 - training_loop - INFO - 
LatentTransformer - Step 12350/20000 - Val Loss: 1.137194 - Seq Acc: 4.75%
2025-03-25 19:25:25,188 - training_loop - INFO - 
SimpleTransformer - Step 12400/20000 - Val Loss: 1.053736 - Seq Acc: 12.90%
2025-03-25 19:25:28,811 - training_loop - INFO - 
LatentTransformer - Step 12400/20000 - Val Loss: 1.123075 - Seq Acc: 4.80%
2025-03-25 19:26:38,232 - training_loop - INFO - 
SimpleTransformer - Step 12450/20000 - Val Loss: 1.050526 - Seq Acc: 12.20%
2025-03-25 19:26:41,669 - training_loop - INFO - 
LatentTransformer - Step 12450/20000 - Val Loss: 1.130681 - Seq Acc: 5.20%
2025-03-25 19:27:48,110 - training_loop - INFO - 
SimpleTransformer - Step 12500/20000 - Val Loss: 1.065101 - Seq Acc: 12.15%
2025-03-25 19:27:52,591 - training_loop - INFO - 
LatentTransformer - Step 12500/20000 - Val Loss: 1.164181 - Seq Acc: 4.80%
2025-03-25 19:29:02,226 - training_loop - INFO - 
SimpleTransformer - Step 12550/20000 - Val Loss: 1.046866 - Seq Acc: 13.35%
2025-03-25 19:29:05,684 - training_loop - INFO - 
LatentTransformer - Step 12550/20000 - Val Loss: 1.145018 - Seq Acc: 4.90%
2025-03-25 19:30:09,845 - training_loop - INFO - 
SimpleTransformer - Step 12600/20000 - Val Loss: 1.053579 - Seq Acc: 12.45%
2025-03-25 19:30:13,315 - training_loop - INFO - 
LatentTransformer - Step 12600/20000 - Val Loss: 1.162172 - Seq Acc: 5.20%
2025-03-25 19:31:23,058 - training_loop - INFO - 
SimpleTransformer - Step 12650/20000 - Val Loss: 1.062108 - Seq Acc: 12.55%
2025-03-25 19:31:27,370 - training_loop - INFO - 
LatentTransformer - Step 12650/20000 - Val Loss: 1.146251 - Seq Acc: 5.20%
2025-03-25 19:32:40,075 - training_loop - INFO - 
SimpleTransformer - Step 12700/20000 - Val Loss: 1.066427 - Seq Acc: 12.00%
2025-03-25 19:32:43,607 - training_loop - INFO - 
LatentTransformer - Step 12700/20000 - Val Loss: 1.171602 - Seq Acc: 4.70%
2025-03-25 19:33:57,576 - training_loop - INFO - 
SimpleTransformer - Step 12750/20000 - Val Loss: 1.053984 - Seq Acc: 12.70%
2025-03-25 19:34:02,015 - training_loop - INFO - 
LatentTransformer - Step 12750/20000 - Val Loss: 1.155612 - Seq Acc: 4.10%
2025-03-25 19:34:19,231 - __main__ - INFO - Using device: cuda
2025-03-25 19:34:19,231 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:34:19,231 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:34:19,231 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:34:19,242 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:34:19,465 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:34:19,465 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:34:19,466 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:34:19,466 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:34:19,466 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:34:19,468 - src.RunManagement - INFO - Registered run: 20250325-193419_d32_l1_n1
2025-03-25 19:34:19,468 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:34:19,469 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:34:19,469 - __main__ - INFO - Using custom log directory from environment: runs/parallel_comparison/20250325-193417_continuous_test
2025-03-25 19:34:19,471 - src.RunManagement - INFO - Registered run: 20250325-193419_d32_l1_n1
2025-03-25 19:34:19,471 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-193417_continuous_test
2025-03-25 19:34:19,472 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:34:19,472 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:34:19,474 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:34:21,705 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:34:21,711 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:34:21,711 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:34:26,437 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:34:29,556 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:34:29,586 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:34:29,612 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:34:29,638 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:34:29,664 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:34:29,691 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:34:29,717 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:34:29,746 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:34:29,778 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:34:29,779 - src.TrainingLoop - INFO - Target steps reached: 5/5. Breaking training loop.
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - Final validation loss: 1.736423
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - Final sequence accuracy: 5.00%
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:34:40,542 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:34:40,543 - src.TrainingLoop - INFO - Final validation loss: 1.818413
2025-03-25 19:34:40,543 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:34:40,543 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:34:40,545 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:34:40,545 - __main__ - INFO - ==================================================
2025-03-25 19:34:40,545 - __main__ - INFO - Training time: 18.84s
2025-03-25 19:34:40,545 - __main__ - INFO - SimpleTransformer: 1.736423 loss, 5.00% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:34:40,545 - __main__ - INFO - LatentTransformer: 1.818413 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:34:40,545 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:34:40,546 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:34:40,546 - __main__ - INFO - SimpleTransformer is 2.04x more accuracy-per-parameter efficient
2025-03-25 19:34:40,546 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:34:40,546 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-193417_continuous_test
2025-03-25 19:34:45,324 - __main__ - INFO - Using device: cuda
2025-03-25 19:34:45,324 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:34:45,325 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:34:45,325 - __main__ - INFO - Attempting to resume from run ID: 20250325-192246_d32_l1_n1
2025-03-25 19:34:45,325 - __main__ - INFO - Found run: 20250325-192246_d32_l1_n1
2025-03-25 19:34:45,325 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:34:45,326 - __main__ - INFO - Using d_model=32 from run config (override 32)
2025-03-25 19:34:45,326 - __main__ - INFO - Using num_layers=1 from run config (override 1)
2025-03-25 19:34:45,326 - __main__ - INFO - Using num_latent=1 from run config (override 1)
2025-03-25 19:34:45,326 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:34:45,326 - __main__ - INFO - Using max_digits=2 from run config (override 2)
2025-03-25 19:34:45,326 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:34:45,339 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:34:45,560 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:34:45,560 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:34:45,561 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:34:45,561 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:34:45,561 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:34:45,564 - src.RunManagement - INFO - Registered run: 20250325-193445_d32_l1_n1
2025-03-25 19:34:45,565 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:34:45,565 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:34:45,565 - __main__ - INFO - Using custom log directory from environment: runs/parallel_comparison/20250325-193417_continuous_test
2025-03-25 19:34:45,567 - src.RunManagement - INFO - Registered run: 20250325-193445_d32_l1_n1
2025-03-25 19:34:45,567 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-193417_continuous_test
2025-03-25 19:34:45,568 - __main__ - INFO - Using checkpoint paths from run 20250325-192246_d32_l1_n1
2025-03-25 19:34:45,977 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=32
2025-03-25 19:34:45,977 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 19:35:16,584 - training_loop - INFO - 
SimpleTransformer - Step 12800/20000 - Val Loss: 1.052676 - Seq Acc: 12.45%
2025-03-25 19:35:19,219 - __main__ - INFO - Using device: cuda
2025-03-25 19:35:19,219 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:35:19,219 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:35:19,219 - __main__ - INFO - Attempting to resume from run ID: 20250325-193517_clean_test
2025-03-25 19:35:19,220 - src.RunManagement - WARNING - Run ID 20250325-193517_clean_test not found in index
2025-03-25 19:35:19,220 - __main__ - WARNING - Run ID 20250325-193517_clean_test not found in index, trying to parse from ID format
2025-03-25 19:35:19,220 - src.RunManagement - WARNING - Run ID 20250325-193517_clean_test not found in index
2025-03-25 19:35:19,221 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:35:19,235 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:35:19,454 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:35:19,454 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:35:19,454 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:35:19,454 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:35:19,455 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:35:19,456 - src.RunManagement - INFO - Registered run: 20250325-193519_d32_l1_n1
2025-03-25 19:35:19,457 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:35:19,457 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:35:19,459 - src.RunManagement - INFO - Registered run: 20250325-193519_d32_l1_n1
2025-03-25 19:35:19,459 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-193519_d32_l1_n1
2025-03-25 19:35:19,459 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:35:19,459 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:35:19,462 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:35:20,373 - training_loop - INFO - 
LatentTransformer - Step 12800/20000 - Val Loss: 1.184300 - Seq Acc: 5.20%
2025-03-25 19:35:21,788 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:35:21,795 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:35:21,795 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:35:26,585 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:35:30,052 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:35:30,079 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:35:30,106 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:35:30,134 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:35:30,165 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:35:30,194 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:35:30,226 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:35:30,256 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:35:30,285 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:35:30,286 - src.TrainingLoop - INFO - Target steps reached: 5/5. Breaking training loop.
2025-03-25 19:35:42,194 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:35:42,194 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:35:42,194 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:35:42,194 - src.TrainingLoop - INFO - Final validation loss: 1.736423
2025-03-25 19:35:42,194 - src.TrainingLoop - INFO - Final sequence accuracy: 5.00%
2025-03-25 19:35:42,194 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:35:42,194 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:35:42,195 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:35:42,195 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:35:42,195 - src.TrainingLoop - INFO - Final validation loss: 1.818413
2025-03-25 19:35:42,195 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:35:42,195 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:35:42,198 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:35:42,198 - __main__ - INFO - ==================================================
2025-03-25 19:35:42,198 - __main__ - INFO - Training time: 20.41s
2025-03-25 19:35:42,198 - __main__ - INFO - SimpleTransformer: 1.736423 loss, 5.00% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:35:42,198 - __main__ - INFO - LatentTransformer: 1.818413 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:35:42,198 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:35:42,199 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:35:42,199 - __main__ - INFO - SimpleTransformer is 2.04x more accuracy-per-parameter efficient
2025-03-25 19:35:42,199 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:35:42,199 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-193519_d32_l1_n1
2025-03-25 19:35:47,114 - __main__ - INFO - Using device: cuda
2025-03-25 19:35:47,114 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:35:47,114 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:35:47,114 - __main__ - INFO - Attempting to resume from run ID: 20250325-193517_clean_test
2025-03-25 19:35:47,115 - src.RunManagement - WARNING - Run ID 20250325-193517_clean_test not found in index
2025-03-25 19:35:47,115 - __main__ - WARNING - Run ID 20250325-193517_clean_test not found in index, trying to parse from ID format
2025-03-25 19:35:47,115 - src.RunManagement - WARNING - Run ID 20250325-193517_clean_test not found in index
2025-03-25 19:35:47,115 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:35:47,128 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:35:47,347 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:35:47,347 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:35:47,347 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:35:47,347 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:35:47,347 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:35:47,350 - src.RunManagement - INFO - Registered run: 20250325-193547_d32_l1_n1
2025-03-25 19:35:47,350 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:35:47,350 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:35:47,352 - src.RunManagement - INFO - Registered run: 20250325-193547_d32_l1_n1
2025-03-25 19:35:47,353 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-193547_d32_l1_n1
2025-03-25 19:35:47,354 - src.RunManagement - WARNING - Run ID 20250325-193517_clean_test not found in index
2025-03-25 19:36:44,489 - training_loop - INFO - 
SimpleTransformer - Step 12850/20000 - Val Loss: 1.057353 - Seq Acc: 12.30%
2025-03-25 19:36:49,043 - training_loop - INFO - 
LatentTransformer - Step 12850/20000 - Val Loss: 1.188348 - Seq Acc: 5.25%
2025-03-25 19:37:37,073 - __main__ - INFO - Using device: cuda
2025-03-25 19:37:37,073 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:37:37,074 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:37:37,074 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:37:37,086 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:37:37,302 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:37:37,302 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:37:37,302 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:37:37,302 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:37:37,302 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:37:37,305 - src.RunManagement - INFO - Registered run: 20250325-193737_d32_l1_n1
2025-03-25 19:37:37,305 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:37:37,305 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:37:37,305 - __main__ - INFO - Using custom log directory from environment: runs/continuous_test_20250325-193735
2025-03-25 19:37:37,307 - src.RunManagement - INFO - Registered run: 20250325-193737_d32_l1_n1
2025-03-25 19:37:37,307 - __main__ - INFO - Removing existing log directory: runs/continuous_test_20250325-193735
2025-03-25 19:37:37,307 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:37:37,307 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:37:37,309 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:37:39,454 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:37:39,460 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:37:39,461 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:37:44,237 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:37:47,254 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:37:47,283 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:37:47,310 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:37:47,338 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:37:47,364 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:37:47,395 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:37:47,423 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:37:47,449 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:37:47,476 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:37:47,477 - src.TrainingLoop - INFO - Target steps reached: 5/5. Breaking training loop.
2025-03-25 19:37:58,948 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:37:58,949 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:37:58,949 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:37:58,949 - src.TrainingLoop - INFO - Final validation loss: 1.736423
2025-03-25 19:37:58,949 - src.TrainingLoop - INFO - Final sequence accuracy: 5.00%
2025-03-25 19:37:58,949 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:37:58,949 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:37:58,949 - src.TrainingLoop - INFO - Steps completed: 0/5
2025-03-25 19:37:58,950 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:37:58,950 - src.TrainingLoop - INFO - Final validation loss: 1.818413
2025-03-25 19:37:58,950 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:37:58,950 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:37:58,952 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:37:58,952 - __main__ - INFO - ==================================================
2025-03-25 19:37:58,953 - __main__ - INFO - Training time: 19.49s
2025-03-25 19:37:58,953 - __main__ - INFO - SimpleTransformer: 1.736423 loss, 5.00% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:37:58,953 - __main__ - INFO - LatentTransformer: 1.818413 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:37:58,953 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:37:58,953 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:37:58,953 - __main__ - INFO - SimpleTransformer is 2.04x more accuracy-per-parameter efficient
2025-03-25 19:37:58,953 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:37:58,953 - __main__ - INFO - tensorboard --logdir=runs/continuous_test_20250325-193735
2025-03-25 19:38:03,719 - __main__ - INFO - Using device: cuda
2025-03-25 19:38:03,720 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:38:03,720 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:38:03,720 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:38:03,731 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:38:03,937 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:38:03,938 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:38:03,938 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:38:03,938 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:38:03,938 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:38:03,940 - src.RunManagement - INFO - Registered run: 20250325-193803_d32_l1_n1
2025-03-25 19:38:03,940 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:38:03,940 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:38:03,940 - __main__ - INFO - Using custom log directory from environment: runs/continuous_test_20250325-193735
2025-03-25 19:38:03,942 - src.RunManagement - INFO - Registered run: 20250325-193803_d32_l1_n1
2025-03-25 19:38:03,942 - __main__ - INFO - Removing existing log directory: runs/continuous_test_20250325-193735
2025-03-25 19:38:03,942 - src.TrainingLoop - INFO - Using max_steps from args: 10
2025-03-25 19:38:03,942 - src.TrainingLoop - INFO - Target steps for full training: 10 (max_steps=10, continuation=0)
2025-03-25 19:38:03,945 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:38:06,017 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:38:06,023 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:38:06,024 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:38:09,530 - training_loop - INFO - 
SimpleTransformer - Step 12900/20000 - Val Loss: 1.062025 - Seq Acc: 12.70%
2025-03-25 19:38:10,954 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,207 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,230 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,254 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,276 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,296 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,316 - training_loop - INFO - 
LatentTransformer - Step 12900/20000 - Val Loss: 1.183710 - Seq Acc: 5.30%
2025-03-25 19:38:14,333 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,361 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,388 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,415 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,442 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,470 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,499 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,528 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,557 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,585 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,611 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,638 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,664 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:14,692 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:14,692 - src.TrainingLoop - INFO - Target steps reached: 10/10. Breaking training loop.
2025-03-25 19:38:25,960 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:38:25,960 - src.TrainingLoop - INFO - Steps completed: 0/10
2025-03-25 19:38:25,960 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:38:25,960 - src.TrainingLoop - INFO - Final validation loss: 1.735986
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - Final sequence accuracy: 5.00%
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - Steps completed: 0/10
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - Final validation loss: 1.817942
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:38:25,961 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:38:25,963 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:38:25,964 - __main__ - INFO - ==================================================
2025-03-25 19:38:25,964 - __main__ - INFO - Training time: 19.94s
2025-03-25 19:38:25,964 - __main__ - INFO - SimpleTransformer: 1.735986 loss, 5.00% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:38:25,964 - __main__ - INFO - LatentTransformer: 1.817942 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:38:25,964 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:38:25,964 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:38:25,964 - __main__ - INFO - SimpleTransformer is 2.04x more accuracy-per-parameter efficient
2025-03-25 19:38:25,964 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:38:25,965 - __main__ - INFO - tensorboard --logdir=runs/continuous_test_20250325-193735
2025-03-25 19:38:29,061 - __main__ - INFO - Using device: cuda
2025-03-25 19:38:29,061 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:38:29,061 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:38:29,061 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:38:29,072 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:38:29,297 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:38:29,297 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:38:29,297 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:38:29,297 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:38:29,297 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:38:29,300 - src.RunManagement - INFO - Registered run: 20250325-193829_d32_l1_n1
2025-03-25 19:38:29,300 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:38:29,300 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:38:29,300 - __main__ - INFO - Using custom log directory from environment: runs/continuous_test_20250325-193735
2025-03-25 19:38:29,302 - src.RunManagement - INFO - Registered run: 20250325-193829_d32_l1_n1
2025-03-25 19:38:29,302 - __main__ - INFO - Removing existing log directory: runs/continuous_test_20250325-193735
2025-03-25 19:38:29,302 - src.TrainingLoop - INFO - Using max_steps from args: 15
2025-03-25 19:38:29,302 - src.TrainingLoop - INFO - Target steps for full training: 15 (max_steps=15, continuation=0)
2025-03-25 19:38:29,304 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:38:31,395 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:38:31,402 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:38:31,403 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:38:36,214 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,244 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,273 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,302 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,327 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,354 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,384 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,418 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,446 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,475 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,503 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,531 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,558 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,586 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,616 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,644 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,672 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,699 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,729 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,756 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,784 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,812 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,840 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,867 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,895 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,922 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:39,951 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:39,980 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:40,009 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:38:40,035 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:38:40,035 - src.TrainingLoop - INFO - Target steps reached: 15/15. Breaking training loop.
2025-03-25 19:38:50,693 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:38:50,693 - src.TrainingLoop - INFO - Steps completed: 0/15
2025-03-25 19:38:50,693 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:38:50,693 - src.TrainingLoop - INFO - Final validation loss: 1.735021
2025-03-25 19:38:50,693 - src.TrainingLoop - INFO - Final sequence accuracy: 5.00%
2025-03-25 19:38:50,693 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:38:50,694 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:38:50,694 - src.TrainingLoop - INFO - Steps completed: 0/15
2025-03-25 19:38:50,694 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:38:50,694 - src.TrainingLoop - INFO - Final validation loss: 1.817500
2025-03-25 19:38:50,694 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:38:50,694 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:38:50,697 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:38:50,697 - __main__ - INFO - ==================================================
2025-03-25 19:38:50,698 - __main__ - INFO - Training time: 19.30s
2025-03-25 19:38:50,698 - __main__ - INFO - SimpleTransformer: 1.735021 loss, 5.00% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:38:50,698 - __main__ - INFO - LatentTransformer: 1.817500 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:38:50,698 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:38:50,699 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:38:50,699 - __main__ - INFO - SimpleTransformer is 2.04x more accuracy-per-parameter efficient
2025-03-25 19:38:50,699 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:38:50,699 - __main__ - INFO - tensorboard --logdir=runs/continuous_test_20250325-193735
2025-03-25 19:39:35,631 - training_loop - INFO - 
SimpleTransformer - Step 12950/20000 - Val Loss: 1.048231 - Seq Acc: 13.10%
2025-03-25 19:39:39,339 - training_loop - INFO - 
LatentTransformer - Step 12950/20000 - Val Loss: 1.167677 - Seq Acc: 4.75%
2025-03-25 19:40:47,075 - training_loop - INFO - 
SimpleTransformer - Step 13000/20000 - Val Loss: 1.046804 - Seq Acc: 12.85%
2025-03-25 19:40:50,404 - training_loop - INFO - 
LatentTransformer - Step 13000/20000 - Val Loss: 1.177424 - Seq Acc: 4.90%
2025-03-25 19:41:58,395 - training_loop - INFO - 
SimpleTransformer - Step 13050/20000 - Val Loss: 1.046071 - Seq Acc: 12.35%
2025-03-25 19:42:02,597 - training_loop - INFO - 
LatentTransformer - Step 13050/20000 - Val Loss: 1.207684 - Seq Acc: 5.20%
2025-03-25 19:43:22,861 - training_loop - INFO - 
SimpleTransformer - Step 13100/20000 - Val Loss: 1.050848 - Seq Acc: 12.85%
2025-03-25 19:43:27,273 - training_loop - INFO - 
LatentTransformer - Step 13100/20000 - Val Loss: 1.216686 - Seq Acc: 5.65%
2025-03-25 19:44:39,581 - training_loop - INFO - 
SimpleTransformer - Step 13150/20000 - Val Loss: 1.044131 - Seq Acc: 12.90%
2025-03-25 19:44:43,793 - training_loop - INFO - 
LatentTransformer - Step 13150/20000 - Val Loss: 1.185845 - Seq Acc: 4.75%
2025-03-25 19:45:28,981 - __main__ - INFO - Using device: cuda
2025-03-25 19:45:28,981 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:45:28,981 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:45:28,981 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 19:45:28,981 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 19:45:29,231 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:45:29,231 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:45:29,231 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 19:45:29,231 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:45:29,231 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 19:45:29,233 - src.RunManagement - INFO - Registered run: 20250325-194529_d64_l2_n4
2025-03-25 19:45:29,233 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:45:29,233 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:45:29,235 - src.RunManagement - INFO - Registered run: 20250325-194529_d64_l2_n4
2025-03-25 19:45:29,235 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-194529_d64_l2_n4
2025-03-25 19:45:29,235 - src.TrainingLoop - INFO - Using max_steps from args: 20
2025-03-25 19:45:29,235 - src.TrainingLoop - INFO - Target steps for full training: 20 (max_steps=20, continuation=0)
2025-03-25 19:45:29,237 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:45:31,323 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:45:31,330 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:45:31,330 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:45:37,031 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:45:48,560 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:45:48,589 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:45:48,620 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:45:48,650 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:45:48,682 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:45:53,933 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:45:56,776 - training_loop - INFO - 
SimpleTransformer - Step 13200/20000 - Val Loss: 1.055063 - Seq Acc: 12.25%
2025-03-25 19:46:00,619 - training_loop - INFO - 
LatentTransformer - Step 13200/20000 - Val Loss: 1.174117 - Seq Acc: 5.30%
2025-03-25 19:46:11,455 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:11,504 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:11,581 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:11,628 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:11,678 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:11,725 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:11,767 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:11,809 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:11,857 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:11,895 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:11,939 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:11,974 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,015 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,052 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,104 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,141 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,177 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,207 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,246 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,273 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,309 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,338 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,376 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,408 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,440 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,471 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,504 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,535 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,570 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,600 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,637 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,668 - src.TrainingLoop - ERROR - Error in training step for SimpleTransformer: 'stability_window'
2025-03-25 19:46:12,703 - src.TrainingLoop - ERROR - Error in training step for LatentTransformer: 'stability_window'
2025-03-25 19:46:12,703 - src.TrainingLoop - INFO - Target steps reached: 20/20. Breaking training loop.
2025-03-25 19:46:17,259 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:46:17,259 - src.TrainingLoop - INFO - Steps completed: 0/20
2025-03-25 19:46:17,259 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:46:17,259 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 19:46:17,260 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 19:46:17,260 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 19:46:17,260 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:46:17,260 - src.TrainingLoop - INFO - Steps completed: 0/20
2025-03-25 19:46:17,260 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:46:17,260 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 19:46:17,260 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 19:46:17,261 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:46:17,272 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:46:17,272 - __main__ - INFO - ==================================================
2025-03-25 19:46:17,272 - __main__ - INFO - Training time: 45.94s
2025-03-25 19:46:17,272 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,427 parameters
2025-03-25 19:46:17,273 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 18.18% digit accuracy, 282,507 parameters
2025-03-25 19:46:17,273 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 19:46:17,273 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:46:17,273 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-194529_d64_l2_n4
2025-03-25 19:47:24,461 - training_loop - INFO - 
SimpleTransformer - Step 13250/20000 - Val Loss: 1.053884 - Seq Acc: 13.00%
2025-03-25 19:47:30,245 - training_loop - INFO - 
LatentTransformer - Step 13250/20000 - Val Loss: 1.187290 - Seq Acc: 4.90%
2025-03-25 19:48:16,624 - __main__ - INFO - Using device: cuda
2025-03-25 19:48:16,624 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:48:16,624 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:48:16,624 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:48:16,637 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:48:16,902 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:48:16,902 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:48:16,902 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:48:16,902 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:48:16,902 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:48:16,909 - src.RunManagement - INFO - Registered run: 20250325-194816_d32_l1_n1
2025-03-25 19:48:16,910 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:48:16,910 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:48:16,917 - src.RunManagement - INFO - Registered run: 20250325-194816_d32_l1_n1
2025-03-25 19:48:16,918 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-194816_d32_l1_n1
2025-03-25 19:48:16,919 - src.TrainingLoop - INFO - Using max_steps from args: 10
2025-03-25 19:48:16,919 - src.TrainingLoop - INFO - Target steps for full training: 10 (max_steps=10, continuation=0)
2025-03-25 19:48:16,922 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:48:19,344 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:48:19,352 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:48:19,354 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:48:28,932 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 10/10, LatentTransformer: 10/10
2025-03-25 19:48:42,200 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:48:42,200 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 19:48:42,200 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:48:42,200 - src.TrainingLoop - INFO - Final validation loss: 1.728147
2025-03-25 19:48:42,200 - src.TrainingLoop - INFO - Final sequence accuracy: 5.41%
2025-03-25 19:48:42,200 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:48:42,200 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:48:42,201 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 19:48:42,201 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 19:48:42,201 - src.TrainingLoop - INFO - Final validation loss: 1.816599
2025-03-25 19:48:42,201 - src.TrainingLoop - INFO - Final sequence accuracy: 3.27%
2025-03-25 19:48:42,201 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:48:42,203 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:48:42,204 - __main__ - INFO - ==================================================
2025-03-25 19:48:42,204 - __main__ - INFO - Training time: 22.86s
2025-03-25 19:48:42,204 - __main__ - INFO - SimpleTransformer: 1.728147 loss, 5.41% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:48:42,204 - __main__ - INFO - LatentTransformer: 1.816599 loss, 3.27% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:48:42,204 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:48:42,204 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:48:42,204 - __main__ - INFO - SimpleTransformer is 2.28x more accuracy-per-parameter efficient
2025-03-25 19:48:42,204 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:48:42,204 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-194816_d32_l1_n1
2025-03-25 19:49:14,571 - __main__ - INFO - Using device: cuda
2025-03-25 19:49:14,572 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:49:14,572 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:49:14,572 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:49:14,586 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:49:14,849 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:49:14,850 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:49:14,850 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:49:14,850 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:49:14,850 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:49:14,852 - src.RunManagement - INFO - Registered run: 20250325-194914_d32_l1_n1
2025-03-25 19:49:14,853 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:49:14,853 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:49:14,856 - src.RunManagement - INFO - Registered run: 20250325-194914_d32_l1_n1
2025-03-25 19:49:14,856 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-194914_d32_l1_n1
2025-03-25 19:49:14,856 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 19:49:14,857 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 19:49:14,860 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:49:17,292 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:49:17,300 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:49:17,301 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:49:31,308 - training_loop - INFO - 
SimpleTransformer - Step 13300/20000 - Val Loss: 1.057416 - Seq Acc: 12.95%
2025-03-25 19:49:32,395 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 5/5 - Val Loss: 1.731837 - Seq Acc: 5.41%
2025-03-25 19:49:32,418 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.731837)
2025-03-25 19:49:37,145 - training_loop - INFO - 
LatentTransformer - Step 13300/20000 - Val Loss: 1.222873 - Seq Acc: 5.00%
2025-03-25 19:49:40,486 - src.TrainingLoop - INFO - 
LatentTransformer - Step 5/5 - Val Loss: 1.817668 - Seq Acc: 3.37%
2025-03-25 19:49:40,517 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.817668)
2025-03-25 19:49:40,646 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 5/5, LatentTransformer: 5/5
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - Best validation loss: 1.731837
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - Final validation loss: 1.731837
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - Final sequence accuracy: 5.41%
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 19:49:44,735 - src.TrainingLoop - INFO - Best validation loss: 1.817668
2025-03-25 19:49:44,736 - src.TrainingLoop - INFO - Final validation loss: 1.817668
2025-03-25 19:49:44,736 - src.TrainingLoop - INFO - Final sequence accuracy: 3.37%
2025-03-25 19:49:44,736 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:49:44,737 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:49:44,737 - __main__ - INFO - ==================================================
2025-03-25 19:49:44,737 - __main__ - INFO - Training time: 27.44s
2025-03-25 19:49:44,738 - __main__ - INFO - SimpleTransformer: 1.731837 loss, 5.41% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:49:44,738 - __main__ - INFO - LatentTransformer: 1.817668 loss, 3.37% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:49:44,738 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:49:44,738 - __main__ - INFO - SimpleTransformer is 1.44x more parameter-efficient (loss*params)
2025-03-25 19:49:44,738 - __main__ - INFO - SimpleTransformer is 2.21x more accuracy-per-parameter efficient
2025-03-25 19:49:44,739 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:49:44,739 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-194914_d32_l1_n1
2025-03-25 19:49:48,345 - __main__ - INFO - Using device: cuda
2025-03-25 19:49:48,345 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:49:48,345 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:49:48,345 - __main__ - INFO - Attempting to resume from run ID: 20250325-194914_d32_l1_n1
2025-03-25 19:49:48,346 - __main__ - INFO - Found run: 20250325-194914_d32_l1_n1
2025-03-25 19:49:48,346 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 19:49:48,346 - __main__ - INFO - Using d_model=32 from run config (override 32)
2025-03-25 19:49:48,346 - __main__ - INFO - Using num_layers=1 from run config (override 1)
2025-03-25 19:49:48,347 - __main__ - INFO - Using num_latent=1 from run config (override 1)
2025-03-25 19:49:48,347 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 19:49:48,347 - __main__ - INFO - Using max_digits=2 from run config (override 2)
2025-03-25 19:49:48,347 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 19:49:48,360 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 19:49:48,639 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:49:48,639 - __main__ - INFO - SimpleTransformer: 31,179
2025-03-25 19:49:48,639 - __main__ - INFO - LatentTransformer: 42,859
2025-03-25 19:49:48,639 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 19:49:48,639 - __main__ - INFO - Difference: 11,680 parameters (37.5%)
2025-03-25 19:49:48,641 - src.RunManagement - INFO - Registered run: 20250325-194948_d32_l1_n1
2025-03-25 19:49:48,641 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:49:48,641 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:49:48,644 - src.RunManagement - INFO - Registered run: 20250325-194948_d32_l1_n1
2025-03-25 19:49:48,645 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-194948_d32_l1_n1
2025-03-25 19:49:48,645 - __main__ - INFO - Using checkpoint paths from run 20250325-194914_d32_l1_n1
2025-03-25 19:49:48,803 - __main__ - INFO - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 19:49:48,803 - __main__ - INFO - Resuming SimpleTransformer from step 5
2025-03-25 19:49:49,013 - __main__ - INFO - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 19:49:49,014 - __main__ - INFO - Resuming LatentTransformer from step 5
2025-03-25 19:49:49,014 - __main__ - INFO - Calculating continuation steps for resumed training
2025-03-25 19:49:49,014 - __main__ - INFO - Original max_steps: 10, start_step: 5
2025-03-25 19:49:49,014 - __main__ - INFO - No continuation steps needed, continuing to target 10
2025-03-25 19:49:49,014 - __main__ - INFO - Resuming from step 5/10
2025-03-25 19:49:49,014 - src.TrainingLoop - INFO - Using max_steps from args: 10
2025-03-25 19:49:49,014 - src.TrainingLoop - INFO - Target steps for full training: 10 (max_steps=10, continuation=0)
2025-03-25 19:49:49,014 - src.TrainingLoop - INFO - Resuming training from checkpoints - adjusting target steps
2025-03-25 19:49:49,015 - src.TrainingLoop - INFO - SimpleTransformer resuming from step 5
2025-03-25 19:49:49,015 - src.TrainingLoop - INFO - SimpleTransformer target steps: 10
2025-03-25 19:49:49,015 - src.TrainingLoop - INFO - LatentTransformer resuming from step 5
2025-03-25 19:49:49,015 - src.TrainingLoop - INFO - LatentTransformer target steps: 10
2025-03-25 19:49:49,018 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:49:51,467 - src.TrainingLoop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 19:49:51,470 - src.TrainingLoop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 19:49:51,470 - src.TrainingLoop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 19:49:51,471 - src.TrainingLoop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 19:49:51,475 - src.TrainingLoop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 19:49:51,475 - src.TrainingLoop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 19:49:51,475 - src.TrainingLoop - INFO - Resetting seed after loading checkpoint to ensure reproducibility
2025-03-25 19:49:51,476 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:49:51,485 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:49:51,485 - src.TrainingLoop - INFO - Setting consistent RNG state for resuming
2025-03-25 19:49:51,485 - src.TrainingLoop - INFO - Using seed 42 for consistent data ordering
2025-03-25 19:49:51,486 - src.TrainingLoop - INFO - Recreating training DataLoader with fixed seed
2025-03-25 19:49:51,487 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:49:54,143 - src.TrainingLoop - INFO - Skipping 5 steps to resume from checkpoint position
2025-03-25 19:50:03,094 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 10/10, LatentTransformer: 10/10
2025-03-25 19:50:16,550 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 19:50:16,551 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 19:50:16,551 - src.TrainingLoop - INFO - Best validation loss: 1.731837
2025-03-25 19:50:16,551 - src.TrainingLoop - INFO - Final validation loss: 1.727001
2025-03-25 19:50:16,551 - src.TrainingLoop - INFO - Final sequence accuracy: 5.41%
2025-03-25 19:50:16,551 - src.TrainingLoop - INFO - Final digit accuracy: 27.27%
2025-03-25 19:50:16,551 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 19:50:16,551 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 19:50:16,552 - src.TrainingLoop - INFO - Best validation loss: 1.817668
2025-03-25 19:50:16,552 - src.TrainingLoop - INFO - Final validation loss: 1.816083
2025-03-25 19:50:16,552 - src.TrainingLoop - INFO - Final sequence accuracy: 3.16%
2025-03-25 19:50:16,552 - src.TrainingLoop - INFO - Final digit accuracy: 18.18%
2025-03-25 19:50:16,560 - __main__ - INFO - 
Final Comparison:
2025-03-25 19:50:16,560 - __main__ - INFO - ==================================================
2025-03-25 19:50:16,560 - __main__ - INFO - Training time: 25.07s
2025-03-25 19:50:16,560 - __main__ - INFO - SimpleTransformer: 1.727001 loss, 5.41% sequence accuracy, 27.27% digit accuracy, 31,179 parameters
2025-03-25 19:50:16,561 - __main__ - INFO - LatentTransformer: 1.816083 loss, 3.16% sequence accuracy, 18.18% digit accuracy, 42,859 parameters
2025-03-25 19:50:16,561 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 19:50:16,561 - __main__ - INFO - SimpleTransformer is 1.45x more parameter-efficient (loss*params)
2025-03-25 19:50:16,561 - __main__ - INFO - SimpleTransformer is 2.35x more accuracy-per-parameter efficient
2025-03-25 19:50:16,561 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 19:50:16,561 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-194948_d32_l1_n1
2025-03-25 19:51:26,583 - training_loop - INFO - 
SimpleTransformer - Step 13350/20000 - Val Loss: 1.050165 - Seq Acc: 13.05%
2025-03-25 19:51:32,300 - training_loop - INFO - 
LatentTransformer - Step 13350/20000 - Val Loss: 1.224060 - Seq Acc: 5.00%
2025-03-25 19:52:47,976 - __main__ - INFO - Using device: cuda
2025-03-25 19:52:47,976 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 19:52:47,976 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 19:52:47,976 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 19:52:47,976 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 19:52:48,288 - __main__ - INFO - 
Model Parameters:
2025-03-25 19:52:48,288 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 19:52:48,288 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 19:52:48,289 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 19:52:48,289 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 19:52:48,291 - src.RunManagement - INFO - Registered run: 20250325-195248_d64_l2_n4
2025-03-25 19:52:48,291 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:52:48,291 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 19:52:48,293 - src.RunManagement - INFO - Registered run: 20250325-195248_d64_l2_n4
2025-03-25 19:52:48,294 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-195248_d64_l2_n4
2025-03-25 19:52:48,294 - src.TrainingLoop - INFO - Using max_steps from args: 20
2025-03-25 19:52:48,294 - src.TrainingLoop - INFO - Target steps for full training: 20 (max_steps=20, continuation=0)
2025-03-25 19:52:48,296 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 19:52:50,441 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 19:52:50,449 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 19:52:50,450 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 19:53:23,881 - training_loop - INFO - 
SimpleTransformer - Step 13400/20000 - Val Loss: 1.055301 - Seq Acc: 12.05%
2025-03-25 19:53:29,806 - training_loop - INFO - 
LatentTransformer - Step 13400/20000 - Val Loss: 1.196253 - Seq Acc: 5.25%
2025-03-25 19:55:13,404 - training_loop - INFO - 
SimpleTransformer - Step 13450/20000 - Val Loss: 1.048263 - Seq Acc: 12.75%
2025-03-25 19:55:18,828 - training_loop - INFO - 
LatentTransformer - Step 13450/20000 - Val Loss: 1.222144 - Seq Acc: 5.50%
2025-03-25 19:56:56,282 - training_loop - INFO - 
SimpleTransformer - Step 13500/20000 - Val Loss: 1.059432 - Seq Acc: 12.55%
2025-03-25 19:57:02,066 - training_loop - INFO - 
LatentTransformer - Step 13500/20000 - Val Loss: 1.228091 - Seq Acc: 5.35%
2025-03-25 19:58:43,859 - training_loop - INFO - 
SimpleTransformer - Step 13550/20000 - Val Loss: 1.041901 - Seq Acc: 13.10%
2025-03-25 19:58:49,469 - training_loop - INFO - 
LatentTransformer - Step 13550/20000 - Val Loss: 1.234705 - Seq Acc: 5.25%
2025-03-25 20:00:33,509 - training_loop - INFO - 
SimpleTransformer - Step 13600/20000 - Val Loss: 1.051158 - Seq Acc: 12.70%
2025-03-25 20:00:38,040 - training_loop - INFO - 
LatentTransformer - Step 13600/20000 - Val Loss: 1.220328 - Seq Acc: 4.70%
2025-03-25 20:02:20,593 - training_loop - INFO - 
SimpleTransformer - Step 13650/20000 - Val Loss: 1.040617 - Seq Acc: 12.75%
2025-03-25 20:02:25,373 - training_loop - INFO - 
LatentTransformer - Step 13650/20000 - Val Loss: 1.229329 - Seq Acc: 5.65%
2025-03-25 20:04:03,893 - training_loop - INFO - 
SimpleTransformer - Step 13700/20000 - Val Loss: 1.049206 - Seq Acc: 13.00%
2025-03-25 20:04:09,551 - training_loop - INFO - 
LatentTransformer - Step 13700/20000 - Val Loss: 1.235766 - Seq Acc: 5.20%
2025-03-25 20:05:56,298 - training_loop - INFO - 
SimpleTransformer - Step 13750/20000 - Val Loss: 1.043101 - Seq Acc: 12.80%
2025-03-25 20:06:01,071 - training_loop - INFO - 
LatentTransformer - Step 13750/20000 - Val Loss: 1.248259 - Seq Acc: 5.10%
2025-03-25 20:07:42,895 - training_loop - INFO - 
SimpleTransformer - Step 13800/20000 - Val Loss: 1.049171 - Seq Acc: 13.05%
2025-03-25 20:07:47,429 - training_loop - INFO - 
LatentTransformer - Step 13800/20000 - Val Loss: 1.240661 - Seq Acc: 4.40%
2025-03-25 20:09:35,952 - training_loop - INFO - 
SimpleTransformer - Step 13850/20000 - Val Loss: 1.045050 - Seq Acc: 13.10%
2025-03-25 20:09:41,767 - training_loop - INFO - 
LatentTransformer - Step 13850/20000 - Val Loss: 1.228694 - Seq Acc: 5.60%
2025-03-25 20:11:31,026 - training_loop - INFO - 
SimpleTransformer - Step 13900/20000 - Val Loss: 1.048772 - Seq Acc: 13.00%
2025-03-25 20:11:36,794 - training_loop - INFO - 
LatentTransformer - Step 13900/20000 - Val Loss: 1.259016 - Seq Acc: 5.25%
2025-03-25 20:13:25,644 - training_loop - INFO - 
SimpleTransformer - Step 13950/20000 - Val Loss: 1.050768 - Seq Acc: 12.95%
2025-03-25 20:13:30,740 - training_loop - INFO - 
LatentTransformer - Step 13950/20000 - Val Loss: 1.249398 - Seq Acc: 5.35%
2025-03-25 20:15:19,612 - training_loop - INFO - 
SimpleTransformer - Step 14000/20000 - Val Loss: 1.043480 - Seq Acc: 12.60%
2025-03-25 20:15:23,838 - training_loop - INFO - 
LatentTransformer - Step 14000/20000 - Val Loss: 1.280271 - Seq Acc: 4.85%
2025-03-25 20:17:09,214 - training_loop - INFO - 
SimpleTransformer - Step 14050/20000 - Val Loss: 1.044328 - Seq Acc: 13.05%
2025-03-25 20:17:14,642 - training_loop - INFO - 
LatentTransformer - Step 14050/20000 - Val Loss: 1.241106 - Seq Acc: 5.10%
2025-03-25 20:18:44,895 - __main__ - INFO - Using device: cuda
2025-03-25 20:18:44,895 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 20:18:44,895 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 20:18:44,895 - __main__ - INFO - Attempting to resume from run ID: 20250325-195248_d64_l2_n4
2025-03-25 20:18:44,896 - __main__ - INFO - Found run: 20250325-195248_d64_l2_n4
2025-03-25 20:18:44,896 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 20:18:44,896 - __main__ - INFO - Using d_model=64 from run config (override 768)
2025-03-25 20:18:44,896 - __main__ - INFO - Using num_layers=2 from run config (override 8)
2025-03-25 20:18:44,896 - __main__ - INFO - Using num_latent=4 from run config (override 16)
2025-03-25 20:18:44,897 - __main__ - INFO - Using min_digits=1 from run config (override 3)
2025-03-25 20:18:44,897 - __main__ - INFO - Using max_digits=1 from run config (override 2)
2025-03-25 20:18:44,897 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 20:18:44,897 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 20:18:45,213 - __main__ - INFO - 
Model Parameters:
2025-03-25 20:18:45,213 - __main__ - INFO - SimpleTransformer: 236,427
2025-03-25 20:18:45,214 - __main__ - INFO - LatentTransformer: 282,507
2025-03-25 20:18:45,214 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 20:18:45,214 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 20:18:45,216 - src.RunManagement - INFO - Registered run: 20250325-201845_d64_l2_n4
2025-03-25 20:18:45,216 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 20:18:45,216 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 20:18:45,219 - src.RunManagement - INFO - Registered run: 20250325-201845_d64_l2_n4
2025-03-25 20:18:45,219 - __main__ - INFO - Removing existing log directory: runs/parallel_comparison/20250325-201845_d64_l2_n4
2025-03-25 20:18:45,220 - __main__ - INFO - Using checkpoint paths from run 20250325-195248_d64_l2_n4
2025-03-25 20:18:45,629 - __main__ - ERROR - ERROR: Model dimension mismatch! Checkpoint has d_model=768, but current model uses d_model=64
2025-03-25 20:18:45,629 - __main__ - ERROR - Please use --d-model 768 when resuming from this checkpoint
2025-03-25 20:18:54,003 - training_loop - INFO - 
SimpleTransformer - Step 14100/20000 - Val Loss: 1.042380 - Seq Acc: 13.20%
2025-03-25 20:18:58,548 - training_loop - INFO - 
LatentTransformer - Step 14100/20000 - Val Loss: 1.274665 - Seq Acc: 5.25%
2025-03-25 20:20:44,899 - training_loop - INFO - 
SimpleTransformer - Step 14150/20000 - Val Loss: 1.051847 - Seq Acc: 12.85%
2025-03-25 20:20:50,356 - training_loop - INFO - 
LatentTransformer - Step 14150/20000 - Val Loss: 1.280051 - Seq Acc: 5.50%
2025-03-25 20:22:33,021 - training_loop - INFO - 
SimpleTransformer - Step 14200/20000 - Val Loss: 1.040977 - Seq Acc: 13.05%
2025-03-25 20:22:37,249 - training_loop - INFO - 
LatentTransformer - Step 14200/20000 - Val Loss: 1.277574 - Seq Acc: 5.20%
2025-03-25 20:24:19,158 - training_loop - INFO - 
SimpleTransformer - Step 14250/20000 - Val Loss: 1.038231 - Seq Acc: 12.75%
2025-03-25 20:24:24,541 - training_loop - INFO - 
LatentTransformer - Step 14250/20000 - Val Loss: 1.250141 - Seq Acc: 4.95%
2025-03-25 20:26:09,198 - training_loop - INFO - 
SimpleTransformer - Step 14300/20000 - Val Loss: 1.035042 - Seq Acc: 13.05%
2025-03-25 20:26:14,481 - training_loop - INFO - 
LatentTransformer - Step 14300/20000 - Val Loss: 1.287732 - Seq Acc: 4.85%
2025-03-25 20:27:58,374 - training_loop - INFO - 
SimpleTransformer - Step 14350/20000 - Val Loss: 1.030234 - Seq Acc: 13.10%
2025-03-25 20:28:03,057 - training_loop - INFO - 
LatentTransformer - Step 14350/20000 - Val Loss: 1.303923 - Seq Acc: 5.50%
2025-03-25 20:29:19,606 - training_loop - INFO - 
SimpleTransformer - Step 14400/20000 - Val Loss: 1.037937 - Seq Acc: 13.00%
2025-03-25 20:29:23,511 - training_loop - INFO - 
LatentTransformer - Step 14400/20000 - Val Loss: 1.280327 - Seq Acc: 5.25%
2025-03-25 20:30:41,246 - training_loop - INFO - 
SimpleTransformer - Step 14450/20000 - Val Loss: 1.039777 - Seq Acc: 13.40%
2025-03-25 20:30:45,831 - training_loop - INFO - 
LatentTransformer - Step 14450/20000 - Val Loss: 1.264139 - Seq Acc: 5.20%
2025-03-25 20:31:50,119 - __main__ - INFO - Using device: cuda
2025-03-25 20:31:50,120 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 20:31:50,120 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 20:31:50,120 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 20:31:50,132 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 20:31:50,364 - __main__ - INFO - 
Model Parameters:
2025-03-25 20:31:50,365 - __main__ - INFO - SimpleTransformer: 31,244
2025-03-25 20:31:50,365 - __main__ - INFO - LatentTransformer: 42,924
2025-03-25 20:31:50,365 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 20:31:50,365 - __main__ - INFO - Difference: 11,680 parameters (37.4%)
2025-03-25 20:31:52,303 - __main__ - INFO - Using device: cuda
2025-03-25 20:31:52,303 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 20:31:52,303 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 20:31:52,303 - __main__ - INFO - Attempting to resume from run ID: 20250325-194948_d32_l1_n1
2025-03-25 20:31:52,304 - __main__ - INFO - Found run: 20250325-194948_d32_l1_n1
2025-03-25 20:31:52,304 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 20:31:52,304 - __main__ - INFO - Using d_model=32 from run config (override 64)
2025-03-25 20:31:52,304 - __main__ - INFO - Using num_layers=1 from run config (override 1)
2025-03-25 20:31:52,304 - __main__ - INFO - Using num_latent=1 from run config (override 1)
2025-03-25 20:31:52,304 - __main__ - INFO - Using min_digits=1 from run config (override 1)
2025-03-25 20:31:52,304 - __main__ - INFO - Using max_digits=2 from run config (override 2)
2025-03-25 20:31:52,305 - __main__ - INFO - Using checkpoint paths from run 20250325-194948_d32_l1_n1
2025-03-25 20:31:53,446 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 20:31:53,447 - __main__ - INFO - Updating d_model from 32 to 768 to match checkpoint
2025-03-25 20:31:53,447 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 20:31:53,473 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 20:31:54,249 - __main__ - INFO - 
Model Parameters:
2025-03-25 20:31:54,249 - __main__ - INFO - SimpleTransformer: 16,576,524
2025-03-25 20:31:54,249 - __main__ - INFO - LatentTransformer: 23,074,572
2025-03-25 20:31:54,249 - __main__ - INFO - Parameter ratio: 1.39x
2025-03-25 20:31:54,249 - __main__ - INFO - Difference: 6,498,048 parameters (39.2%)
2025-03-25 20:32:07,275 - training_loop - INFO - 
SimpleTransformer - Step 14500/20000 - Val Loss: 1.034142 - Seq Acc: 12.95%
2025-03-25 20:32:12,694 - training_loop - INFO - 
LatentTransformer - Step 14500/20000 - Val Loss: 1.306909 - Seq Acc: 5.25%
2025-03-25 20:32:24,045 - __main__ - INFO - Using device: cuda
2025-03-25 20:32:24,045 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 20:32:24,045 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 20:32:24,046 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 20:32:24,061 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 20:32:24,334 - __main__ - INFO - 
Model Parameters:
2025-03-25 20:32:24,334 - __main__ - INFO - SimpleTransformer: 31,244
2025-03-25 20:32:24,334 - __main__ - INFO - LatentTransformer: 42,924
2025-03-25 20:32:24,334 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 20:32:24,335 - __main__ - INFO - Difference: 11,680 parameters (37.4%)
2025-03-25 20:32:24,337 - src.RunManagement - INFO - Registered run: 20250325-203224_d32_l1_n1
2025-03-25 20:32:24,337 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 20:32:24,340 - src.RunManagement - INFO - Registered run: 20250325-203224_d32_l1_n1
2025-03-25 20:32:24,341 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 20:32:24,341 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 20:32:24,344 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 20:32:27,111 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 20:32:27,118 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 20:32:27,119 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 20:33:08,727 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 5/5 - Val Loss: 1.811092 - Seq Acc: 3.78%
2025-03-25 20:33:08,755 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 1.811092)
2025-03-25 20:33:22,296 - src.TrainingLoop - INFO - 
LatentTransformer - Step 5/5 - Val Loss: 1.922457 - Seq Acc: 2.86%
2025-03-25 20:33:22,330 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 1.922457)
2025-03-25 20:33:22,469 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 5/5, LatentTransformer: 5/5
2025-03-25 20:33:26,560 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 20:33:26,561 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 20:33:26,561 - src.TrainingLoop - INFO - Best validation loss: 1.811092
2025-03-25 20:33:26,561 - src.TrainingLoop - INFO - Final validation loss: 1.811092
2025-03-25 20:33:26,561 - src.TrainingLoop - INFO - Final sequence accuracy: 3.78%
2025-03-25 20:33:26,561 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 20:33:26,561 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 20:33:26,562 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 20:33:26,562 - src.TrainingLoop - INFO - Best validation loss: 1.922457
2025-03-25 20:33:26,562 - src.TrainingLoop - INFO - Final validation loss: 1.922457
2025-03-25 20:33:26,562 - src.TrainingLoop - INFO - Final sequence accuracy: 2.86%
2025-03-25 20:33:26,562 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 20:33:26,564 - __main__ - INFO - 
Final Comparison:
2025-03-25 20:33:26,564 - __main__ - INFO - ==================================================
2025-03-25 20:33:26,564 - __main__ - INFO - Training time: 59.45s
2025-03-25 20:33:26,564 - __main__ - INFO - SimpleTransformer: 1.811092 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-25 20:33:26,564 - __main__ - INFO - LatentTransformer: 1.922457 loss, 2.86% sequence accuracy, 9.09% digit accuracy, 42,924 parameters
2025-03-25 20:33:26,565 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 20:33:26,565 - __main__ - INFO - SimpleTransformer is 1.46x more parameter-efficient (loss*params)
2025-03-25 20:33:26,565 - __main__ - INFO - SimpleTransformer is 1.82x more accuracy-per-parameter efficient
2025-03-25 20:33:26,566 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 20:33:26,566 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-203224_d32_l1_n1
2025-03-25 20:33:31,009 - __main__ - INFO - Using device: cuda
2025-03-25 20:33:31,009 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 20:33:31,009 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 20:33:31,010 - __main__ - INFO - Attempting to resume from run ID: 20250325-203224_d32_l1_n1
2025-03-25 20:33:31,010 - __main__ - INFO - Found run: 20250325-203224_d32_l1_n1
2025-03-25 20:33:31,011 - __main__ - INFO - Using checkpoint paths from run 20250325-203224_d32_l1_n1
2025-03-25 20:33:31,545 - __main__ - INFO - Found d_model=32 in checkpoint config
2025-03-25 20:33:31,546 - __main__ - INFO - Updating d_model from 64 to 32 to match checkpoint
2025-03-25 20:33:31,546 - __main__ - INFO - Using train dataset with range 1-99
2025-03-25 20:33:31,560 - __main__ - INFO - Using val dataset with range 1-99
2025-03-25 20:33:31,650 - __main__ - INFO - 
Model Parameters:
2025-03-25 20:33:31,650 - __main__ - INFO - SimpleTransformer: 31,244
2025-03-25 20:33:31,650 - __main__ - INFO - LatentTransformer: 42,924
2025-03-25 20:33:31,651 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 20:33:31,651 - __main__ - INFO - Difference: 11,680 parameters (37.4%)
2025-03-25 20:33:31,654 - src.RunManagement - INFO - Registered run: 20250325-203331_d32_l1_n1
2025-03-25 20:33:31,654 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 20:33:31,657 - src.RunManagement - INFO - Registered run: 20250325-203331_d32_l1_n1
2025-03-25 20:33:31,661 - __main__ - INFO - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 20:33:31,661 - __main__ - INFO - Resuming SimpleTransformer from step 5
2025-03-25 20:33:31,665 - __main__ - INFO - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 20:33:31,666 - __main__ - INFO - Resuming LatentTransformer from step 5
2025-03-25 20:33:31,666 - __main__ - INFO - Calculating continuation steps for resumed training
2025-03-25 20:33:31,666 - __main__ - INFO - Original max_steps: 10, start_step: 5
2025-03-25 20:33:31,666 - __main__ - INFO - No continuation steps needed, continuing to target 10
2025-03-25 20:33:31,667 - __main__ - INFO - Resuming from step 5/10
2025-03-25 20:33:31,667 - src.TrainingLoop - INFO - Using max_steps from args: 10
2025-03-25 20:33:31,667 - src.TrainingLoop - INFO - Target steps for full training: 10 (max_steps=10, continuation=0)
2025-03-25 20:33:31,667 - src.TrainingLoop - INFO - Resuming training from checkpoints - adjusting target steps
2025-03-25 20:33:31,667 - src.TrainingLoop - INFO - SimpleTransformer resuming from step 5
2025-03-25 20:33:31,667 - src.TrainingLoop - INFO - SimpleTransformer target steps: 10
2025-03-25 20:33:31,667 - src.TrainingLoop - INFO - LatentTransformer resuming from step 5
2025-03-25 20:33:31,668 - src.TrainingLoop - INFO - LatentTransformer target steps: 10
2025-03-25 20:33:31,670 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 20:33:34,517 - src.TrainingLoop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 20:33:34,521 - src.TrainingLoop - INFO - Loaded SimpleTransformer optimizer state
2025-03-25 20:33:34,521 - src.TrainingLoop - INFO - Loaded SimpleTransformer scheduler state
2025-03-25 20:33:34,521 - src.TrainingLoop - INFO - Loading LatentTransformer from checkpoint
2025-03-25 20:33:34,525 - src.TrainingLoop - INFO - Loaded LatentTransformer optimizer state
2025-03-25 20:33:34,526 - src.TrainingLoop - INFO - Loaded LatentTransformer scheduler state
2025-03-25 20:33:34,526 - src.TrainingLoop - INFO - Resetting seed after loading checkpoint to ensure reproducibility
2025-03-25 20:33:34,527 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 20:33:34,534 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 20:33:34,534 - src.TrainingLoop - INFO - Setting consistent RNG state for resuming
2025-03-25 20:33:34,534 - src.TrainingLoop - INFO - Using seed 42 for consistent data ordering
2025-03-25 20:33:34,535 - src.TrainingLoop - INFO - Recreating training DataLoader with fixed seed
2025-03-25 20:33:34,536 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 20:33:37,562 - src.TrainingLoop - INFO - Skipping 5 steps to resume from checkpoint position
2025-03-25 20:33:49,880 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 10/10, LatentTransformer: 10/10
2025-03-25 20:34:07,894 - training_loop - INFO - 
SimpleTransformer - Step 14550/20000 - Val Loss: 1.040663 - Seq Acc: 13.10%
2025-03-25 20:34:10,829 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Best validation loss: 1.811092
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Final validation loss: 1.805256
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Final sequence accuracy: 3.98%
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Steps completed: 10/10
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Best validation loss: 1.922457
2025-03-25 20:34:10,830 - src.TrainingLoop - INFO - Final validation loss: 1.918659
2025-03-25 20:34:10,831 - src.TrainingLoop - INFO - Final sequence accuracy: 2.76%
2025-03-25 20:34:10,831 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 20:34:10,840 - __main__ - INFO - 
Final Comparison:
2025-03-25 20:34:10,843 - __main__ - INFO - ==================================================
2025-03-25 20:34:10,844 - __main__ - INFO - Training time: 36.30s
2025-03-25 20:34:10,845 - __main__ - INFO - SimpleTransformer: 1.805256 loss, 3.98% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-25 20:34:10,845 - __main__ - INFO - LatentTransformer: 1.918659 loss, 2.76% sequence accuracy, 9.09% digit accuracy, 42,924 parameters
2025-03-25 20:34:10,845 - __main__ - INFO - 
Efficiency Metrics:
2025-03-25 20:34:10,845 - __main__ - INFO - SimpleTransformer is 1.46x more parameter-efficient (loss*params)
2025-03-25 20:34:10,845 - __main__ - INFO - SimpleTransformer is 1.98x more accuracy-per-parameter efficient
2025-03-25 20:34:10,845 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 20:34:10,845 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-203331_d32_l1_n1
2025-03-25 20:34:16,829 - training_loop - INFO - 
LatentTransformer - Step 14550/20000 - Val Loss: 1.312265 - Seq Acc: 5.80%
2025-03-25 20:35:56,476 - training_loop - INFO - 
SimpleTransformer - Step 14600/20000 - Val Loss: 1.036774 - Seq Acc: 13.00%
2025-03-25 20:36:00,551 - training_loop - INFO - 
LatentTransformer - Step 14600/20000 - Val Loss: 1.297621 - Seq Acc: 4.90%
2025-03-25 20:37:34,076 - training_loop - INFO - 
SimpleTransformer - Step 14650/20000 - Val Loss: 1.036866 - Seq Acc: 12.85%
2025-03-25 20:37:39,047 - training_loop - INFO - 
LatentTransformer - Step 14650/20000 - Val Loss: 1.274452 - Seq Acc: 5.35%
2025-03-25 20:38:59,195 - training_loop - INFO - 
SimpleTransformer - Step 14700/20000 - Val Loss: 1.031813 - Seq Acc: 12.90%
2025-03-25 20:39:03,820 - training_loop - INFO - 
LatentTransformer - Step 14700/20000 - Val Loss: 1.302345 - Seq Acc: 5.55%
2025-03-25 20:40:25,577 - training_loop - INFO - 
SimpleTransformer - Step 14750/20000 - Val Loss: 1.030038 - Seq Acc: 12.90%
2025-03-25 20:40:30,912 - training_loop - INFO - 
LatentTransformer - Step 14750/20000 - Val Loss: 1.322528 - Seq Acc: 5.15%
2025-03-25 20:41:57,801 - training_loop - INFO - 
SimpleTransformer - Step 14800/20000 - Val Loss: 1.032016 - Seq Acc: 13.05%
2025-03-25 20:42:02,055 - training_loop - INFO - 
LatentTransformer - Step 14800/20000 - Val Loss: 1.311620 - Seq Acc: 5.55%
2025-03-25 20:43:35,258 - training_loop - INFO - 
SimpleTransformer - Step 14850/20000 - Val Loss: 1.031374 - Seq Acc: 13.20%
2025-03-25 20:43:40,800 - training_loop - INFO - 
LatentTransformer - Step 14850/20000 - Val Loss: 1.286942 - Seq Acc: 5.25%
2025-03-25 20:45:05,001 - training_loop - INFO - 
SimpleTransformer - Step 14900/20000 - Val Loss: 1.033867 - Seq Acc: 13.15%
2025-03-25 20:45:09,212 - training_loop - INFO - 
LatentTransformer - Step 14900/20000 - Val Loss: 1.298515 - Seq Acc: 5.60%
2025-03-25 20:46:36,137 - training_loop - INFO - 
SimpleTransformer - Step 14950/20000 - Val Loss: 1.032050 - Seq Acc: 13.10%
2025-03-25 20:46:41,702 - training_loop - INFO - 
LatentTransformer - Step 14950/20000 - Val Loss: 1.342707 - Seq Acc: 5.85%
2025-03-25 20:48:08,676 - training_loop - INFO - 
SimpleTransformer - Step 15000/20000 - Val Loss: 1.027462 - Seq Acc: 13.15%
2025-03-25 20:48:12,404 - training_loop - INFO - 
LatentTransformer - Step 15000/20000 - Val Loss: 1.325693 - Seq Acc: 4.95%
2025-03-25 20:49:34,861 - training_loop - INFO - 
SimpleTransformer - Step 15050/20000 - Val Loss: 1.028985 - Seq Acc: 13.20%
2025-03-25 20:49:39,520 - training_loop - INFO - 
LatentTransformer - Step 15050/20000 - Val Loss: 1.323708 - Seq Acc: 5.25%
2025-03-25 20:51:02,017 - training_loop - INFO - 
SimpleTransformer - Step 15100/20000 - Val Loss: 1.033002 - Seq Acc: 13.10%
2025-03-25 20:51:06,786 - training_loop - INFO - 
LatentTransformer - Step 15100/20000 - Val Loss: 1.305604 - Seq Acc: 5.45%
2025-03-25 20:52:30,702 - training_loop - INFO - 
SimpleTransformer - Step 15150/20000 - Val Loss: 1.030014 - Seq Acc: 13.00%
2025-03-25 20:52:35,770 - training_loop - INFO - 
LatentTransformer - Step 15150/20000 - Val Loss: 1.342727 - Seq Acc: 5.75%
2025-03-25 20:53:55,090 - training_loop - INFO - 
SimpleTransformer - Step 15200/20000 - Val Loss: 1.037804 - Seq Acc: 13.65%
2025-03-25 20:53:58,690 - training_loop - INFO - 
LatentTransformer - Step 15200/20000 - Val Loss: 1.328391 - Seq Acc: 5.40%
2025-03-25 20:55:26,080 - training_loop - INFO - 
SimpleTransformer - Step 15250/20000 - Val Loss: 1.034275 - Seq Acc: 12.75%
2025-03-25 20:55:30,771 - training_loop - INFO - 
LatentTransformer - Step 15250/20000 - Val Loss: 1.331857 - Seq Acc: 4.95%
2025-03-25 20:56:14,438 - __main__ - INFO - Using device: cuda
2025-03-25 20:56:14,438 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 20:56:14,438 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 20:56:14,438 - __main__ - INFO - Attempting to resume from run ID: 20250325-195248_d64_l2_n4
2025-03-25 20:56:14,439 - __main__ - INFO - Found run: 20250325-195248_d64_l2_n4
2025-03-25 20:56:14,439 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 20:56:14,439 - __main__ - INFO - Using d_model=64 from run config (override 768)
2025-03-25 20:56:14,439 - __main__ - INFO - Using num_layers=2 from run config (override 8)
2025-03-25 20:56:14,439 - __main__ - INFO - Using num_latent=4 from run config (override 16)
2025-03-25 20:56:14,439 - __main__ - INFO - Using min_digits=1 from run config (override 3)
2025-03-25 20:56:14,440 - __main__ - INFO - Using max_digits=1 from run config (override 2)
2025-03-25 20:56:14,440 - __main__ - INFO - Using checkpoint paths from run 20250325-195248_d64_l2_n4
2025-03-25 20:56:15,385 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 20:56:15,385 - __main__ - INFO - Updating d_model from 64 to 768 to match checkpoint
2025-03-25 20:56:15,385 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 20:56:15,385 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 20:56:16,107 - __main__ - INFO - 
Model Parameters:
2025-03-25 20:56:16,107 - __main__ - INFO - SimpleTransformer: 33,116,172
2025-03-25 20:56:16,107 - __main__ - INFO - LatentTransformer: 39,616,524
2025-03-25 20:56:16,108 - __main__ - INFO - Parameter ratio: 1.20x
2025-03-25 20:56:16,108 - __main__ - INFO - Difference: 6,500,352 parameters (19.6%)
2025-03-25 20:56:16,110 - src.RunManagement - INFO - Registered run: 20250325-205616_d768_l2_n4
2025-03-25 20:56:16,110 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 20:56:16,112 - src.RunManagement - INFO - Registered run: 20250325-205616_d768_l2_n4
2025-03-25 20:56:16,116 - __main__ - ERROR - Error loading checkpoints: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 
	size mismatch for embed.weight: copying a param with shape torch.Size([11, 768]) from checkpoint, the shape in current model is torch.Size([12, 768]).
	size mismatch for output_proj.weight: copying a param with shape torch.Size([11, 768]) from checkpoint, the shape in current model is torch.Size([12, 768]).
	size mismatch for output_proj.bias: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([12]).
2025-03-25 20:56:16,116 - __main__ - ERROR - Traceback (most recent call last):
  File "/home/h/Devel/latent/main.py", line 536, in main
    simple_transformer.load_state_dict(new_state_dict)
  File "/home/h/.virtualenvs/latent/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 
	size mismatch for embed.weight: copying a param with shape torch.Size([11, 768]) from checkpoint, the shape in current model is torch.Size([12, 768]).
	size mismatch for output_proj.weight: copying a param with shape torch.Size([11, 768]) from checkpoint, the shape in current model is torch.Size([12, 768]).
	size mismatch for output_proj.bias: copying a param with shape torch.Size([11]) from checkpoint, the shape in current model is torch.Size([12]).

2025-03-25 20:56:55,653 - training_loop - INFO - 
SimpleTransformer - Step 15300/20000 - Val Loss: 1.033713 - Seq Acc: 12.75%
2025-03-25 20:57:00,667 - training_loop - INFO - 
LatentTransformer - Step 15300/20000 - Val Loss: 1.322488 - Seq Acc: 5.15%
2025-03-25 20:58:25,122 - training_loop - INFO - 
SimpleTransformer - Step 15350/20000 - Val Loss: 1.028605 - Seq Acc: 12.55%
2025-03-25 20:58:30,494 - training_loop - INFO - 
LatentTransformer - Step 15350/20000 - Val Loss: 1.340946 - Seq Acc: 6.00%
2025-03-25 20:59:57,806 - training_loop - INFO - 
SimpleTransformer - Step 15400/20000 - Val Loss: 1.034558 - Seq Acc: 13.35%
2025-03-25 21:00:02,020 - training_loop - INFO - 
LatentTransformer - Step 15400/20000 - Val Loss: 1.330834 - Seq Acc: 5.75%
2025-03-25 21:00:44,767 - __main__ - INFO - Using device: cuda
2025-03-25 21:00:44,767 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:00:44,767 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:00:44,767 - __main__ - INFO - Attempting to resume from run ID: 20250325-195248_d64_l2_n4
2025-03-25 21:00:44,768 - __main__ - INFO - Found run: 20250325-195248_d64_l2_n4
2025-03-25 21:00:44,768 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 21:00:44,768 - __main__ - INFO - Using d_model=64 from run config (override 768)
2025-03-25 21:00:44,769 - __main__ - INFO - Using num_layers=2 from run config (override 8)
2025-03-25 21:00:44,769 - __main__ - INFO - Using num_latent=4 from run config (override 16)
2025-03-25 21:00:44,769 - __main__ - INFO - Using min_digits=1 from run config (override 3)
2025-03-25 21:00:44,769 - __main__ - INFO - Using max_digits=1 from run config (override 3)
2025-03-25 21:00:44,769 - __main__ - INFO - Using checkpoint paths from run 20250325-195248_d64_l2_n4
2025-03-25 21:00:45,998 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:00:45,999 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 21:00:45,999 - __main__ - INFO - Updating d_model from 64 to 768 to match checkpoint
2025-03-25 21:00:45,999 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:00:45,999 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:00:46,000 - __main__ - INFO - Using vocabulary size: 11
2025-03-25 21:00:46,794 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:00:46,794 - __main__ - INFO - SimpleTransformer: 33,114,635
2025-03-25 21:00:46,794 - __main__ - INFO - LatentTransformer: 39,614,987
2025-03-25 21:00:46,794 - __main__ - INFO - Parameter ratio: 1.20x
2025-03-25 21:00:46,794 - __main__ - INFO - Difference: 6,500,352 parameters (19.6%)
2025-03-25 21:00:46,796 - src.RunManagement - INFO - Registered run: 20250325-210046_d768_l2_n4
2025-03-25 21:00:46,797 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:00:46,798 - src.RunManagement - INFO - Registered run: 20250325-210046_d768_l2_n4
2025-03-25 21:00:46,804 - __main__ - ERROR - Error loading checkpoints: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 
2025-03-25 21:00:46,805 - __main__ - ERROR - Traceback (most recent call last):
  File "/home/h/Devel/latent/main.py", line 551, in main
    simple_transformer.load_state_dict(new_state_dict)
  File "/home/h/.virtualenvs/latent/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 

2025-03-25 21:01:38,526 - training_loop - INFO - 
SimpleTransformer - Step 15450/20000 - Val Loss: 1.032175 - Seq Acc: 13.20%
2025-03-25 21:01:38,592 - __main__ - INFO - Using device: cuda
2025-03-25 21:01:38,592 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:01:38,592 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:01:38,592 - __main__ - INFO - Attempting to resume from run ID: 20250325-195248_d64_l2_n4
2025-03-25 21:01:38,593 - __main__ - INFO - Found run: 20250325-195248_d64_l2_n4
2025-03-25 21:01:38,593 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 21:01:38,593 - __main__ - INFO - Using d_model=64 from run config (override 768)
2025-03-25 21:01:38,593 - __main__ - INFO - Using num_layers=2 from run config (override 8)
2025-03-25 21:01:38,593 - __main__ - INFO - Using num_latent=4 from run config (override 16)
2025-03-25 21:01:38,593 - __main__ - INFO - Using min_digits=1 from run config (override 3)
2025-03-25 21:01:38,593 - __main__ - INFO - Using max_digits=1 from run config (override 3)
2025-03-25 21:01:38,594 - __main__ - INFO - Using checkpoint paths from run 20250325-195248_d64_l2_n4
2025-03-25 21:01:39,595 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:01:39,595 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 21:01:39,595 - __main__ - INFO - Updating d_model from 64 to 768 to match checkpoint
2025-03-25 21:01:39,595 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:01:39,596 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:01:39,596 - __main__ - INFO - Using vocabulary size: 11
2025-03-25 21:01:40,314 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:01:40,314 - __main__ - INFO - SimpleTransformer: 33,114,635
2025-03-25 21:01:40,314 - __main__ - INFO - LatentTransformer: 39,614,987
2025-03-25 21:01:40,314 - __main__ - INFO - Parameter ratio: 1.20x
2025-03-25 21:01:40,314 - __main__ - INFO - Difference: 6,500,352 parameters (19.6%)
2025-03-25 21:01:40,316 - src.RunManagement - INFO - Registered run: 20250325-210140_d768_l2_n4
2025-03-25 21:01:40,316 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:01:40,319 - src.RunManagement - INFO - Registered run: 20250325-210140_d768_l2_n4
2025-03-25 21:01:40,323 - __main__ - ERROR - Error loading checkpoints: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 
2025-03-25 21:01:40,324 - __main__ - ERROR - Traceback (most recent call last):
  File "/home/h/Devel/latent/main.py", line 551, in main
    simple_transformer.load_state_dict(new_state_dict)
  File "/home/h/.virtualenvs/latent/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 

2025-03-25 21:01:43,543 - training_loop - INFO - 
LatentTransformer - Step 15450/20000 - Val Loss: 1.340268 - Seq Acc: 5.45%
2025-03-25 21:03:11,139 - training_loop - INFO - 
SimpleTransformer - Step 15500/20000 - Val Loss: 1.028259 - Seq Acc: 13.25%
2025-03-25 21:03:15,944 - training_loop - INFO - 
LatentTransformer - Step 15500/20000 - Val Loss: 1.335573 - Seq Acc: 5.20%
2025-03-25 21:04:03,746 - __main__ - INFO - Using device: cuda
2025-03-25 21:04:03,747 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:04:03,747 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:04:03,747 - __main__ - INFO - Attempting to resume from run ID: 20250325-195248_d64_l2_n4
2025-03-25 21:04:03,747 - __main__ - INFO - Found run: 20250325-195248_d64_l2_n4
2025-03-25 21:04:03,748 - __main__ - INFO - Using seed=42 from run config (override 42)
2025-03-25 21:04:03,748 - __main__ - INFO - Using d_model=64 from run config (override 768)
2025-03-25 21:04:03,748 - __main__ - INFO - Using num_layers=2 from run config (override 8)
2025-03-25 21:04:03,748 - __main__ - INFO - Using num_latent=4 from run config (override 16)
2025-03-25 21:04:03,748 - __main__ - INFO - Using min_digits=1 from run config (override 3)
2025-03-25 21:04:03,748 - __main__ - INFO - Using max_digits=1 from run config (override 2)
2025-03-25 21:04:03,749 - __main__ - INFO - Using checkpoint paths from run 20250325-195248_d64_l2_n4
2025-03-25 21:04:04,728 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:04:04,728 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 21:04:04,728 - __main__ - INFO - Updating d_model from 64 to 768 to match checkpoint
2025-03-25 21:04:04,728 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:04:04,729 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:04:04,729 - __main__ - INFO - Using vocabulary size: 11
2025-03-25 21:04:05,457 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:04:05,457 - __main__ - INFO - SimpleTransformer: 33,114,635
2025-03-25 21:04:05,457 - __main__ - INFO - LatentTransformer: 39,614,987
2025-03-25 21:04:05,458 - __main__ - INFO - Parameter ratio: 1.20x
2025-03-25 21:04:05,458 - __main__ - INFO - Difference: 6,500,352 parameters (19.6%)
2025-03-25 21:04:05,460 - src.RunManagement - INFO - Registered run: 20250325-210405_d768_l2_n4
2025-03-25 21:04:05,460 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:04:05,463 - src.RunManagement - INFO - Registered run: 20250325-210405_d768_l2_n4
2025-03-25 21:04:05,466 - __main__ - ERROR - Error loading checkpoints: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 
2025-03-25 21:04:05,467 - __main__ - ERROR - Traceback (most recent call last):
  File "/home/h/Devel/latent/main.py", line 551, in main
    simple_transformer.load_state_dict(new_state_dict)
  File "/home/h/.virtualenvs/latent/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 

2025-03-25 21:04:45,886 - training_loop - INFO - 
SimpleTransformer - Step 15550/20000 - Val Loss: 1.023593 - Seq Acc: 13.10%
2025-03-25 21:04:50,649 - training_loop - INFO - 
LatentTransformer - Step 15550/20000 - Val Loss: 1.355130 - Seq Acc: 5.55%
2025-03-25 21:06:20,512 - training_loop - INFO - 
SimpleTransformer - Step 15600/20000 - Val Loss: 1.025133 - Seq Acc: 12.75%
2025-03-25 21:06:24,561 - training_loop - INFO - 
LatentTransformer - Step 15600/20000 - Val Loss: 1.350042 - Seq Acc: 6.00%
2025-03-25 21:07:44,651 - training_loop - INFO - 
SimpleTransformer - Step 15650/20000 - Val Loss: 1.025051 - Seq Acc: 12.95%
2025-03-25 21:07:48,666 - training_loop - INFO - 
LatentTransformer - Step 15650/20000 - Val Loss: 1.342756 - Seq Acc: 5.00%
2025-03-25 21:08:41,314 - __main__ - INFO - Using device: cuda
2025-03-25 21:08:41,314 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:08:41,314 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:08:41,314 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:08:41,315 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:08:41,315 - __main__ - INFO - Using vocabulary size: 12
2025-03-25 21:08:41,589 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:08:41,589 - __main__ - INFO - SimpleTransformer: 236,556
2025-03-25 21:08:41,589 - __main__ - INFO - LatentTransformer: 282,636
2025-03-25 21:08:41,589 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 21:08:41,589 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 21:08:41,591 - src.RunManagement - INFO - Registered run: 20250325-210841_d64_l2_n4
2025-03-25 21:08:41,592 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:08:41,594 - src.RunManagement - INFO - Registered run: 20250325-210841_d64_l2_n4
2025-03-25 21:08:41,594 - src.TrainingLoop - INFO - Using max_steps from args: 20
2025-03-25 21:08:41,594 - src.TrainingLoop - INFO - Target steps for full training: 20 (max_steps=20, continuation=0)
2025-03-25 21:08:41,597 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 21:08:43,729 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 21:08:43,734 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 21:08:43,735 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 21:09:19,448 - training_loop - INFO - 
SimpleTransformer - Step 15700/20000 - Val Loss: 1.027913 - Seq Acc: 12.90%
2025-03-25 21:09:23,780 - training_loop - INFO - 
LatentTransformer - Step 15700/20000 - Val Loss: 1.345233 - Seq Acc: 5.40%
2025-03-25 21:09:47,888 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 21:09:47,954 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 0.000000)
2025-03-25 21:09:51,488 - src.TrainingLoop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 21:09:51,540 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 0.000000)
2025-03-25 21:09:52,678 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 21:09:53,051 - src.TrainingLoop - INFO - 
LatentTransformer - Step 20/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 21:09:53,097 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 20/20, LatentTransformer: 20/20
2025-03-25 21:09:53,710 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 21:09:53,710 - src.TrainingLoop - INFO - Steps completed: 20/20
2025-03-25 21:09:53,710 - src.TrainingLoop - INFO - Best validation loss: 0.000000
2025-03-25 21:09:53,710 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:09:53,710 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:09:53,710 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:09:53,710 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 21:09:53,711 - src.TrainingLoop - INFO - Steps completed: 20/20
2025-03-25 21:09:53,711 - src.TrainingLoop - INFO - Best validation loss: 0.000000
2025-03-25 21:09:53,711 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:09:53,711 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:09:53,711 - src.TrainingLoop - INFO - Final digit accuracy: 0.00%
2025-03-25 21:09:53,714 - __main__ - INFO - 
Final Comparison:
2025-03-25 21:09:53,714 - __main__ - INFO - ==================================================
2025-03-25 21:09:53,714 - __main__ - INFO - Training time: 69.98s
2025-03-25 21:09:53,714 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-25 21:09:53,715 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-25 21:09:53,715 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 21:09:53,715 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 21:09:53,715 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-210841_d64_l2_n4
2025-03-25 21:10:06,497 - __main__ - INFO - Using device: cuda
2025-03-25 21:10:06,497 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:10:06,497 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:10:06,497 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:10:06,497 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:10:06,498 - __main__ - INFO - Using vocabulary size: 12
2025-03-25 21:10:06,790 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:10:06,791 - __main__ - INFO - SimpleTransformer: 236,556
2025-03-25 21:10:06,791 - __main__ - INFO - LatentTransformer: 282,636
2025-03-25 21:10:06,791 - __main__ - INFO - Parameter ratio: 1.19x
2025-03-25 21:10:06,791 - __main__ - INFO - Difference: 46,080 parameters (19.5%)
2025-03-25 21:10:06,794 - src.RunManagement - INFO - Registered run: 20250325-211006_d64_l2_n4
2025-03-25 21:10:06,794 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:10:06,796 - src.RunManagement - INFO - Registered run: 20250325-211006_d64_l2_n4
2025-03-25 21:10:06,796 - src.TrainingLoop - INFO - Using max_steps from args: 20
2025-03-25 21:10:06,796 - src.TrainingLoop - INFO - Target steps for full training: 20 (max_steps=20, continuation=0)
2025-03-25 21:10:06,799 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 21:10:08,928 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 21:10:08,935 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 21:10:08,936 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 21:10:32,785 - src.TrainingLoop - INFO - 
SimpleTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 21:10:32,825 - src.TrainingLoop - INFO - Saved new best model for SimpleTransformer (val_loss: 0.000000)
2025-03-25 21:10:34,989 - src.TrainingLoop - INFO - 
LatentTransformer - Step 10/20 - Val Loss: 0.000000 - Seq Acc: 0.00%
2025-03-25 21:10:35,040 - src.TrainingLoop - INFO - Saved new best model for LatentTransformer (val_loss: 0.000000)
2025-03-25 21:11:00,058 - training_loop - INFO - 
SimpleTransformer - Step 15750/20000 - Val Loss: 1.026942 - Seq Acc: 12.80%
2025-03-25 21:11:03,914 - training_loop - INFO - 
LatentTransformer - Step 15750/20000 - Val Loss: 1.346298 - Seq Acc: 5.85%
2025-03-25 21:12:32,589 - training_loop - INFO - 
SimpleTransformer - Step 15800/20000 - Val Loss: 1.027038 - Seq Acc: 12.55%
2025-03-25 21:12:36,934 - training_loop - INFO - 
LatentTransformer - Step 15800/20000 - Val Loss: 1.348389 - Seq Acc: 5.95%
2025-03-25 21:12:53,936 - __main__ - INFO - Using device: cuda
2025-03-25 21:12:53,936 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:12:53,936 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:12:53,936 - __main__ - INFO - Attempting to resume from run ID: 20250325-211006_d64_l2_n4
2025-03-25 21:12:53,937 - __main__ - INFO - Found run: 20250325-211006_d64_l2_n4
2025-03-25 21:12:53,937 - __main__ - INFO - Using checkpoint paths from run 20250325-211006_d64_l2_n4
2025-03-25 21:12:54,870 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:12:54,871 - __main__ - INFO - Using train dataset with range 100-99
2025-03-25 21:14:08,714 - training_loop - INFO - 
SimpleTransformer - Step 15850/20000 - Val Loss: 1.026874 - Seq Acc: 13.05%
2025-03-25 21:14:12,759 - training_loop - INFO - 
LatentTransformer - Step 15850/20000 - Val Loss: 1.332606 - Seq Acc: 5.85%
2025-03-25 21:15:41,518 - training_loop - INFO - 
SimpleTransformer - Step 15900/20000 - Val Loss: 1.025665 - Seq Acc: 12.85%
2025-03-25 21:15:46,778 - training_loop - INFO - 
LatentTransformer - Step 15900/20000 - Val Loss: 1.348389 - Seq Acc: 5.45%
2025-03-25 21:17:49,881 - __main__ - INFO - Using device: cuda
2025-03-25 21:17:49,881 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:17:49,881 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:17:49,881 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:17:49,882 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:17:49,882 - __main__ - INFO - Using vocabulary size: 12
2025-03-25 21:17:50,300 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:17:50,300 - __main__ - INFO - SimpleTransformer: 31,244
2025-03-25 21:17:50,300 - __main__ - INFO - LatentTransformer: 42,924
2025-03-25 21:17:50,301 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 21:17:50,301 - __main__ - INFO - Difference: 11,680 parameters (37.4%)
2025-03-25 21:17:50,306 - src.RunManagement - INFO - Registered run: 20250325-211750_d32_l1_n1
2025-03-25 21:17:50,306 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:17:50,311 - src.RunManagement - INFO - Registered run: 20250325-211750_d32_l1_n1
2025-03-25 21:17:50,312 - src.TrainingLoop - INFO - Using max_steps from args: 5
2025-03-25 21:17:50,312 - src.TrainingLoop - INFO - Target steps for full training: 5 (max_steps=5, continuation=0)
2025-03-25 21:17:50,316 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 21:17:53,147 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 21:17:53,149 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 21:17:53,150 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 21:18:31,697 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 5/5, LatentTransformer: 5/5
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 21:18:38,003 - src.TrainingLoop - INFO - Steps completed: 5/5
2025-03-25 21:18:38,004 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:18:38,004 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:18:38,004 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:18:38,004 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:18:38,007 - __main__ - INFO - 
Final Comparison:
2025-03-25 21:18:38,007 - __main__ - INFO - ==================================================
2025-03-25 21:18:38,007 - __main__ - INFO - Training time: 44.86s
2025-03-25 21:18:38,007 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-25 21:18:38,007 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 42,924 parameters
2025-03-25 21:18:38,007 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 21:18:38,008 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 21:18:38,008 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-211750_d32_l1_n1
2025-03-25 21:19:17,230 - __main__ - INFO - Using device: cuda
2025-03-25 21:19:17,230 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:19:17,230 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:19:17,230 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:19:17,231 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:19:17,231 - __main__ - INFO - Using vocabulary size: 12
2025-03-25 21:19:17,528 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:19:17,529 - __main__ - INFO - SimpleTransformer: 31,244
2025-03-25 21:19:17,529 - __main__ - INFO - LatentTransformer: 42,924
2025-03-25 21:19:17,529 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 21:19:17,529 - __main__ - INFO - Difference: 11,680 parameters (37.4%)
2025-03-25 21:19:17,532 - src.RunManagement - INFO - Registered run: 20250325-211917_d32_l1_n1
2025-03-25 21:19:17,532 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:19:17,535 - src.RunManagement - INFO - Registered run: 20250325-211917_d32_l1_n1
2025-03-25 21:19:17,535 - src.TrainingLoop - INFO - Using max_steps from args: 3
2025-03-25 21:19:17,535 - src.TrainingLoop - INFO - Target steps for full training: 3 (max_steps=3, continuation=0)
2025-03-25 21:19:17,538 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 21:19:19,809 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 21:19:19,812 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 21:19:19,812 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 21:19:27,008 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 3/3, LatentTransformer: 3/3
2025-03-25 21:19:30,618 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - Steps completed: 3/3
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - Steps completed: 3/3
2025-03-25 21:19:30,619 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:19:30,620 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:19:30,620 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:19:30,620 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:19:30,622 - __main__ - INFO - 
Final Comparison:
2025-03-25 21:19:30,622 - __main__ - INFO - ==================================================
2025-03-25 21:19:30,622 - __main__ - INFO - Training time: 10.81s
2025-03-25 21:19:30,622 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-25 21:19:30,623 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 42,924 parameters
2025-03-25 21:19:30,623 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 21:19:30,623 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 21:19:30,623 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-211917_d32_l1_n1
2025-03-25 21:19:33,889 - __main__ - INFO - Using device: cuda
2025-03-25 21:19:33,889 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:19:33,889 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:19:33,889 - __main__ - INFO - Attempting to resume from run ID: 20250325-211917_d32_l1_n1
2025-03-25 21:19:33,890 - __main__ - INFO - Found run: 20250325-211917_d32_l1_n1
2025-03-25 21:19:33,891 - __main__ - INFO - Using checkpoint paths from run 20250325-211917_d32_l1_n1
2025-03-25 21:19:34,845 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:19:34,845 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 21:19:34,845 - __main__ - INFO - Updating d_model from 32 to 768 to match checkpoint
2025-03-25 21:19:34,845 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:19:34,846 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:19:34,846 - __main__ - INFO - Using vocabulary size: 11
2025-03-25 21:19:35,288 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:19:35,288 - __main__ - INFO - SimpleTransformer: 16,574,987
2025-03-25 21:19:35,289 - __main__ - INFO - LatentTransformer: 23,073,035
2025-03-25 21:19:35,289 - __main__ - INFO - Parameter ratio: 1.39x
2025-03-25 21:19:35,289 - __main__ - INFO - Difference: 6,498,048 parameters (39.2%)
2025-03-25 21:19:35,291 - src.RunManagement - INFO - Registered run: 20250325-211935_d768_l1_n1
2025-03-25 21:19:35,291 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:19:35,294 - src.RunManagement - INFO - Registered run: 20250325-211935_d768_l1_n1
2025-03-25 21:19:35,296 - __main__ - ERROR - Error loading checkpoints: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.1.self_attn.in_proj_weight", "encoder.layers.1.self_attn.in_proj_bias", "encoder.layers.1.self_attn.out_proj.weight", "encoder.layers.1.self_attn.out_proj.bias", "encoder.layers.1.linear1.weight", "encoder.layers.1.linear1.bias", "encoder.layers.1.linear2.weight", "encoder.layers.1.linear2.bias", "encoder.layers.1.norm1.weight", "encoder.layers.1.norm1.bias", "encoder.layers.1.norm2.weight", "encoder.layers.1.norm2.bias", "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.1.self_attn.in_proj_weight", "decoder.layers.1.self_attn.in_proj_bias", "decoder.layers.1.self_attn.out_proj.weight", "decoder.layers.1.self_attn.out_proj.bias", "decoder.layers.1.multihead_attn.in_proj_weight", "decoder.layers.1.multihead_attn.in_proj_bias", "decoder.layers.1.multihead_attn.out_proj.weight", "decoder.layers.1.multihead_attn.out_proj.bias", "decoder.layers.1.linear1.weight", "decoder.layers.1.linear1.bias", "decoder.layers.1.linear2.weight", "decoder.layers.1.linear2.bias", "decoder.layers.1.norm1.weight", "decoder.layers.1.norm1.bias", "decoder.layers.1.norm2.weight", "decoder.layers.1.norm2.bias", "decoder.layers.1.norm3.weight", "decoder.layers.1.norm3.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 
2025-03-25 21:19:35,297 - __main__ - ERROR - Traceback (most recent call last):
  File "/home/h/Devel/latent/main.py", line 551, in main
    simple_transformer.load_state_dict(new_state_dict)
  File "/home/h/.virtualenvs/latent/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StableSimpleTransformer:
	Unexpected key(s) in state_dict: "encoder.layers.1.self_attn.in_proj_weight", "encoder.layers.1.self_attn.in_proj_bias", "encoder.layers.1.self_attn.out_proj.weight", "encoder.layers.1.self_attn.out_proj.bias", "encoder.layers.1.linear1.weight", "encoder.layers.1.linear1.bias", "encoder.layers.1.linear2.weight", "encoder.layers.1.linear2.bias", "encoder.layers.1.norm1.weight", "encoder.layers.1.norm1.bias", "encoder.layers.1.norm2.weight", "encoder.layers.1.norm2.bias", "encoder.layers.2.self_attn.in_proj_weight", "encoder.layers.2.self_attn.in_proj_bias", "encoder.layers.2.self_attn.out_proj.weight", "encoder.layers.2.self_attn.out_proj.bias", "encoder.layers.2.linear1.weight", "encoder.layers.2.linear1.bias", "encoder.layers.2.linear2.weight", "encoder.layers.2.linear2.bias", "encoder.layers.2.norm1.weight", "encoder.layers.2.norm1.bias", "encoder.layers.2.norm2.weight", "encoder.layers.2.norm2.bias", "encoder.layers.3.self_attn.in_proj_weight", "encoder.layers.3.self_attn.in_proj_bias", "encoder.layers.3.self_attn.out_proj.weight", "encoder.layers.3.self_attn.out_proj.bias", "encoder.layers.3.linear1.weight", "encoder.layers.3.linear1.bias", "encoder.layers.3.linear2.weight", "encoder.layers.3.linear2.bias", "encoder.layers.3.norm1.weight", "encoder.layers.3.norm1.bias", "encoder.layers.3.norm2.weight", "encoder.layers.3.norm2.bias", "encoder.layers.4.self_attn.in_proj_weight", "encoder.layers.4.self_attn.in_proj_bias", "encoder.layers.4.self_attn.out_proj.weight", "encoder.layers.4.self_attn.out_proj.bias", "encoder.layers.4.linear1.weight", "encoder.layers.4.linear1.bias", "encoder.layers.4.linear2.weight", "encoder.layers.4.linear2.bias", "encoder.layers.4.norm1.weight", "encoder.layers.4.norm1.bias", "encoder.layers.4.norm2.weight", "encoder.layers.4.norm2.bias", "encoder.layers.5.self_attn.in_proj_weight", "encoder.layers.5.self_attn.in_proj_bias", "encoder.layers.5.self_attn.out_proj.weight", "encoder.layers.5.self_attn.out_proj.bias", "encoder.layers.5.linear1.weight", "encoder.layers.5.linear1.bias", "encoder.layers.5.linear2.weight", "encoder.layers.5.linear2.bias", "encoder.layers.5.norm1.weight", "encoder.layers.5.norm1.bias", "encoder.layers.5.norm2.weight", "encoder.layers.5.norm2.bias", "encoder.layers.6.self_attn.in_proj_weight", "encoder.layers.6.self_attn.in_proj_bias", "encoder.layers.6.self_attn.out_proj.weight", "encoder.layers.6.self_attn.out_proj.bias", "encoder.layers.6.linear1.weight", "encoder.layers.6.linear1.bias", "encoder.layers.6.linear2.weight", "encoder.layers.6.linear2.bias", "encoder.layers.6.norm1.weight", "encoder.layers.6.norm1.bias", "encoder.layers.6.norm2.weight", "encoder.layers.6.norm2.bias", "encoder.layers.7.self_attn.in_proj_weight", "encoder.layers.7.self_attn.in_proj_bias", "encoder.layers.7.self_attn.out_proj.weight", "encoder.layers.7.self_attn.out_proj.bias", "encoder.layers.7.linear1.weight", "encoder.layers.7.linear1.bias", "encoder.layers.7.linear2.weight", "encoder.layers.7.linear2.bias", "encoder.layers.7.norm1.weight", "encoder.layers.7.norm1.bias", "encoder.layers.7.norm2.weight", "encoder.layers.7.norm2.bias", "decoder.layers.1.self_attn.in_proj_weight", "decoder.layers.1.self_attn.in_proj_bias", "decoder.layers.1.self_attn.out_proj.weight", "decoder.layers.1.self_attn.out_proj.bias", "decoder.layers.1.multihead_attn.in_proj_weight", "decoder.layers.1.multihead_attn.in_proj_bias", "decoder.layers.1.multihead_attn.out_proj.weight", "decoder.layers.1.multihead_attn.out_proj.bias", "decoder.layers.1.linear1.weight", "decoder.layers.1.linear1.bias", "decoder.layers.1.linear2.weight", "decoder.layers.1.linear2.bias", "decoder.layers.1.norm1.weight", "decoder.layers.1.norm1.bias", "decoder.layers.1.norm2.weight", "decoder.layers.1.norm2.bias", "decoder.layers.1.norm3.weight", "decoder.layers.1.norm3.bias", "decoder.layers.2.self_attn.in_proj_weight", "decoder.layers.2.self_attn.in_proj_bias", "decoder.layers.2.self_attn.out_proj.weight", "decoder.layers.2.self_attn.out_proj.bias", "decoder.layers.2.multihead_attn.in_proj_weight", "decoder.layers.2.multihead_attn.in_proj_bias", "decoder.layers.2.multihead_attn.out_proj.weight", "decoder.layers.2.multihead_attn.out_proj.bias", "decoder.layers.2.linear1.weight", "decoder.layers.2.linear1.bias", "decoder.layers.2.linear2.weight", "decoder.layers.2.linear2.bias", "decoder.layers.2.norm1.weight", "decoder.layers.2.norm1.bias", "decoder.layers.2.norm2.weight", "decoder.layers.2.norm2.bias", "decoder.layers.2.norm3.weight", "decoder.layers.2.norm3.bias", "decoder.layers.3.self_attn.in_proj_weight", "decoder.layers.3.self_attn.in_proj_bias", "decoder.layers.3.self_attn.out_proj.weight", "decoder.layers.3.self_attn.out_proj.bias", "decoder.layers.3.multihead_attn.in_proj_weight", "decoder.layers.3.multihead_attn.in_proj_bias", "decoder.layers.3.multihead_attn.out_proj.weight", "decoder.layers.3.multihead_attn.out_proj.bias", "decoder.layers.3.linear1.weight", "decoder.layers.3.linear1.bias", "decoder.layers.3.linear2.weight", "decoder.layers.3.linear2.bias", "decoder.layers.3.norm1.weight", "decoder.layers.3.norm1.bias", "decoder.layers.3.norm2.weight", "decoder.layers.3.norm2.bias", "decoder.layers.3.norm3.weight", "decoder.layers.3.norm3.bias", "decoder.layers.4.self_attn.in_proj_weight", "decoder.layers.4.self_attn.in_proj_bias", "decoder.layers.4.self_attn.out_proj.weight", "decoder.layers.4.self_attn.out_proj.bias", "decoder.layers.4.multihead_attn.in_proj_weight", "decoder.layers.4.multihead_attn.in_proj_bias", "decoder.layers.4.multihead_attn.out_proj.weight", "decoder.layers.4.multihead_attn.out_proj.bias", "decoder.layers.4.linear1.weight", "decoder.layers.4.linear1.bias", "decoder.layers.4.linear2.weight", "decoder.layers.4.linear2.bias", "decoder.layers.4.norm1.weight", "decoder.layers.4.norm1.bias", "decoder.layers.4.norm2.weight", "decoder.layers.4.norm2.bias", "decoder.layers.4.norm3.weight", "decoder.layers.4.norm3.bias", "decoder.layers.5.self_attn.in_proj_weight", "decoder.layers.5.self_attn.in_proj_bias", "decoder.layers.5.self_attn.out_proj.weight", "decoder.layers.5.self_attn.out_proj.bias", "decoder.layers.5.multihead_attn.in_proj_weight", "decoder.layers.5.multihead_attn.in_proj_bias", "decoder.layers.5.multihead_attn.out_proj.weight", "decoder.layers.5.multihead_attn.out_proj.bias", "decoder.layers.5.linear1.weight", "decoder.layers.5.linear1.bias", "decoder.layers.5.linear2.weight", "decoder.layers.5.linear2.bias", "decoder.layers.5.norm1.weight", "decoder.layers.5.norm1.bias", "decoder.layers.5.norm2.weight", "decoder.layers.5.norm2.bias", "decoder.layers.5.norm3.weight", "decoder.layers.5.norm3.bias", "decoder.layers.6.self_attn.in_proj_weight", "decoder.layers.6.self_attn.in_proj_bias", "decoder.layers.6.self_attn.out_proj.weight", "decoder.layers.6.self_attn.out_proj.bias", "decoder.layers.6.multihead_attn.in_proj_weight", "decoder.layers.6.multihead_attn.in_proj_bias", "decoder.layers.6.multihead_attn.out_proj.weight", "decoder.layers.6.multihead_attn.out_proj.bias", "decoder.layers.6.linear1.weight", "decoder.layers.6.linear1.bias", "decoder.layers.6.linear2.weight", "decoder.layers.6.linear2.bias", "decoder.layers.6.norm1.weight", "decoder.layers.6.norm1.bias", "decoder.layers.6.norm2.weight", "decoder.layers.6.norm2.bias", "decoder.layers.6.norm3.weight", "decoder.layers.6.norm3.bias", "decoder.layers.7.self_attn.in_proj_weight", "decoder.layers.7.self_attn.in_proj_bias", "decoder.layers.7.self_attn.out_proj.weight", "decoder.layers.7.self_attn.out_proj.bias", "decoder.layers.7.multihead_attn.in_proj_weight", "decoder.layers.7.multihead_attn.in_proj_bias", "decoder.layers.7.multihead_attn.out_proj.weight", "decoder.layers.7.multihead_attn.out_proj.bias", "decoder.layers.7.linear1.weight", "decoder.layers.7.linear1.bias", "decoder.layers.7.linear2.weight", "decoder.layers.7.linear2.bias", "decoder.layers.7.norm1.weight", "decoder.layers.7.norm1.bias", "decoder.layers.7.norm2.weight", "decoder.layers.7.norm2.bias", "decoder.layers.7.norm3.weight", "decoder.layers.7.norm3.bias". 

2025-03-25 21:20:28,065 - __main__ - INFO - Using device: cuda
2025-03-25 21:20:28,065 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:20:28,065 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:20:28,065 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:20:28,066 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:20:28,066 - __main__ - INFO - Using vocabulary size: 12
2025-03-25 21:20:28,346 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:20:28,347 - __main__ - INFO - SimpleTransformer: 31,244
2025-03-25 21:20:28,347 - __main__ - INFO - LatentTransformer: 42,924
2025-03-25 21:20:28,347 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 21:20:28,347 - __main__ - INFO - Difference: 11,680 parameters (37.4%)
2025-03-25 21:20:28,349 - src.RunManagement - INFO - Registered run: 20250325-212028_d32_l1_n1
2025-03-25 21:20:28,350 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:20:28,352 - src.RunManagement - INFO - Registered run: 20250325-212028_d32_l1_n1
2025-03-25 21:20:28,352 - src.TrainingLoop - INFO - Using max_steps from args: 3
2025-03-25 21:20:28,352 - src.TrainingLoop - INFO - Target steps for full training: 3 (max_steps=3, continuation=0)
2025-03-25 21:20:28,355 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 21:20:30,551 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 21:20:30,552 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 21:20:30,553 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 21:20:37,626 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 3/3, LatentTransformer: 3/3
2025-03-25 21:20:41,186 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Steps completed: 3/3
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Steps completed: 3/3
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:20:41,187 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:20:41,188 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:20:41,190 - __main__ - INFO - 
Final Comparison:
2025-03-25 21:20:41,191 - __main__ - INFO - ==================================================
2025-03-25 21:20:41,191 - __main__ - INFO - Training time: 10.64s
2025-03-25 21:20:41,191 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-25 21:20:41,191 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 42,924 parameters
2025-03-25 21:20:41,191 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 21:20:41,191 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 21:20:41,191 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-212028_d32_l1_n1
2025-03-25 21:20:44,084 - __main__ - INFO - Using device: cuda
2025-03-25 21:20:44,085 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:20:44,085 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:20:44,085 - __main__ - INFO - Attempting to resume from run ID: 20250325-212028_d32_l1_n1
2025-03-25 21:20:44,085 - __main__ - INFO - Found run: 20250325-212028_d32_l1_n1
2025-03-25 21:20:44,086 - __main__ - INFO - Using checkpoint paths from run 20250325-212028_d32_l1_n1
2025-03-25 21:20:45,103 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:20:45,103 - __main__ - INFO - Detected 8 layers from checkpoint state dict
2025-03-25 21:20:45,103 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 21:20:45,103 - __main__ - INFO - Updating d_model from 32 to 768 to match checkpoint
2025-03-25 21:20:45,104 - __main__ - INFO - Updating num_layers from 1 to 8 to match checkpoint
2025-03-25 21:20:45,104 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:20:45,104 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:20:45,105 - __main__ - INFO - Using vocabulary size: 11
2025-03-25 21:20:47,001 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:20:47,002 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 21:20:47,002 - __main__ - INFO - LatentTransformer: 138,850,571
2025-03-25 21:20:47,002 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 21:20:47,002 - __main__ - INFO - Difference: 6,498,048 parameters (4.9%)
2025-03-25 21:20:47,005 - src.RunManagement - INFO - Registered run: 20250325-212047_d768_l8_n1
2025-03-25 21:20:47,005 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:20:47,007 - src.RunManagement - INFO - Registered run: 20250325-212047_d768_l8_n1
2025-03-25 21:20:47,029 - __main__ - INFO - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 21:20:47,029 - __main__ - INFO - Resuming SimpleTransformer from step 15900
2025-03-25 21:20:47,042 - __main__ - ERROR - Error loading checkpoints: Error(s) in loading state_dict for StableLatentTransformer:
	size mismatch for latent_tokens: copying a param with shape torch.Size([16, 768]) from checkpoint, the shape in current model is torch.Size([1, 768]).
2025-03-25 21:20:47,043 - __main__ - ERROR - Traceback (most recent call last):
  File "/home/h/Devel/latent/main.py", line 603, in main
    latent_transformer.load_state_dict(new_state_dict)
  File "/home/h/.virtualenvs/latent/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StableLatentTransformer:
	size mismatch for latent_tokens: copying a param with shape torch.Size([16, 768]) from checkpoint, the shape in current model is torch.Size([1, 768]).

2025-03-25 21:21:56,319 - __main__ - INFO - Using device: cuda
2025-03-25 21:21:56,319 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:21:56,320 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:21:56,320 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:21:56,320 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:21:56,321 - __main__ - INFO - Using vocabulary size: 12
2025-03-25 21:21:56,598 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:21:56,599 - __main__ - INFO - SimpleTransformer: 31,244
2025-03-25 21:21:56,599 - __main__ - INFO - LatentTransformer: 42,924
2025-03-25 21:21:56,599 - __main__ - INFO - Parameter ratio: 1.37x
2025-03-25 21:21:56,599 - __main__ - INFO - Difference: 11,680 parameters (37.4%)
2025-03-25 21:21:56,601 - src.RunManagement - INFO - Registered run: 20250325-212156_d32_l1_n1
2025-03-25 21:21:56,602 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:21:56,604 - src.RunManagement - INFO - Registered run: 20250325-212156_d32_l1_n1
2025-03-25 21:21:56,604 - src.TrainingLoop - INFO - Using max_steps from args: 3
2025-03-25 21:21:56,605 - src.TrainingLoop - INFO - Target steps for full training: 3 (max_steps=3, continuation=0)
2025-03-25 21:21:56,607 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 21:21:58,733 - src.TrainingLoop - INFO - Precomputing val set with range 10-5
2025-03-25 21:21:58,734 - src.TrainingLoop - INFO - Created 10 evaluation examples
2025-03-25 21:21:58,735 - src.TrainingLoop - INFO - Starting: Training (steps)
2025-03-25 21:22:06,572 - src.TrainingLoop - INFO - Both models reached their target steps. SimpleTransformer: 3/3, LatentTransformer: 3/3
2025-03-25 21:22:10,578 - src.TrainingLoop - INFO - 
SimpleTransformer Training Summary:
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - Steps completed: 3/3
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - 
LatentTransformer Training Summary:
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - Steps completed: 3/3
2025-03-25 21:22:10,579 - src.TrainingLoop - INFO - Best validation loss: inf
2025-03-25 21:22:10,580 - src.TrainingLoop - INFO - Final validation loss: 0.000000
2025-03-25 21:22:10,580 - src.TrainingLoop - INFO - Final sequence accuracy: 0.00%
2025-03-25 21:22:10,580 - src.TrainingLoop - INFO - Final digit accuracy: 9.09%
2025-03-25 21:22:10,583 - __main__ - INFO - 
Final Comparison:
2025-03-25 21:22:10,583 - __main__ - INFO - ==================================================
2025-03-25 21:22:10,583 - __main__ - INFO - Training time: 11.85s
2025-03-25 21:22:10,583 - __main__ - INFO - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-25 21:22:10,583 - __main__ - INFO - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 42,924 parameters
2025-03-25 21:22:10,584 - __main__ - INFO - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-25 21:22:10,584 - __main__ - INFO - 
To view parallel training curves, run:
2025-03-25 21:22:10,584 - __main__ - INFO - tensorboard --logdir=runs/parallel_comparison/20250325-212156_d32_l1_n1
2025-03-25 21:22:14,650 - __main__ - INFO - Using device: cuda
2025-03-25 21:22:14,650 - __main__ - INFO - Using accuracy-aware loss with weight: 0.5
2025-03-25 21:22:14,651 - __main__ - INFO - This reduces loss for correct token predictions during training
2025-03-25 21:22:14,651 - __main__ - INFO - Attempting to resume from run ID: 20250325-212156_d32_l1_n1
2025-03-25 21:22:14,651 - __main__ - INFO - Found run: 20250325-212156_d32_l1_n1
2025-03-25 21:22:14,652 - __main__ - INFO - Using checkpoint paths from run 20250325-212156_d32_l1_n1
2025-03-25 21:22:15,683 - __main__ - INFO - Found vocab_size=11 in checkpoint state dict
2025-03-25 21:22:15,683 - __main__ - INFO - Detected 8 layers from checkpoint state dict
2025-03-25 21:22:15,684 - __main__ - INFO - Found d_model=768 in checkpoint state dict
2025-03-25 21:22:15,684 - __main__ - INFO - Updating d_model from 32 to 768 to match checkpoint
2025-03-25 21:22:15,684 - __main__ - INFO - Updating num_layers from 1 to 8 to match checkpoint
2025-03-25 21:22:15,684 - __main__ - INFO - Using train dataset with range 1-9
2025-03-25 21:22:15,684 - __main__ - INFO - Using val dataset with range 1-9
2025-03-25 21:22:15,685 - __main__ - INFO - Using vocabulary size: 11
2025-03-25 21:22:17,892 - __main__ - INFO - 
Model Parameters:
2025-03-25 21:22:17,892 - __main__ - INFO - SimpleTransformer: 132,352,523
2025-03-25 21:22:17,892 - __main__ - INFO - LatentTransformer: 138,850,571
2025-03-25 21:22:17,892 - __main__ - INFO - Parameter ratio: 1.05x
2025-03-25 21:22:17,892 - __main__ - INFO - Difference: 6,498,048 parameters (4.9%)
2025-03-25 21:22:17,895 - src.RunManagement - INFO - Registered run: 20250325-212217_d768_l8_n1
2025-03-25 21:22:17,895 - __main__ - INFO - 
Training both models in parallel...
2025-03-25 21:22:17,897 - src.RunManagement - INFO - Registered run: 20250325-212217_d768_l8_n1
2025-03-25 21:22:17,911 - __main__ - INFO - Loaded filtered SimpleTransformer state dict with 248 parameters
2025-03-25 21:22:17,911 - __main__ - INFO - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-25 21:22:17,911 - __main__ - INFO - Resuming SimpleTransformer from step 15900
2025-03-25 21:22:17,924 - __main__ - INFO - Loaded filtered LatentTransformer state dict with 262 parameters
2025-03-25 21:22:17,925 - __main__ - INFO - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-25 21:22:17,925 - __main__ - INFO - Resuming LatentTransformer from step 15900
2025-03-25 21:22:17,925 - __main__ - INFO - Calculating continuation steps for resumed training
2025-03-25 21:22:17,925 - __main__ - INFO - Original max_steps: 6, start_step: 15900
2025-03-25 21:22:17,925 - __main__ - INFO - Setting continuation_steps to 6 to allow full additional training
2025-03-25 21:22:17,925 - __main__ - INFO - Resuming from step 15900/6
2025-03-25 21:22:17,925 - src.TrainingLoop - INFO - Using max_steps from args: 6
2025-03-25 21:22:17,925 - src.TrainingLoop - INFO - Target steps for full training: 12 (max_steps=6, continuation=6)
2025-03-25 21:22:17,925 - src.TrainingLoop - INFO - Resuming training from checkpoints - adjusting target steps
2025-03-25 21:22:17,926 - src.TrainingLoop - INFO - SimpleTransformer resuming from step 15900
2025-03-25 21:22:17,926 - src.TrainingLoop - INFO - SimpleTransformer target steps: 6
2025-03-25 21:22:17,926 - src.TrainingLoop - INFO - LatentTransformer resuming from step 15900
2025-03-25 21:22:17,926 - src.TrainingLoop - INFO - LatentTransformer target steps: 6
2025-03-25 21:22:17,928 - src.TrainingLoop - INFO - Using torch.compile to optimize models
2025-03-25 21:22:20,106 - src.TrainingLoop - INFO - Loading SimpleTransformer from checkpoint
2025-03-25 21:22:20,120 - src.TrainingLoop - INFO - Loading LatentTransformer from checkpoint
2025-03-26 21:39:14.506 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 21:39:14.507 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 21:39:14.507 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 21:39:14.507 | INFO     | __main__:main:452 - Using train dataset with range 100-99
2025-03-26 21:45:01.042 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 21:45:01.043 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 21:45:01.044 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 21:45:01.044 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 21:45:01.055 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 21:45:01.055 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 21:45:01.341 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 21:45:01.341 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 21:45:01.342 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 21:45:01.342 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 21:45:01.342 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 21:45:01.343 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 21:47:55.991 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 21:47:55.991 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 21:47:55.991 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 21:47:55.991 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 21:47:56.003 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 21:47:56.003 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 21:47:56.262 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 21:47:56.262 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 21:47:56.262 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 21:47:56.262 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 21:47:56.262 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 21:47:56.263 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 21:48:28.527 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 21:48:28.527 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 21:48:28.528 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 21:48:28.528 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 21:48:28.539 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 21:48:28.539 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 21:48:28.815 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 21:48:28.815 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 21:48:28.816 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 21:48:28.816 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 21:48:28.816 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 21:48:28.816 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 21:48:50.802 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 21:48:50.802 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 21:48:50.802 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 21:48:50.802 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 21:48:50.815 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 21:48:50.815 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 21:48:51.087 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 21:48:51.087 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 21:48:51.087 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 21:48:51.087 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 21:48:51.088 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 21:48:51.088 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 21:55:07.102 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 21:55:07.102 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 21:55:07.102 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 21:55:07.103 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 21:55:07.114 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 21:55:07.114 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 21:55:07.389 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 21:55:07.390 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 21:55:07.390 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 21:55:07.390 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 21:55:07.390 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 21:55:07.391 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 21:59:36.041 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 21:59:36.041 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 21:59:36.041 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 21:59:36.042 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 21:59:36.052 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 21:59:36.053 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 21:59:36.343 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 21:59:36.343 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 21:59:36.343 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 21:59:36.344 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 21:59:36.344 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 21:59:36.344 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 21:59:39.908 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 21:59:39.908 | INFO     | __main__:main:699 - ==================================================
2025-03-26 21:59:39.909 | INFO     | __main__:main:705 - Training time: 2.69s
2025-03-26 21:59:39.909 | INFO     | __main__:main:706 - SimpleTransformer: 1.823114 loss, 3.47% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 21:59:39.909 | INFO     | __main__:main:709 - LatentTransformer: 1.885396 loss, 4.08% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 21:59:39.909 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 21:59:39.909 | INFO     | __main__:main:753 - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-26 21:59:39.910 | INFO     | __main__:main:774 - SimpleTransformer is 1.02x more accuracy-per-parameter efficient
2025-03-26 21:59:39.910 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 21:59:39.910 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-215936_d64_l2_n4
2025-03-26 22:03:36.097 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:03:36.097 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:03:36.097 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:03:37.212 | INFO     | __main__:main:359 - Found vocab_size=11 in checkpoint state dict
2025-03-26 22:03:37.212 | INFO     | __main__:main:384 - Detected 8 layers from checkpoint state dict
2025-03-26 22:03:37.213 | INFO     | __main__:main:392 - Found d_model=768 in checkpoint state dict
2025-03-26 22:03:37.213 | INFO     | __main__:main:398 - Updating d_model from 384 to 768 to match checkpoint
2025-03-26 22:03:37.213 | INFO     | __main__:main:405 - Updating num_layers from 4 to 8 to match checkpoint
2025-03-26 22:03:37.213 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 22:03:37.225 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 22:03:37.226 | INFO     | __main__:main:518 - Using vocabulary size: 11
2025-03-26 22:03:38.998 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:03:38.998 | INFO     | __main__:main:544 - SimpleTransformer: 132,352,523
2025-03-26 22:03:38.998 | INFO     | __main__:main:545 - LatentTransformer: 138,855,947
2025-03-26 22:03:38.998 | INFO     | __main__:main:546 - Parameter ratio: 1.05x
2025-03-26 22:03:38.999 | INFO     | __main__:main:547 - Difference: 6,503,424 parameters (4.9%)
2025-03-26 22:03:38.999 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:03:39.010 | INFO     | __main__:main:604 - Loaded filtered SimpleTransformer state dict with 248 parameters
2025-03-26 22:03:39.010 | INFO     | __main__:main:613 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:03:39.010 | INFO     | __main__:main:616 - Resuming SimpleTransformer from step 15900
2025-03-26 22:03:39.023 | INFO     | __main__:main:625 - Loaded filtered LatentTransformer state dict with 262 parameters
2025-03-26 22:03:39.023 | INFO     | __main__:main:634 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:03:39.023 | INFO     | __main__:main:637 - Resuming LatentTransformer from step 15900
2025-03-26 22:03:39.023 | INFO     | __main__:main:652 - Calculating continuation steps for resumed training
2025-03-26 22:03:39.023 | INFO     | __main__:main:653 - Original max_steps: 10000, start_step: 15900
2025-03-26 22:03:39.023 | INFO     | __main__:main:660 - Setting continuation_steps to 10000 to allow full additional training
2025-03-26 22:03:39.023 | INFO     | __main__:main:668 - Resuming from step 15900/10000
2025-03-26 22:03:42.588 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:03:42.589 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:03:42.589 | INFO     | __main__:main:705 - Training time: 2.72s
2025-03-26 22:03:42.589 | INFO     | __main__:main:706 - SimpleTransformer: 1.858691 loss, 26.33% sequence accuracy, 18.18% digit accuracy, 132,352,523 parameters
2025-03-26 22:03:42.589 | INFO     | __main__:main:709 - LatentTransformer: 1.327075 loss, 24.69% sequence accuracy, 18.18% digit accuracy, 138,855,947 parameters
2025-03-26 22:03:42.589 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 22:03:42.589 | INFO     | __main__:main:748 - LatentTransformer is 1.33x more parameter-efficient (loss*params)
2025-03-26 22:03:42.590 | INFO     | __main__:main:774 - SimpleTransformer is 1.12x more accuracy-per-parameter efficient
2025-03-26 22:03:42.590 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:03:42.590 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-220338_d768_l8_n8
2025-03-26 22:05:06.057 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:05:06.057 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:05:06.057 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:05:06.057 | INFO     | __main__:main:245 - Attempting to resume from run ID: 20250326-215936_d64_l2_n4
2025-03-26 22:05:06.058 | INFO     | __main__:main:249 - Found run: 20250326-215936_d64_l2_n4
2025-03-26 22:05:06.058 | INFO     | __main__:main:324 - Using checkpoint paths from run 20250326-215936_d64_l2_n4
2025-03-26 22:05:07.290 | INFO     | __main__:main:359 - Found vocab_size=11 in checkpoint state dict
2025-03-26 22:05:07.290 | INFO     | __main__:main:384 - Detected 8 layers from checkpoint state dict
2025-03-26 22:05:07.291 | INFO     | __main__:main:392 - Found d_model=768 in checkpoint state dict
2025-03-26 22:05:07.291 | INFO     | __main__:main:398 - Updating d_model from 384 to 768 to match checkpoint
2025-03-26 22:05:07.291 | INFO     | __main__:main:405 - Updating num_layers from 4 to 8 to match checkpoint
2025-03-26 22:05:07.291 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 22:05:07.302 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 22:05:07.302 | INFO     | __main__:main:518 - Using vocabulary size: 11
2025-03-26 22:05:09.188 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:05:09.188 | INFO     | __main__:main:544 - SimpleTransformer: 132,352,523
2025-03-26 22:05:09.188 | INFO     | __main__:main:545 - LatentTransformer: 138,855,947
2025-03-26 22:05:09.188 | INFO     | __main__:main:546 - Parameter ratio: 1.05x
2025-03-26 22:05:09.189 | INFO     | __main__:main:547 - Difference: 6,503,424 parameters (4.9%)
2025-03-26 22:05:09.189 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:05:09.202 | INFO     | __main__:main:604 - Loaded filtered SimpleTransformer state dict with 248 parameters
2025-03-26 22:05:09.202 | INFO     | __main__:main:613 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:05:09.203 | INFO     | __main__:main:616 - Resuming SimpleTransformer from step 15900
2025-03-26 22:05:09.216 | INFO     | __main__:main:625 - Loaded filtered LatentTransformer state dict with 262 parameters
2025-03-26 22:05:09.216 | INFO     | __main__:main:634 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:05:09.216 | INFO     | __main__:main:637 - Resuming LatentTransformer from step 15900
2025-03-26 22:05:09.217 | INFO     | __main__:main:652 - Calculating continuation steps for resumed training
2025-03-26 22:05:09.217 | INFO     | __main__:main:653 - Original max_steps: 10000, start_step: 15900
2025-03-26 22:05:09.217 | INFO     | __main__:main:660 - Setting continuation_steps to 10000 to allow full additional training
2025-03-26 22:05:09.217 | INFO     | __main__:main:668 - Resuming from step 15900/10000
2025-03-26 22:05:12.748 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:05:12.748 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:05:12.749 | INFO     | __main__:main:705 - Training time: 2.69s
2025-03-26 22:05:12.749 | INFO     | __main__:main:706 - SimpleTransformer: 1.858691 loss, 26.33% sequence accuracy, 18.18% digit accuracy, 132,352,523 parameters
2025-03-26 22:05:12.749 | INFO     | __main__:main:709 - LatentTransformer: 1.327075 loss, 24.69% sequence accuracy, 18.18% digit accuracy, 138,855,947 parameters
2025-03-26 22:05:12.749 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 22:05:12.749 | INFO     | __main__:main:748 - LatentTransformer is 1.33x more parameter-efficient (loss*params)
2025-03-26 22:05:12.749 | INFO     | __main__:main:774 - SimpleTransformer is 1.12x more accuracy-per-parameter efficient
2025-03-26 22:05:12.750 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:05:12.750 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-220509_d768_l8_n8
2025-03-26 22:08:53.818 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:08:53.818 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:08:53.819 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:08:53.819 | INFO     | __main__:main:245 - Attempting to resume from run ID: 20250326-215936_d64_l2_n4
2025-03-26 22:08:53.819 | INFO     | __main__:main:249 - Found run: 20250326-215936_d64_l2_n4
2025-03-26 22:08:53.819 | INFO     | __main__:main:324 - Using checkpoint paths from run 20250326-215936_d64_l2_n4
2025-03-26 22:08:54.621 | INFO     | __main__:main:359 - Found vocab_size=11 in checkpoint state dict
2025-03-26 22:08:54.621 | INFO     | __main__:main:384 - Detected 8 layers from checkpoint state dict
2025-03-26 22:08:54.622 | INFO     | __main__:main:392 - Found d_model=768 in checkpoint state dict
2025-03-26 22:08:54.622 | INFO     | __main__:main:398 - Updating d_model from 384 to 768 to match checkpoint
2025-03-26 22:08:54.622 | INFO     | __main__:main:405 - Updating num_layers from 4 to 8 to match checkpoint
2025-03-26 22:08:54.622 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 22:08:54.633 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 22:08:54.634 | INFO     | __main__:main:518 - Using vocabulary size: 11
2025-03-26 22:08:56.451 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:08:56.451 | INFO     | __main__:main:544 - SimpleTransformer: 132,352,523
2025-03-26 22:08:56.452 | INFO     | __main__:main:545 - LatentTransformer: 138,855,947
2025-03-26 22:08:56.452 | INFO     | __main__:main:546 - Parameter ratio: 1.05x
2025-03-26 22:08:56.452 | INFO     | __main__:main:547 - Difference: 6,503,424 parameters (4.9%)
2025-03-26 22:08:56.453 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:08:56.469 | INFO     | __main__:main:604 - Loaded filtered SimpleTransformer state dict with 248 parameters
2025-03-26 22:08:56.469 | INFO     | __main__:main:613 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:08:56.469 | INFO     | __main__:main:616 - Resuming SimpleTransformer from step 15900
2025-03-26 22:08:56.489 | INFO     | __main__:main:625 - Loaded filtered LatentTransformer state dict with 262 parameters
2025-03-26 22:08:56.490 | INFO     | __main__:main:634 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:08:56.490 | INFO     | __main__:main:637 - Resuming LatentTransformer from step 15900
2025-03-26 22:08:56.490 | INFO     | __main__:main:652 - Calculating continuation steps for resumed training
2025-03-26 22:08:56.490 | INFO     | __main__:main:653 - Original max_steps: 10000, start_step: 15900
2025-03-26 22:08:56.490 | INFO     | __main__:main:660 - Setting continuation_steps to 10000 to allow full additional training
2025-03-26 22:08:56.491 | INFO     | __main__:main:668 - Resuming from step 15900/10000
2025-03-26 22:09:00.462 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:09:00.463 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:09:00.463 | INFO     | __main__:main:705 - Training time: 3.03s
2025-03-26 22:09:00.463 | INFO     | __main__:main:706 - SimpleTransformer: 1.858691 loss, 26.33% sequence accuracy, 18.18% digit accuracy, 132,352,523 parameters
2025-03-26 22:09:00.463 | INFO     | __main__:main:709 - LatentTransformer: 1.327075 loss, 24.69% sequence accuracy, 18.18% digit accuracy, 138,855,947 parameters
2025-03-26 22:09:00.463 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 22:09:00.464 | INFO     | __main__:main:748 - LatentTransformer is 1.33x more parameter-efficient (loss*params)
2025-03-26 22:09:00.464 | INFO     | __main__:main:774 - SimpleTransformer is 1.12x more accuracy-per-parameter efficient
2025-03-26 22:09:00.464 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:09:00.464 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-220856_d768_l8_n8
2025-03-26 22:09:29.486 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:09:29.486 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:09:29.486 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:09:29.487 | INFO     | __main__:main:245 - Attempting to resume from run ID: 20250326-215936_d64_l2_n4
2025-03-26 22:09:29.487 | INFO     | __main__:main:249 - Found run: 20250326-215936_d64_l2_n4
2025-03-26 22:09:29.487 | INFO     | __main__:main:324 - Using checkpoint paths from run 20250326-215936_d64_l2_n4
2025-03-26 22:09:30.728 | INFO     | __main__:main:359 - Found vocab_size=11 in checkpoint state dict
2025-03-26 22:09:30.729 | INFO     | __main__:main:384 - Detected 8 layers from checkpoint state dict
2025-03-26 22:09:30.729 | INFO     | __main__:main:392 - Found d_model=768 in checkpoint state dict
2025-03-26 22:09:30.729 | INFO     | __main__:main:398 - Updating d_model from 64 to 768 to match checkpoint
2025-03-26 22:09:30.729 | INFO     | __main__:main:405 - Updating num_layers from 2 to 8 to match checkpoint
2025-03-26 22:09:30.729 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 22:09:30.742 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 22:09:30.742 | INFO     | __main__:main:518 - Using vocabulary size: 11
2025-03-26 22:09:32.442 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:09:32.442 | INFO     | __main__:main:544 - SimpleTransformer: 132,352,523
2025-03-26 22:09:32.442 | INFO     | __main__:main:545 - LatentTransformer: 138,852,875
2025-03-26 22:09:32.442 | INFO     | __main__:main:546 - Parameter ratio: 1.05x
2025-03-26 22:09:32.443 | INFO     | __main__:main:547 - Difference: 6,500,352 parameters (4.9%)
2025-03-26 22:09:32.443 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:09:32.454 | INFO     | __main__:main:604 - Loaded filtered SimpleTransformer state dict with 248 parameters
2025-03-26 22:09:32.455 | INFO     | __main__:main:613 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:09:32.455 | INFO     | __main__:main:616 - Resuming SimpleTransformer from step 15900
2025-03-26 22:09:32.466 | INFO     | __main__:main:625 - Loaded filtered LatentTransformer state dict with 262 parameters
2025-03-26 22:09:32.466 | INFO     | __main__:main:634 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:09:32.466 | INFO     | __main__:main:637 - Resuming LatentTransformer from step 15900
2025-03-26 22:09:32.466 | INFO     | __main__:main:652 - Calculating continuation steps for resumed training
2025-03-26 22:09:32.466 | INFO     | __main__:main:653 - Original max_steps: 10000, start_step: 15900
2025-03-26 22:09:32.466 | INFO     | __main__:main:660 - Setting continuation_steps to 10000 to allow full additional training
2025-03-26 22:09:32.467 | INFO     | __main__:main:668 - Resuming from step 15900/10000
2025-03-26 22:09:36.494 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:09:36.496 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:09:36.496 | INFO     | __main__:main:705 - Training time: 3.14s
2025-03-26 22:09:36.496 | INFO     | __main__:main:706 - SimpleTransformer: 1.858691 loss, 26.33% sequence accuracy, 18.18% digit accuracy, 132,352,523 parameters
2025-03-26 22:09:36.496 | INFO     | __main__:main:709 - LatentTransformer: 1.335290 loss, 24.80% sequence accuracy, 0.00% digit accuracy, 138,852,875 parameters
2025-03-26 22:09:36.496 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 22:09:36.496 | INFO     | __main__:main:748 - LatentTransformer is 1.33x more parameter-efficient (loss*params)
2025-03-26 22:09:36.497 | INFO     | __main__:main:774 - SimpleTransformer is 1.11x more accuracy-per-parameter efficient
2025-03-26 22:09:36.497 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:09:36.497 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-220932_d768_l8_n4
2025-03-26 22:12:21.185 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:12:21.185 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:12:21.185 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:12:21.185 | INFO     | __main__:main:245 - Attempting to resume from run ID: 20250326-215936_d64_l2_n4
2025-03-26 22:12:21.185 | INFO     | __main__:main:249 - Found run: 20250326-215936_d64_l2_n4
2025-03-26 22:12:21.186 | INFO     | __main__:main:324 - Using checkpoint paths from run 20250326-215936_d64_l2_n4
2025-03-26 22:12:22.450 | INFO     | __main__:main:359 - Found vocab_size=11 in checkpoint state dict
2025-03-26 22:12:22.450 | INFO     | __main__:main:384 - Detected 8 layers from checkpoint state dict
2025-03-26 22:12:22.450 | INFO     | __main__:main:392 - Found d_model=768 in checkpoint state dict
2025-03-26 22:12:22.450 | INFO     | __main__:main:398 - Updating d_model from 384 to 768 to match checkpoint
2025-03-26 22:12:22.451 | INFO     | __main__:main:405 - Updating num_layers from 4 to 8 to match checkpoint
2025-03-26 22:12:22.451 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 22:12:22.461 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 22:12:22.462 | INFO     | __main__:main:518 - Using vocabulary size: 11
2025-03-26 22:12:24.152 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:12:24.152 | INFO     | __main__:main:544 - SimpleTransformer: 132,352,523
2025-03-26 22:12:24.152 | INFO     | __main__:main:545 - LatentTransformer: 138,855,947
2025-03-26 22:12:24.152 | INFO     | __main__:main:546 - Parameter ratio: 1.05x
2025-03-26 22:12:24.152 | INFO     | __main__:main:547 - Difference: 6,503,424 parameters (4.9%)
2025-03-26 22:12:24.153 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:12:24.165 | INFO     | __main__:main:604 - Loaded filtered SimpleTransformer state dict with 248 parameters
2025-03-26 22:12:24.165 | INFO     | __main__:main:613 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:12:24.165 | INFO     | __main__:main:616 - Resuming SimpleTransformer from step 15900
2025-03-26 22:12:24.176 | INFO     | __main__:main:625 - Loaded filtered LatentTransformer state dict with 262 parameters
2025-03-26 22:12:24.176 | INFO     | __main__:main:634 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:12:24.176 | INFO     | __main__:main:637 - Resuming LatentTransformer from step 15900
2025-03-26 22:12:24.176 | INFO     | __main__:main:652 - Calculating continuation steps for resumed training
2025-03-26 22:12:24.177 | INFO     | __main__:main:653 - Original max_steps: 10000, start_step: 15900
2025-03-26 22:12:24.177 | INFO     | __main__:main:660 - Setting continuation_steps to 10000 to allow full additional training
2025-03-26 22:12:24.177 | INFO     | __main__:main:668 - Resuming from step 15900/10000
2025-03-26 22:12:28.380 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:12:28.381 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:12:28.381 | INFO     | __main__:main:705 - Training time: 3.33s
2025-03-26 22:12:28.381 | INFO     | __main__:main:706 - SimpleTransformer: 1.858691 loss, 26.33% sequence accuracy, 18.18% digit accuracy, 132,352,523 parameters
2025-03-26 22:12:28.381 | INFO     | __main__:main:709 - LatentTransformer: 1.327075 loss, 24.69% sequence accuracy, 18.18% digit accuracy, 138,855,947 parameters
2025-03-26 22:12:28.381 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 22:12:28.381 | INFO     | __main__:main:748 - LatentTransformer is 1.33x more parameter-efficient (loss*params)
2025-03-26 22:12:28.382 | INFO     | __main__:main:774 - SimpleTransformer is 1.12x more accuracy-per-parameter efficient
2025-03-26 22:12:28.382 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:12:28.382 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-221224_d768_l8_n8
2025-03-26 22:15:40.279 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:15:40.280 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:15:40.280 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:15:40.280 | INFO     | __main__:main:452 - Using train dataset with range 1-9
2025-03-26 22:15:40.280 | INFO     | __main__:main:461 - Using val dataset with range 1-9
2025-03-26 22:15:40.281 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 22:15:40.554 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:15:40.554 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 22:15:40.554 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 22:15:40.554 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 22:15:40.555 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:15:40.555 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:15:45.641 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:15:45.641 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:15:45.641 | INFO     | __main__:main:705 - Training time: 4.21s
2025-03-26 22:15:45.642 | INFO     | __main__:main:706 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:15:45.642 | INFO     | __main__:main:709 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:15:45.642 | INFO     | __main__:main:782 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:15:45.642 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:15:45.642 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-221540_d64_l2_n4
2025-03-26 22:15:53.475 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:15:53.475 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:15:53.475 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:15:53.475 | INFO     | __main__:main:245 - Attempting to resume from run ID: 20250326-221540_d64_l2_n4
2025-03-26 22:15:53.476 | INFO     | __main__:main:249 - Found run: 20250326-221540_d64_l2_n4
2025-03-26 22:15:53.476 | INFO     | __main__:main:324 - Using checkpoint paths from run 20250326-221540_d64_l2_n4
2025-03-26 22:15:53.867 | INFO     | __main__:main:349 - Found d_model=64 in checkpoint config
2025-03-26 22:15:53.867 | INFO     | __main__:main:359 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:15:53.868 | INFO     | __main__:main:384 - Detected 2 layers from checkpoint state dict
2025-03-26 22:15:53.868 | INFO     | __main__:main:398 - Updating d_model from 384 to 64 to match checkpoint
2025-03-26 22:15:53.868 | INFO     | __main__:main:405 - Updating num_layers from 4 to 2 to match checkpoint
2025-03-26 22:15:53.868 | INFO     | __main__:main:426 - Updating num_latent from 8 to 4 to match checkpoint
2025-03-26 22:15:53.868 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 22:15:53.882 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 22:15:53.882 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 22:15:53.925 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:15:53.925 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 22:15:53.925 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 22:15:53.926 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 22:15:53.926 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:15:53.926 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:15:53.931 | INFO     | __main__:main:604 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:15:53.931 | INFO     | __main__:main:613 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:15:53.931 | INFO     | __main__:main:616 - Resuming SimpleTransformer from step 20
2025-03-26 22:15:53.937 | INFO     | __main__:main:625 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:15:53.937 | INFO     | __main__:main:634 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:15:53.937 | INFO     | __main__:main:637 - Resuming LatentTransformer from step 20
2025-03-26 22:15:53.937 | INFO     | __main__:main:652 - Calculating continuation steps for resumed training
2025-03-26 22:15:53.937 | INFO     | __main__:main:653 - Original max_steps: 40, start_step: 20
2025-03-26 22:15:53.937 | INFO     | __main__:main:664 - No continuation steps needed, continuing to target 40
2025-03-26 22:15:53.938 | INFO     | __main__:main:668 - Resuming from step 20/40
2025-03-26 22:15:58.328 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:15:58.330 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:15:58.330 | INFO     | __main__:main:705 - Training time: 3.52s
2025-03-26 22:15:58.330 | INFO     | __main__:main:706 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:15:58.330 | INFO     | __main__:main:709 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:15:58.330 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 22:15:58.331 | INFO     | __main__:main:753 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:15:58.331 | INFO     | __main__:main:774 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:15:58.331 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:15:58.331 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-221553_d64_l2_n4
2025-03-26 22:20:20.336 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:20:20.337 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:20:20.337 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:20:20.337 | INFO     | __main__:main:452 - Using train dataset with range 1-9
2025-03-26 22:20:20.338 | INFO     | __main__:main:461 - Using val dataset with range 1-9
2025-03-26 22:20:20.338 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 22:20:20.628 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:20:20.629 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 22:20:20.629 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 22:20:20.629 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 22:20:20.630 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:20:20.630 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:20:26.348 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:20:26.349 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:20:26.349 | INFO     | __main__:main:705 - Training time: 4.41s
2025-03-26 22:20:26.350 | INFO     | __main__:main:706 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:20:26.350 | INFO     | __main__:main:709 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:20:26.350 | INFO     | __main__:main:782 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:20:26.350 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:20:26.351 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-222020_d64_l2_n4
2025-03-26 22:20:34.742 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:20:34.742 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:20:34.743 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:20:34.743 | INFO     | __main__:main:245 - Attempting to resume from run ID: 20250326-222020_d64_l2_n4
2025-03-26 22:20:34.743 | INFO     | __main__:main:249 - Found run: 20250326-222020_d64_l2_n4
2025-03-26 22:20:34.744 | INFO     | __main__:main:324 - Using checkpoint paths from run 20250326-222020_d64_l2_n4
2025-03-26 22:20:35.158 | INFO     | __main__:main:349 - Found d_model=64 in checkpoint config
2025-03-26 22:20:35.158 | INFO     | __main__:main:359 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:20:35.159 | INFO     | __main__:main:384 - Detected 2 layers from checkpoint state dict
2025-03-26 22:20:35.159 | INFO     | __main__:main:398 - Updating d_model from 384 to 64 to match checkpoint
2025-03-26 22:20:35.159 | INFO     | __main__:main:405 - Updating num_layers from 4 to 2 to match checkpoint
2025-03-26 22:20:35.159 | INFO     | __main__:main:426 - Updating num_latent from 8 to 4 to match checkpoint
2025-03-26 22:20:35.160 | INFO     | __main__:main:452 - Using train dataset with range 1-99
2025-03-26 22:20:35.171 | INFO     | __main__:main:461 - Using val dataset with range 1-99
2025-03-26 22:20:35.171 | INFO     | __main__:main:518 - Using vocabulary size: 12
2025-03-26 22:20:35.216 | INFO     | __main__:main:543 - 
Model Parameters:
2025-03-26 22:20:35.217 | INFO     | __main__:main:544 - SimpleTransformer: 236,556
2025-03-26 22:20:35.217 | INFO     | __main__:main:545 - LatentTransformer: 282,636
2025-03-26 22:20:35.217 | INFO     | __main__:main:546 - Parameter ratio: 1.19x
2025-03-26 22:20:35.217 | INFO     | __main__:main:547 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:20:35.218 | INFO     | __main__:main:579 - 
Training both models in parallel...
2025-03-26 22:20:35.222 | INFO     | __main__:main:604 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:20:35.222 | INFO     | __main__:main:613 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:20:35.222 | INFO     | __main__:main:616 - Resuming SimpleTransformer from step 20
2025-03-26 22:20:35.227 | INFO     | __main__:main:625 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:20:35.228 | INFO     | __main__:main:634 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:20:35.228 | INFO     | __main__:main:637 - Resuming LatentTransformer from step 20
2025-03-26 22:20:35.228 | INFO     | __main__:main:652 - Calculating continuation steps for resumed training
2025-03-26 22:20:35.228 | INFO     | __main__:main:653 - Original max_steps: 40, start_step: 20
2025-03-26 22:20:35.229 | INFO     | __main__:main:664 - No continuation steps needed, continuing to target 40
2025-03-26 22:20:35.229 | INFO     | __main__:main:668 - Resuming from step 20/40
2025-03-26 22:20:40.079 | INFO     | __main__:main:698 - 
Final Comparison:
2025-03-26 22:20:40.080 | INFO     | __main__:main:699 - ==================================================
2025-03-26 22:20:40.080 | INFO     | __main__:main:705 - Training time: 3.77s
2025-03-26 22:20:40.080 | INFO     | __main__:main:706 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:20:40.081 | INFO     | __main__:main:709 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:20:40.081 | INFO     | __main__:main:738 - 
Efficiency Metrics:
2025-03-26 22:20:40.081 | INFO     | __main__:main:753 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:20:40.081 | INFO     | __main__:main:774 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:20:40.082 | INFO     | __main__:main:786 - 
To view parallel training curves, run:
2025-03-26 22:20:40.082 | INFO     | __main__:main:787 - tensorboard --logdir=runs/parallel_comparison/20250326-222035_d64_l2_n4
2025-03-26 22:23:58.106 | INFO     | __main__:main:218 - Using device: cuda
2025-03-26 22:23:58.106 | INFO     | __main__:main:222 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:23:58.107 | INFO     | __main__:main:223 - This reduces loss for correct token predictions during training
2025-03-26 22:23:58.107 | INFO     | __main__:main:458 - Using train dataset with range 1-9
2025-03-26 22:23:58.107 | INFO     | __main__:main:467 - Using val dataset with range 1-9
2025-03-26 22:23:58.108 | INFO     | __main__:main:524 - Using vocabulary size: 12
2025-03-26 22:23:58.404 | INFO     | __main__:main:549 - 
Model Parameters:
2025-03-26 22:23:58.405 | INFO     | __main__:main:550 - SimpleTransformer: 236,556
2025-03-26 22:23:58.405 | INFO     | __main__:main:551 - LatentTransformer: 282,636
2025-03-26 22:23:58.405 | INFO     | __main__:main:552 - Parameter ratio: 1.19x
2025-03-26 22:23:58.405 | INFO     | __main__:main:553 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:23:58.406 | INFO     | __main__:main:585 - 
Training both models in parallel...
2025-03-26 22:27:45.500 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:27:45.500 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:27:45.501 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:27:45.501 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:27:45.501 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:27:45.502 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:27:45.782 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:27:45.782 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:27:45.782 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:27:45.783 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:27:45.783 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:27:45.784 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:29:05.603 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:29:05.603 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:29:05.604 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:29:05.604 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:29:05.604 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:29:05.605 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:29:05.879 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:29:05.879 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:29:05.879 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:29:05.879 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:29:05.880 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:29:05.880 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:29:25.185 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:29:25.185 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:29:25.186 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:29:25.186 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:29:25.186 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:29:25.187 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:29:25.456 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:29:25.456 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:29:25.456 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:29:25.457 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:29:25.457 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:29:25.457 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:29:31.094 | INFO     | __main__:main:734 - 
Final Comparison:
2025-03-26 22:29:31.094 | INFO     | __main__:main:735 - ==================================================
2025-03-26 22:29:31.095 | INFO     | __main__:main:741 - Training time: 4.65s
2025-03-26 22:29:31.095 | INFO     | __main__:main:742 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:29:31.095 | INFO     | __main__:main:745 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:29:31.095 | INFO     | __main__:main:818 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:29:31.096 | INFO     | __main__:main:822 - 
To view parallel training curves, run:
2025-03-26 22:29:31.096 | INFO     | __main__:main:823 - tensorboard --logdir=runs/parallel_comparison/20250326-222925_d64_l2_n4
2025-03-26 22:29:40.907 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:29:40.908 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:29:40.908 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:29:40.908 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-222925_d64_l2_n4
2025-03-26 22:29:40.909 | INFO     | __main__:main:256 - Found run: 20250326-222925_d64_l2_n4
2025-03-26 22:29:40.909 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:29:40.910 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:29:40.910 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:29:40.910 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:29:40.911 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-222925_d64_l2_n4
2025-03-26 22:29:41.316 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:29:41.317 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:29:41.317 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:29:41.317 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:29:41.327 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:29:41.328 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:29:41.368 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:29:41.369 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:29:41.369 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:29:41.369 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:29:41.369 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:29:41.370 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:29:41.370 | INFO     | __main__:main:602 - Creating new log directory for resumed training: runs/parallel_comparison/20250326-222925_d64_l2_n4_resumed_20250326-222941_d64_l2_n4
2025-03-26 22:29:41.374 | INFO     | __main__:main:640 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:29:41.374 | INFO     | __main__:main:649 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:29:41.375 | INFO     | __main__:main:652 - Resuming SimpleTransformer from step 20
2025-03-26 22:29:41.386 | INFO     | __main__:main:661 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:29:41.387 | INFO     | __main__:main:670 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:29:41.387 | INFO     | __main__:main:673 - Resuming LatentTransformer from step 20
2025-03-26 22:29:41.387 | INFO     | __main__:main:688 - Calculating continuation steps for resumed training
2025-03-26 22:29:41.388 | INFO     | __main__:main:689 - Original max_steps: 40, start_step: 20
2025-03-26 22:29:41.388 | INFO     | __main__:main:700 - No continuation steps needed, continuing to target 40
2025-03-26 22:29:41.388 | INFO     | __main__:main:704 - Resuming from step 20/40
2025-03-26 22:29:46.548 | INFO     | __main__:main:734 - 
Final Comparison:
2025-03-26 22:29:46.549 | INFO     | __main__:main:735 - ==================================================
2025-03-26 22:29:46.549 | INFO     | __main__:main:741 - Training time: 4.05s
2025-03-26 22:29:46.549 | INFO     | __main__:main:742 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:29:46.550 | INFO     | __main__:main:745 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:29:46.550 | INFO     | __main__:main:774 - 
Efficiency Metrics:
2025-03-26 22:29:46.550 | INFO     | __main__:main:789 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:29:46.550 | INFO     | __main__:main:810 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:29:46.551 | INFO     | __main__:main:822 - 
To view parallel training curves, run:
2025-03-26 22:29:46.551 | INFO     | __main__:main:823 - tensorboard --logdir=runs/parallel_comparison/20250326-222925_d64_l2_n4_resumed_20250326-222941_d64_l2_n4
2025-03-26 22:32:47.191 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:32:47.191 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:32:47.192 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:32:47.192 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:32:47.192 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:32:47.193 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:32:47.471 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:32:47.472 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:32:47.472 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:32:47.472 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:32:47.472 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:32:47.473 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:32:52.975 | INFO     | __main__:main:740 - 
Final Comparison:
2025-03-26 22:32:52.976 | INFO     | __main__:main:741 - ==================================================
2025-03-26 22:32:52.976 | INFO     | __main__:main:747 - Training time: 4.50s
2025-03-26 22:32:52.977 | INFO     | __main__:main:748 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:32:52.977 | INFO     | __main__:main:751 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:32:52.977 | INFO     | __main__:main:824 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:32:52.977 | INFO     | __main__:main:828 - 
To view parallel training curves, run:
2025-03-26 22:32:52.978 | INFO     | __main__:main:829 - tensorboard --logdir=runs/parallel_comparison/20250326-223247_d64_l2_n4
2025-03-26 22:33:01.400 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:33:01.400 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:33:01.400 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:33:01.401 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-223247_d64_l2_n4
2025-03-26 22:33:01.401 | INFO     | __main__:main:256 - Found run: 20250326-223247_d64_l2_n4
2025-03-26 22:33:01.401 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:33:01.402 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:33:01.403 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:33:01.403 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:33:01.403 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-223247_d64_l2_n4
2025-03-26 22:33:01.794 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:33:01.794 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:33:01.794 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:33:01.795 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:33:01.805 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:33:01.806 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:33:01.844 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:33:01.844 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:33:01.844 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:33:01.844 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:33:01.845 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:33:01.846 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:33:01.846 | INFO     | __main__:main:608 - Creating new log directory for resumed training: runs/parallel_comparison/20250326-223247_d64_l2_n4_resumed_20250326-223301_d64_l2_n4
2025-03-26 22:33:01.850 | INFO     | __main__:main:646 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:33:01.850 | INFO     | __main__:main:655 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:33:01.851 | INFO     | __main__:main:658 - Resuming SimpleTransformer from step 20
2025-03-26 22:33:01.854 | INFO     | __main__:main:667 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:33:01.854 | INFO     | __main__:main:676 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:33:01.855 | INFO     | __main__:main:679 - Resuming LatentTransformer from step 20
2025-03-26 22:33:01.855 | INFO     | __main__:main:694 - Calculating continuation steps for resumed training
2025-03-26 22:33:01.855 | INFO     | __main__:main:695 - Original max_steps: 40, start_step: 20
2025-03-26 22:33:01.855 | INFO     | __main__:main:706 - No continuation steps needed, continuing to target 40
2025-03-26 22:33:01.855 | INFO     | __main__:main:710 - Resuming from step 20/40
2025-03-26 22:33:06.890 | INFO     | __main__:main:740 - 
Final Comparison:
2025-03-26 22:33:06.890 | INFO     | __main__:main:741 - ==================================================
2025-03-26 22:33:06.891 | INFO     | __main__:main:747 - Training time: 3.93s
2025-03-26 22:33:06.891 | INFO     | __main__:main:748 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:33:06.891 | INFO     | __main__:main:751 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:33:06.891 | INFO     | __main__:main:780 - 
Efficiency Metrics:
2025-03-26 22:33:06.892 | INFO     | __main__:main:795 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:33:06.892 | INFO     | __main__:main:816 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:33:06.892 | INFO     | __main__:main:828 - 
To view parallel training curves, run:
2025-03-26 22:33:06.893 | INFO     | __main__:main:829 - tensorboard --logdir=runs/parallel_comparison/20250326-223247_d64_l2_n4_resumed_20250326-223301_d64_l2_n4
2025-03-26 22:35:28.951 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:35:28.951 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:35:28.951 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:35:28.952 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:35:28.952 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:35:28.953 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:35:29.234 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:35:29.234 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:35:29.235 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:35:29.235 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:35:29.235 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:35:29.236 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:35:34.931 | INFO     | __main__:main:736 - 
Final Comparison:
2025-03-26 22:35:34.931 | INFO     | __main__:main:737 - ==================================================
2025-03-26 22:35:34.932 | INFO     | __main__:main:743 - Training time: 4.61s
2025-03-26 22:35:34.932 | INFO     | __main__:main:744 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:35:34.932 | INFO     | __main__:main:747 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:35:34.933 | INFO     | __main__:main:820 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:35:34.933 | INFO     | __main__:main:824 - 
To view parallel training curves, run:
2025-03-26 22:35:34.933 | INFO     | __main__:main:825 - tensorboard --logdir=runs/parallel_comparison/20250326-223529_d64_l2_n4
2025-03-26 22:35:44.610 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:35:44.610 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:35:44.611 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:35:44.611 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-223529_d64_l2_n4
2025-03-26 22:35:44.612 | INFO     | __main__:main:256 - Found run: 20250326-223529_d64_l2_n4
2025-03-26 22:35:44.612 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:35:44.613 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:35:44.613 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:35:44.613 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:35:44.614 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-223529_d64_l2_n4
2025-03-26 22:35:45.104 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:35:45.104 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:35:45.104 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:35:45.105 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:35:45.118 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:35:45.119 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:35:45.172 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:35:45.172 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:35:45.173 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:35:45.173 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:35:45.173 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:35:45.174 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:35:45.174 | INFO     | __main__:main:604 - Creating directory with run_id name for resumed training: runs/parallel_comparison/20250326-223529_d64_l2_n4
2025-03-26 22:35:45.182 | INFO     | __main__:main:642 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:35:45.183 | INFO     | __main__:main:651 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:35:45.183 | INFO     | __main__:main:654 - Resuming SimpleTransformer from step 20
2025-03-26 22:35:45.186 | INFO     | __main__:main:663 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:35:45.187 | INFO     | __main__:main:672 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:35:45.187 | INFO     | __main__:main:675 - Resuming LatentTransformer from step 20
2025-03-26 22:35:45.188 | INFO     | __main__:main:690 - Calculating continuation steps for resumed training
2025-03-26 22:35:45.188 | INFO     | __main__:main:691 - Original max_steps: 40, start_step: 20
2025-03-26 22:35:45.188 | INFO     | __main__:main:702 - No continuation steps needed, continuing to target 40
2025-03-26 22:35:45.189 | INFO     | __main__:main:706 - Resuming from step 20/40
2025-03-26 22:35:50.936 | INFO     | __main__:main:736 - 
Final Comparison:
2025-03-26 22:35:50.937 | INFO     | __main__:main:737 - ==================================================
2025-03-26 22:35:50.937 | INFO     | __main__:main:743 - Training time: 4.59s
2025-03-26 22:35:50.937 | INFO     | __main__:main:744 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:35:50.938 | INFO     | __main__:main:747 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:35:50.938 | INFO     | __main__:main:776 - 
Efficiency Metrics:
2025-03-26 22:35:50.938 | INFO     | __main__:main:791 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:35:50.938 | INFO     | __main__:main:812 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:35:50.939 | INFO     | __main__:main:824 - 
To view parallel training curves, run:
2025-03-26 22:35:50.939 | INFO     | __main__:main:825 - tensorboard --logdir=runs/parallel_comparison/20250326-223529_d64_l2_n4
2025-03-26 22:37:28.077 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:37:28.078 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:37:28.078 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:37:28.078 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:37:28.078 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:37:28.079 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:37:28.381 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:37:28.381 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:37:28.382 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:37:28.382 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:37:28.382 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:37:28.384 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:37:34.262 | INFO     | __main__:main:736 - 
Final Comparison:
2025-03-26 22:37:34.262 | INFO     | __main__:main:737 - ==================================================
2025-03-26 22:37:34.263 | INFO     | __main__:main:743 - Training time: 4.86s
2025-03-26 22:37:34.263 | INFO     | __main__:main:744 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:37:34.263 | INFO     | __main__:main:747 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:37:34.264 | INFO     | __main__:main:820 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:37:34.264 | INFO     | __main__:main:824 - 
To view parallel training curves, run:
2025-03-26 22:37:34.264 | INFO     | __main__:main:825 - tensorboard --logdir=runs/parallel_comparison/20250326-223728_d64_l2_n4
2025-03-26 22:37:46.606 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:37:46.606 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:37:46.607 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:37:46.607 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-223728_d64_l2_n4
2025-03-26 22:37:46.607 | INFO     | __main__:main:256 - Found run: 20250326-223728_d64_l2_n4
2025-03-26 22:37:46.608 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:37:46.608 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:37:46.609 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:37:46.609 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:37:46.609 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-223728_d64_l2_n4
2025-03-26 22:37:47.152 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:37:47.152 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:37:47.153 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:37:47.153 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:37:47.167 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:37:47.168 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:37:47.224 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:37:47.224 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:37:47.225 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:37:47.225 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:37:47.225 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:37:47.226 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:37:47.227 | INFO     | __main__:main:604 - Creating directory with run_id name for resumed training: runs/parallel_comparison/20250326-223728_d64_l2_n4
2025-03-26 22:37:47.232 | INFO     | __main__:main:642 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:37:47.233 | INFO     | __main__:main:651 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:37:47.233 | INFO     | __main__:main:654 - Resuming SimpleTransformer from step 20
2025-03-26 22:37:47.239 | INFO     | __main__:main:663 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:37:47.240 | INFO     | __main__:main:672 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:37:47.240 | INFO     | __main__:main:675 - Resuming LatentTransformer from step 20
2025-03-26 22:37:47.240 | INFO     | __main__:main:690 - Calculating continuation steps for resumed training
2025-03-26 22:37:47.241 | INFO     | __main__:main:691 - Original max_steps: 40, start_step: 20
2025-03-26 22:37:47.241 | INFO     | __main__:main:702 - No continuation steps needed, continuing to target 40
2025-03-26 22:37:47.241 | INFO     | __main__:main:706 - Resuming from step 20/40
2025-03-26 22:37:53.766 | INFO     | __main__:main:736 - 
Final Comparison:
2025-03-26 22:37:53.767 | INFO     | __main__:main:737 - ==================================================
2025-03-26 22:37:53.768 | INFO     | __main__:main:743 - Training time: 5.32s
2025-03-26 22:37:53.768 | INFO     | __main__:main:744 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:37:53.768 | INFO     | __main__:main:747 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:37:53.768 | INFO     | __main__:main:776 - 
Efficiency Metrics:
2025-03-26 22:37:53.769 | INFO     | __main__:main:791 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:37:53.769 | INFO     | __main__:main:812 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:37:53.769 | INFO     | __main__:main:824 - 
To view parallel training curves, run:
2025-03-26 22:37:53.769 | INFO     | __main__:main:825 - tensorboard --logdir=runs/parallel_comparison/20250326-223728_d64_l2_n4
2025-03-26 22:39:46.090 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:39:46.090 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:39:46.090 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:39:46.090 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:39:46.091 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:39:46.091 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:39:46.361 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:39:46.361 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:39:46.362 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:39:46.362 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:39:46.362 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:39:46.363 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:39:51.961 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:39:51.962 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:39:51.963 | INFO     | __main__:main:740 - Training time: 4.59s
2025-03-26 22:39:51.963 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:39:51.963 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:39:51.964 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:39:51.964 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:39:51.964 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-223946_d64_l2_n4
2025-03-26 22:40:00.609 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:40:00.610 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:40:00.610 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:40:00.610 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-223946_d64_l2_n4
2025-03-26 22:40:00.611 | INFO     | __main__:main:256 - Found run: 20250326-223946_d64_l2_n4
2025-03-26 22:40:00.611 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:40:00.612 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:40:00.612 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:40:00.612 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:40:00.613 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-223946_d64_l2_n4
2025-03-26 22:40:01.014 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:40:01.015 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:40:01.015 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:40:01.015 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:40:01.026 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:40:01.027 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:40:01.067 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:40:01.067 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:40:01.068 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:40:01.068 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:40:01.068 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:40:01.069 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:40:01.070 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-223946_d64_l2_n4
2025-03-26 22:40:01.074 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:40:01.074 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:40:01.074 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 20
2025-03-26 22:40:01.078 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:40:01.078 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:40:01.079 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 20
2025-03-26 22:40:01.079 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 22:40:01.079 | INFO     | __main__:main:688 - Original max_steps: 40, start_step: 20
2025-03-26 22:40:01.079 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 40
2025-03-26 22:40:01.080 | INFO     | __main__:main:703 - Resuming from step 20/40
2025-03-26 22:40:05.966 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:40:05.967 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:40:05.967 | INFO     | __main__:main:740 - Training time: 3.77s
2025-03-26 22:40:05.967 | INFO     | __main__:main:741 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:40:05.968 | INFO     | __main__:main:744 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:40:05.968 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 22:40:05.968 | INFO     | __main__:main:788 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:40:05.968 | INFO     | __main__:main:809 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:40:05.969 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:40:05.969 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-223946_d64_l2_n4
2025-03-26 22:41:06.024 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:41:06.024 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:41:06.024 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:41:06.024 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:41:06.025 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:41:06.025 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:41:06.307 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:41:06.308 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:41:06.308 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:41:06.308 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:41:06.308 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:41:06.310 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:41:13.646 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:41:13.647 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:41:13.648 | INFO     | __main__:main:740 - Training time: 6.06s
2025-03-26 22:41:13.648 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:41:13.648 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:41:13.649 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:41:13.649 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:41:13.649 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-224106_d64_l2_n4
2025-03-26 22:41:22.418 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:41:22.419 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:41:22.419 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:41:22.419 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-224106_d64_l2_n4
2025-03-26 22:41:22.420 | INFO     | __main__:main:256 - Found run: 20250326-224106_d64_l2_n4
2025-03-26 22:41:22.420 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:41:22.420 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:41:22.421 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:41:22.421 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:41:22.421 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-224106_d64_l2_n4
2025-03-26 22:41:22.872 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:41:22.872 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:41:22.873 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:41:22.873 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:41:22.883 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:41:22.884 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:41:22.927 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:41:22.927 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:41:22.928 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:41:22.928 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:41:22.928 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:41:22.929 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:41:22.929 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-224106_d64_l2_n4
2025-03-26 22:41:22.933 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:41:22.934 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:41:22.934 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 20
2025-03-26 22:41:22.937 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:41:22.938 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:41:22.938 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 20
2025-03-26 22:41:22.938 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 22:41:22.938 | INFO     | __main__:main:688 - Original max_steps: 40, start_step: 20
2025-03-26 22:41:22.938 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 40
2025-03-26 22:41:22.939 | INFO     | __main__:main:703 - Resuming from step 20/40
2025-03-26 22:41:28.057 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:41:28.058 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:41:28.058 | INFO     | __main__:main:740 - Training time: 4.03s
2025-03-26 22:41:28.058 | INFO     | __main__:main:741 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:41:28.059 | INFO     | __main__:main:744 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:41:28.059 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 22:41:28.059 | INFO     | __main__:main:788 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:41:28.060 | INFO     | __main__:main:809 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:41:28.060 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:41:28.060 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-224106_d64_l2_n4
2025-03-26 22:43:15.690 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:43:15.691 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:43:15.691 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:43:15.691 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:43:15.692 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:43:15.692 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:43:15.970 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:43:15.970 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:43:15.970 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:43:15.970 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:43:15.971 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:43:15.972 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:43:22.145 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:43:22.146 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:43:22.146 | INFO     | __main__:main:740 - Training time: 5.14s
2025-03-26 22:43:22.147 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:43:22.147 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:43:22.147 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:43:22.148 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:43:22.148 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-224315_d64_l2_n4
2025-03-26 22:45:50.200 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:45:50.200 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:45:50.200 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:45:50.201 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:45:50.201 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:45:50.201 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:45:50.471 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:45:50.471 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:45:50.472 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:45:50.472 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:45:50.472 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:45:50.473 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:45:55.514 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:45:55.515 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:45:55.515 | INFO     | __main__:main:740 - Training time: 4.05s
2025-03-26 22:45:55.516 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:45:55.516 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:45:55.516 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:45:55.516 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:45:55.516 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-224550_d64_l2_n4
2025-03-26 22:46:04.782 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:46:04.782 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:46:04.782 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:46:04.782 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-224550_d64_l2_n4
2025-03-26 22:46:04.783 | INFO     | __main__:main:256 - Found run: 20250326-224550_d64_l2_n4
2025-03-26 22:46:04.783 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:46:04.784 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:46:04.784 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:46:04.784 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:46:04.785 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-224550_d64_l2_n4
2025-03-26 22:46:05.198 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:46:05.199 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:46:05.199 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:46:05.199 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:46:05.210 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:46:05.211 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:46:05.257 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:46:05.257 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:46:05.257 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:46:05.258 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:46:05.258 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:46:05.259 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:46:05.259 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-224550_d64_l2_n4
2025-03-26 22:46:05.265 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:46:05.265 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:46:05.265 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 20
2025-03-26 22:46:05.270 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:46:05.270 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:46:05.270 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 20
2025-03-26 22:46:05.271 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 22:46:05.271 | INFO     | __main__:main:688 - Original max_steps: 40, start_step: 20
2025-03-26 22:46:05.271 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 40
2025-03-26 22:46:05.271 | INFO     | __main__:main:703 - Resuming from step 20/40
2025-03-26 22:46:09.915 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:46:09.916 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:46:09.916 | INFO     | __main__:main:740 - Training time: 3.57s
2025-03-26 22:46:09.917 | INFO     | __main__:main:741 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:46:09.917 | INFO     | __main__:main:744 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:46:09.917 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 22:46:09.918 | INFO     | __main__:main:788 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:46:09.918 | INFO     | __main__:main:809 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:46:09.918 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:46:09.918 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-224550_d64_l2_n4
2025-03-26 22:51:02.991 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:51:02.992 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:51:02.992 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:51:02.992 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:51:02.992 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:51:02.993 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:51:03.268 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:51:03.268 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:51:03.268 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:51:03.269 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:51:03.269 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:51:03.270 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:51:08.981 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:51:08.982 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:51:08.982 | INFO     | __main__:main:740 - Training time: 4.71s
2025-03-26 22:51:08.982 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:51:08.983 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:51:08.983 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:51:08.984 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:51:08.984 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225103_d64_l2_n4
2025-03-26 22:51:18.406 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:51:18.406 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:51:18.406 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:51:18.407 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-225103_d64_l2_n4
2025-03-26 22:51:18.407 | INFO     | __main__:main:256 - Found run: 20250326-225103_d64_l2_n4
2025-03-26 22:51:18.407 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:51:18.408 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:51:18.408 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:51:18.408 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:51:18.409 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-225103_d64_l2_n4
2025-03-26 22:51:18.844 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:51:18.844 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:51:18.845 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:51:18.845 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:51:18.856 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:51:18.856 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:51:18.897 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:51:18.898 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:51:18.898 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:51:18.898 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:51:18.898 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:51:18.900 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:51:18.900 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-225103_d64_l2_n4
2025-03-26 22:51:18.904 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:51:18.905 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:51:18.905 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 20
2025-03-26 22:51:18.908 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:51:18.909 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:51:18.909 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 20
2025-03-26 22:51:18.909 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 22:51:18.909 | INFO     | __main__:main:688 - Original max_steps: 40, start_step: 20
2025-03-26 22:51:18.909 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 40
2025-03-26 22:51:18.910 | INFO     | __main__:main:703 - Resuming from step 20/40
2025-03-26 22:51:24.118 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:51:24.119 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:51:24.119 | INFO     | __main__:main:740 - Training time: 3.97s
2025-03-26 22:51:24.119 | INFO     | __main__:main:741 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:51:24.120 | INFO     | __main__:main:744 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:51:24.120 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 22:51:24.120 | INFO     | __main__:main:788 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:51:24.121 | INFO     | __main__:main:809 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:51:24.121 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:51:24.121 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225103_d64_l2_n4
2025-03-26 22:52:40.284 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:52:40.285 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:52:40.285 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:52:40.285 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:52:40.285 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:52:40.286 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:52:40.561 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:52:40.561 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:52:40.561 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:52:40.562 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:52:40.562 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:52:40.563 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:52:46.252 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:52:46.253 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:52:46.253 | INFO     | __main__:main:740 - Training time: 4.68s
2025-03-26 22:52:46.253 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:52:46.254 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:52:46.254 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:52:46.254 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:52:46.254 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225240_d64_l2_n4
2025-03-26 22:52:52.528 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:52:52.529 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:52:52.529 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:52:52.529 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-225240_d64_l2_n4
2025-03-26 22:52:52.530 | INFO     | __main__:main:256 - Found run: 20250326-225240_d64_l2_n4
2025-03-26 22:52:52.530 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:52:52.531 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:52:52.531 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:52:52.532 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:52:52.532 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-225240_d64_l2_n4
2025-03-26 22:52:52.928 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:52:52.928 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:52:52.928 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:52:52.928 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:52:52.940 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:52:52.940 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:52:52.981 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:52:52.981 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:52:52.981 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:52:52.982 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:52:52.982 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:52:52.983 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:52:52.983 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-225240_d64_l2_n4
2025-03-26 22:52:52.988 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:52:52.988 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:52:52.988 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 20
2025-03-26 22:52:52.992 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:52:52.992 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:52:52.992 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 20
2025-03-26 22:52:52.993 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 22:52:52.993 | INFO     | __main__:main:688 - Original max_steps: 40, start_step: 20
2025-03-26 22:52:52.993 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 40
2025-03-26 22:52:52.993 | INFO     | __main__:main:703 - Resuming from step 20/40
2025-03-26 22:52:57.714 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:52:57.714 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:52:57.715 | INFO     | __main__:main:740 - Training time: 3.61s
2025-03-26 22:52:57.715 | INFO     | __main__:main:741 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:52:57.715 | INFO     | __main__:main:744 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:52:57.715 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 22:52:57.716 | INFO     | __main__:main:788 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:52:57.716 | INFO     | __main__:main:809 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:52:57.716 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:52:57.716 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225240_d64_l2_n4
2025-03-26 22:55:03.351 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:55:03.351 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:55:03.352 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:55:03.352 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:55:03.352 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:55:03.353 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:55:03.633 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:55:03.634 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:55:03.634 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:55:03.634 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:55:03.634 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:55:03.636 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:55:09.069 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:55:09.069 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:55:09.070 | INFO     | __main__:main:740 - Training time: 4.42s
2025-03-26 22:55:09.070 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:55:09.070 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:55:09.070 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:55:09.071 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:55:09.071 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225503_d64_l2_n4
2025-03-26 22:55:17.283 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:55:17.283 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:55:17.283 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:55:17.283 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-225503_d64_l2_n4
2025-03-26 22:55:17.284 | INFO     | __main__:main:256 - Found run: 20250326-225503_d64_l2_n4
2025-03-26 22:55:17.284 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:55:17.285 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:55:17.285 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:55:17.285 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:55:17.286 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-225503_d64_l2_n4
2025-03-26 22:55:17.678 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:55:17.679 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:55:17.679 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:55:17.679 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:55:17.690 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:55:17.691 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:55:17.733 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:55:17.733 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:55:17.733 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:55:17.733 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:55:17.734 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:55:17.735 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:55:17.735 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-225503_d64_l2_n4
2025-03-26 22:55:17.740 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:55:17.741 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:55:17.741 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 20
2025-03-26 22:55:17.745 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:55:17.745 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:55:17.746 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 20
2025-03-26 22:55:17.746 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 22:55:17.746 | INFO     | __main__:main:688 - Original max_steps: 40, start_step: 20
2025-03-26 22:55:17.747 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 40
2025-03-26 22:55:17.747 | INFO     | __main__:main:703 - Resuming from step 20/40
2025-03-26 22:55:22.871 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:55:22.872 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:55:22.872 | INFO     | __main__:main:740 - Training time: 4.08s
2025-03-26 22:55:22.873 | INFO     | __main__:main:741 - SimpleTransformer: 1.807948 loss, 3.78% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:55:22.873 | INFO     | __main__:main:744 - LatentTransformer: 1.866596 loss, 4.49% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:55:22.873 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 22:55:22.874 | INFO     | __main__:main:788 - SimpleTransformer is 1.23x more parameter-efficient (loss*params)
2025-03-26 22:55:22.874 | INFO     | __main__:main:809 - SimpleTransformer is 1.00x more accuracy-per-parameter efficient
2025-03-26 22:55:22.874 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:55:22.874 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225503_d64_l2_n4
2025-03-26 22:58:29.887 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:58:29.887 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:58:29.887 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:58:29.887 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 22:58:29.888 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 22:58:29.888 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:58:30.186 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:58:30.187 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:58:30.187 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:58:30.187 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:58:30.187 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:58:30.189 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:58:35.242 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:58:35.243 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:58:35.243 | INFO     | __main__:main:740 - Training time: 3.98s
2025-03-26 22:58:35.244 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:58:35.244 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:58:35.244 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 22:58:35.245 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:58:35.245 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225830_d64_l2_n4
2025-03-26 22:58:44.663 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 22:58:44.663 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 22:58:44.664 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 22:58:44.664 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-225830_d64_l2_n4
2025-03-26 22:58:44.664 | INFO     | __main__:main:256 - Found run: 20250326-225830_d64_l2_n4
2025-03-26 22:58:44.665 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 22:58:44.665 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 22:58:44.666 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 22:58:44.666 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 22:58:44.666 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-225830_d64_l2_n4
2025-03-26 22:58:45.111 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 22:58:45.111 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 22:58:45.112 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 22:58:45.112 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 22:58:45.123 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 22:58:45.124 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 22:58:45.172 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 22:58:45.173 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 22:58:45.173 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 22:58:45.173 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 22:58:45.174 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 22:58:45.176 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 22:58:45.176 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-225830_d64_l2_n4
2025-03-26 22:58:45.182 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 22:58:45.182 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 22:58:45.182 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 10
2025-03-26 22:58:45.186 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 22:58:45.187 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 22:58:45.187 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 10
2025-03-26 22:58:45.188 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 22:58:45.188 | INFO     | __main__:main:688 - Original max_steps: 20, start_step: 10
2025-03-26 22:58:45.188 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 20
2025-03-26 22:58:45.188 | INFO     | __main__:main:703 - Resuming from step 10/20
2025-03-26 22:58:49.408 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 22:58:49.409 | INFO     | __main__:main:734 - ==================================================
2025-03-26 22:58:49.410 | INFO     | __main__:main:740 - Training time: 2.95s
2025-03-26 22:58:49.410 | INFO     | __main__:main:741 - SimpleTransformer: 1.820769 loss, 3.47% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-26 22:58:49.410 | INFO     | __main__:main:744 - LatentTransformer: 1.882688 loss, 4.08% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 22:58:49.411 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 22:58:49.411 | INFO     | __main__:main:788 - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-26 22:58:49.411 | INFO     | __main__:main:809 - SimpleTransformer is 1.02x more accuracy-per-parameter efficient
2025-03-26 22:58:49.412 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 22:58:49.412 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-225830_d64_l2_n4
2025-03-26 23:00:00.715 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:00:00.716 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:00:00.716 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:00:00.716 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 23:00:00.716 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 23:00:00.717 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:00:01.001 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:00:01.002 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:00:01.002 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:00:01.002 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:00:01.002 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:00:01.005 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:00:32.872 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 23:00:32.873 | INFO     | __main__:main:734 - ==================================================
2025-03-26 23:00:32.873 | INFO     | __main__:main:740 - Training time: 30.84s
2025-03-26 23:00:32.873 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 236,556 parameters
2025-03-26 23:00:32.874 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 23:00:32.874 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 23:00:32.874 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 23:00:32.875 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-230001_d64_l2_n4
2025-03-26 23:02:54.658 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:02:54.658 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:02:54.658 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:02:54.658 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 23:02:54.659 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 23:02:54.659 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:02:54.931 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:02:54.931 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:02:54.931 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:02:54.932 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:02:54.932 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:02:54.932 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:03:26.470 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 23:03:26.471 | INFO     | __main__:main:734 - ==================================================
2025-03-26 23:03:26.471 | INFO     | __main__:main:740 - Training time: 30.52s
2025-03-26 23:03:26.471 | INFO     | __main__:main:741 - SimpleTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 236,556 parameters
2025-03-26 23:03:26.471 | INFO     | __main__:main:744 - LatentTransformer: 0.000000 loss, 0.00% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 23:03:26.472 | INFO     | __main__:main:817 - Cannot calculate efficiency metrics due to invalid or zero loss values
2025-03-26 23:03:26.472 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 23:03:26.472 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-230254_d64_l2_n4
2025-03-26 23:04:18.296 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:04:18.296 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:04:18.296 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:04:18.297 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-230254_d64_l2_n4
2025-03-26 23:04:18.297 | INFO     | __main__:main:256 - Found run: 20250326-230254_d64_l2_n4
2025-03-26 23:04:18.297 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 23:04:18.298 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 23:04:18.298 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 23:04:18.298 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 23:04:18.298 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-230254_d64_l2_n4
2025-03-26 23:04:18.700 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 23:04:18.700 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 23:04:18.700 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 23:04:18.701 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 23:04:18.711 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 23:04:18.712 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:04:18.758 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:04:18.758 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:04:18.759 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:04:18.759 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:04:18.759 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:04:18.760 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:04:18.760 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-230254_d64_l2_n4
2025-03-26 23:04:18.764 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 23:04:18.765 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 23:04:18.765 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 200
2025-03-26 23:04:18.769 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 23:04:18.769 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 23:04:18.770 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 200
2025-03-26 23:04:18.770 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 23:04:18.770 | INFO     | __main__:main:688 - Original max_steps: 50, start_step: 200
2025-03-26 23:04:18.770 | INFO     | __main__:main:695 - Setting continuation_steps to 50 to allow full additional training
2025-03-26 23:04:18.771 | INFO     | __main__:main:703 - Resuming from step 200/50
2025-03-26 23:04:21.147 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 23:04:21.148 | INFO     | __main__:main:734 - ==================================================
2025-03-26 23:04:21.148 | INFO     | __main__:main:740 - Training time: 1.24s
2025-03-26 23:04:21.148 | INFO     | __main__:main:741 - SimpleTransformer: 1.794687 loss, 5.51% sequence accuracy, 0.00% digit accuracy, 236,556 parameters
2025-03-26 23:04:21.148 | INFO     | __main__:main:744 - LatentTransformer: 1.863985 loss, 5.92% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-26 23:04:21.149 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 23:04:21.149 | INFO     | __main__:main:788 - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-26 23:04:21.149 | INFO     | __main__:main:809 - SimpleTransformer is 1.11x more accuracy-per-parameter efficient
2025-03-26 23:04:21.149 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 23:04:21.150 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-230254_d64_l2_n4
2025-03-26 23:06:41.352 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:06:41.352 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:06:41.353 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:06:41.353 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250326-230254_d64_l2_n4
2025-03-26 23:06:41.353 | INFO     | __main__:main:256 - Found run: 20250326-230254_d64_l2_n4
2025-03-26 23:06:41.353 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-26 23:06:41.354 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-26 23:06:41.354 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-26 23:06:41.354 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-26 23:06:41.355 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250326-230254_d64_l2_n4
2025-03-26 23:06:41.737 | INFO     | __main__:main:362 - Found d_model=64 in checkpoint config
2025-03-26 23:06:41.737 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-26 23:06:41.738 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-26 23:06:41.738 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-26 23:06:41.749 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-26 23:06:41.750 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:06:41.789 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:06:41.790 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:06:41.790 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:06:41.790 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:06:41.790 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:06:41.791 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:06:41.791 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250326-230254_d64_l2_n4
2025-03-26 23:06:41.795 | INFO     | __main__:main:639 - Loaded filtered SimpleTransformer state dict with 68 parameters
2025-03-26 23:06:41.795 | INFO     | __main__:main:648 - Successfully loaded SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-26 23:06:41.795 | INFO     | __main__:main:651 - Resuming SimpleTransformer from step 200
2025-03-26 23:06:41.799 | INFO     | __main__:main:660 - Loaded filtered LatentTransformer state dict with 83 parameters
2025-03-26 23:06:41.799 | INFO     | __main__:main:669 - Successfully loaded LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-26 23:06:41.800 | INFO     | __main__:main:672 - Resuming LatentTransformer from step 200
2025-03-26 23:06:41.800 | INFO     | __main__:main:687 - Calculating continuation steps for resumed training
2025-03-26 23:06:41.800 | INFO     | __main__:main:688 - Original max_steps: 250, start_step: 200
2025-03-26 23:06:41.800 | INFO     | __main__:main:699 - No continuation steps needed, continuing to target 250
2025-03-26 23:06:41.801 | INFO     | __main__:main:703 - Resuming from step 200/250
2025-03-26 23:06:50.750 | INFO     | __main__:main:733 - 
Final Comparison:
2025-03-26 23:06:50.751 | INFO     | __main__:main:734 - ==================================================
2025-03-26 23:06:50.751 | INFO     | __main__:main:740 - Training time: 7.89s
2025-03-26 23:06:50.752 | INFO     | __main__:main:741 - SimpleTransformer: 1.632085 loss, 5.31% sequence accuracy, 18.18% digit accuracy, 236,556 parameters
2025-03-26 23:06:50.752 | INFO     | __main__:main:744 - LatentTransformer: 1.696267 loss, 5.82% sequence accuracy, 9.09% digit accuracy, 282,636 parameters
2025-03-26 23:06:50.752 | INFO     | __main__:main:773 - 
Efficiency Metrics:
2025-03-26 23:06:50.752 | INFO     | __main__:main:788 - SimpleTransformer is 1.24x more parameter-efficient (loss*params)
2025-03-26 23:06:50.753 | INFO     | __main__:main:809 - SimpleTransformer is 1.09x more accuracy-per-parameter efficient
2025-03-26 23:06:50.753 | INFO     | __main__:main:821 - 
To view parallel training curves, run:
2025-03-26 23:06:50.753 | INFO     | __main__:main:822 - tensorboard --logdir=runs/parallel_comparison/20250326-230254_d64_l2_n4
2025-03-26 23:11:26.764 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:11:26.764 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:11:26.764 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:11:26.765 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 23:11:26.765 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 23:11:26.766 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:11:27.066 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:11:27.067 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:11:27.067 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:11:27.067 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:11:27.068 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:11:27.068 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:12:05.674 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:12:05.674 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:12:05.674 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:12:05.674 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 23:12:05.675 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 23:12:05.675 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:12:05.952 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:12:05.952 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:12:05.952 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:12:05.953 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:12:05.953 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:12:05.954 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:15:39.045 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:15:39.046 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:15:39.046 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:15:39.046 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 23:15:39.046 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 23:15:39.047 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:15:39.314 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:15:39.314 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:15:39.314 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:15:39.315 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:15:39.315 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:15:39.316 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:16:00.159 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:16:00.159 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:16:00.160 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:16:00.160 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 23:16:00.160 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 23:16:00.161 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:16:00.434 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:16:00.434 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:16:00.434 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:16:00.434 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:16:00.435 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:16:00.436 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-26 23:18:03.417 | INFO     | __main__:main:225 - Using device: cuda
2025-03-26 23:18:03.417 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-26 23:18:03.417 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-26 23:18:03.417 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-26 23:18:03.418 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-26 23:18:03.418 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-26 23:18:03.665 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-26 23:18:03.665 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-26 23:18:03.665 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-26 23:18:03.665 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-26 23:18:03.666 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-26 23:18:03.666 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 22:32:17.033 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 22:32:17.034 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 22:32:17.034 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 22:32:17.034 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 22:32:17.035 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 22:32:17.035 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 22:32:17.353 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 22:32:17.354 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 22:32:17.354 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 22:32:17.354 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 22:32:17.354 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 22:32:17.356 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 22:33:41.427 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 22:33:41.427 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 22:33:41.427 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 22:33:41.428 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 22:33:41.428 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 22:33:41.428 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 22:33:41.685 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 22:33:41.686 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 22:33:41.686 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 22:33:41.686 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 22:33:41.686 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 22:33:41.687 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 22:58:53.242 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 22:58:53.243 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 22:58:53.244 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 22:58:53.244 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 22:58:53.244 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 22:58:53.245 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 22:58:53.552 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 22:58:53.553 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 22:58:53.553 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 22:58:53.553 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 22:58:53.554 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 22:58:53.555 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:17:11.529 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:17:11.529 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:17:11.529 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:17:11.529 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:17:11.530 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:17:11.530 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:17:11.805 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:17:11.806 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:17:11.806 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:17:11.806 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:17:11.806 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:17:11.807 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:20:00.106 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:20:00.106 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:20:00.107 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:20:00.107 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:20:00.107 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:20:00.108 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:20:00.369 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:20:00.369 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:20:00.369 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:20:00.370 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:20:00.370 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:20:00.371 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:25:15.363 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:25:15.363 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:25:15.363 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:25:15.364 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:25:15.364 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:25:15.365 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:25:15.625 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:25:15.626 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:25:15.626 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:25:15.626 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:25:15.626 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:25:15.627 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:26:49.410 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:26:49.411 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:26:49.411 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:26:49.777 | INFO     | __main__:main:362 - Found d_model=320 in checkpoint config
2025-03-27 23:26:49.778 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-27 23:26:49.778 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-27 23:26:49.778 | INFO     | __main__:main:411 - Updating d_model from 384 to 320 to match checkpoint
2025-03-27 23:26:49.778 | INFO     | __main__:main:418 - Updating num_layers from 4 to 2 to match checkpoint
2025-03-27 23:26:49.779 | INFO     | __main__:main:439 - Updating num_latent from 8 to 10 to match checkpoint
2025-03-27 23:26:49.779 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-27 23:26:49.790 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-27 23:26:49.790 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:26:49.937 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:26:49.937 | INFO     | __main__:main:557 - SimpleTransformer: 5,770,252
2025-03-27 23:26:49.938 | INFO     | __main__:main:558 - LatentTransformer: 6,903,692
2025-03-27 23:26:49.938 | INFO     | __main__:main:559 - Parameter ratio: 1.20x
2025-03-27 23:26:49.938 | INFO     | __main__:main:560 - Difference: 1,133,440 parameters (19.6%)
2025-03-27 23:26:49.939 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:26:49.940 | INFO     | __main__:main:636 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-27 23:27:42.992 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:27:42.992 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:27:42.993 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:27:43.354 | INFO     | __main__:main:362 - Found d_model=320 in checkpoint config
2025-03-27 23:27:43.354 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-27 23:27:43.355 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-27 23:27:43.355 | INFO     | __main__:main:411 - Updating d_model from 384 to 320 to match checkpoint
2025-03-27 23:27:43.355 | INFO     | __main__:main:418 - Updating num_layers from 4 to 2 to match checkpoint
2025-03-27 23:27:43.355 | INFO     | __main__:main:439 - Updating num_latent from 8 to 10 to match checkpoint
2025-03-27 23:27:43.355 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-27 23:27:43.366 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-27 23:27:43.367 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:27:43.523 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:27:43.523 | INFO     | __main__:main:557 - SimpleTransformer: 5,770,252
2025-03-27 23:27:43.524 | INFO     | __main__:main:558 - LatentTransformer: 6,903,692
2025-03-27 23:27:43.524 | INFO     | __main__:main:559 - Parameter ratio: 1.20x
2025-03-27 23:27:43.524 | INFO     | __main__:main:560 - Difference: 1,133,440 parameters (19.6%)
2025-03-27 23:27:43.525 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:27:43.526 | INFO     | __main__:main:636 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-27 23:28:49.233 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:28:49.233 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:28:49.234 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:28:49.234 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:28:49.234 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:28:49.235 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:28:49.500 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:28:49.501 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:28:49.501 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:28:49.501 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:28:49.501 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:28:49.502 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:29:05.141 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:29:05.141 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:29:05.142 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:29:05.142 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:29:05.142 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:29:05.143 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:29:05.405 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:29:05.405 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:29:05.405 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:29:05.406 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:29:05.406 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:29:05.407 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:34:08.358 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:34:08.358 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:34:08.359 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:34:08.359 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:34:08.359 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:34:08.360 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:34:08.615 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:34:08.616 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:34:08.616 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:34:08.616 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:34:08.617 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:34:08.617 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:34:43.576 | INFO     | __main__:main:675 - 
Final Comparison:
2025-03-27 23:34:43.576 | INFO     | __main__:main:676 - ==================================================
2025-03-27 23:34:43.576 | INFO     | __main__:main:682 - Training time: 33.96s
2025-03-27 23:34:43.577 | INFO     | __main__:main:683 - SimpleTransformer: 1.119071 loss, 63.93% sequence accuracy, 0.00% digit accuracy, 236,556 parameters
2025-03-27 23:34:43.577 | INFO     | __main__:main:686 - LatentTransformer: 1.103361 loss, 63.93% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-27 23:34:43.577 | INFO     | __main__:main:715 - 
Efficiency Metrics:
2025-03-27 23:34:43.577 | INFO     | __main__:main:730 - SimpleTransformer is 1.18x more parameter-efficient (loss*params)
2025-03-27 23:34:43.578 | INFO     | __main__:main:751 - SimpleTransformer is 1.19x more accuracy-per-parameter efficient
2025-03-27 23:34:43.578 | INFO     | __main__:main:763 - 
To view parallel training curves, run:
2025-03-27 23:34:43.578 | INFO     | __main__:main:764 - tensorboard --logdir=runs/parallel_comparison/20250327-233408_d64_l2_n4
2025-03-27 23:35:51.231 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:35:51.232 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:35:51.232 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:35:51.232 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250327-233408_d64_l2_n4
2025-03-27 23:35:51.232 | INFO     | __main__:main:256 - Found run: 20250327-233408_d64_l2_n4
2025-03-27 23:35:51.233 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-27 23:35:51.233 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-27 23:35:51.233 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-27 23:35:51.234 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-27 23:35:51.234 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250327-233408_d64_l2_n4
2025-03-27 23:35:51.595 | INFO     | __main__:main:362 - Found d_model=320 in checkpoint config
2025-03-27 23:35:51.595 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-27 23:35:51.595 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-27 23:35:51.596 | INFO     | __main__:main:411 - Updating d_model from 64 to 320 to match checkpoint
2025-03-27 23:35:51.596 | INFO     | __main__:main:439 - Updating num_latent from 4 to 10 to match checkpoint
2025-03-27 23:35:51.596 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-27 23:35:51.606 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-27 23:35:51.607 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:35:51.746 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:35:51.747 | INFO     | __main__:main:557 - SimpleTransformer: 5,770,252
2025-03-27 23:35:51.747 | INFO     | __main__:main:558 - LatentTransformer: 6,903,692
2025-03-27 23:35:51.747 | INFO     | __main__:main:559 - Parameter ratio: 1.20x
2025-03-27 23:35:51.748 | INFO     | __main__:main:560 - Difference: 1,133,440 parameters (19.6%)
2025-03-27 23:35:51.748 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:35:51.748 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250327-233408_d64_l2_n4
2025-03-27 23:35:51.749 | INFO     | __main__:main:636 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-27 23:51:11.858 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:51:11.859 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:51:11.859 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:51:11.860 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250327-233408_d64_l2_n4
2025-03-27 23:51:11.860 | INFO     | __main__:main:256 - Found run: 20250327-233408_d64_l2_n4
2025-03-27 23:51:11.861 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-27 23:51:11.861 | INFO     | __main__:main:277 - Using d_model=320 from run config (override 384)
2025-03-27 23:51:11.861 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-27 23:51:11.862 | INFO     | __main__:main:289 - Using num_latent=10 from run config (override 8)
2025-03-27 23:51:11.862 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250327-233408_d64_l2_n4
2025-03-27 23:51:12.300 | INFO     | __main__:main:362 - Found d_model=320 in checkpoint config
2025-03-27 23:51:12.301 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-27 23:51:12.301 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-27 23:51:12.301 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-27 23:51:12.312 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-27 23:51:12.312 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:51:12.488 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:51:12.489 | INFO     | __main__:main:557 - SimpleTransformer: 5,770,252
2025-03-27 23:51:12.489 | INFO     | __main__:main:558 - LatentTransformer: 6,903,692
2025-03-27 23:51:12.489 | INFO     | __main__:main:559 - Parameter ratio: 1.20x
2025-03-27 23:51:12.489 | INFO     | __main__:main:560 - Difference: 1,133,440 parameters (19.6%)
2025-03-27 23:51:12.490 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:51:12.490 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250327-233408_d64_l2_n4
2025-03-27 23:51:12.491 | INFO     | __main__:main:636 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-27 23:51:35.005 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:51:35.006 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:51:35.006 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:51:35.006 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:51:35.006 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:51:35.007 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:51:35.276 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:51:35.276 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:51:35.276 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:51:35.277 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:51:35.277 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:51:35.278 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:51:38.814 | INFO     | __main__:main:675 - 
Final Comparison:
2025-03-27 23:51:38.815 | INFO     | __main__:main:676 - ==================================================
2025-03-27 23:51:38.815 | INFO     | __main__:main:682 - Training time: 1.90s
2025-03-27 23:51:38.815 | INFO     | __main__:main:683 - SimpleTransformer: 1.786141 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-27 23:51:38.815 | INFO     | __main__:main:686 - LatentTransformer: 1.743914 loss, 42.62% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-27 23:51:38.816 | INFO     | __main__:main:715 - 
Efficiency Metrics:
2025-03-27 23:51:38.816 | INFO     | __main__:main:730 - SimpleTransformer is 1.17x more parameter-efficient (loss*params)
2025-03-27 23:51:38.816 | INFO     | __main__:main:751 - SimpleTransformer is 1.15x more accuracy-per-parameter efficient
2025-03-27 23:51:38.816 | INFO     | __main__:main:763 - 
To view parallel training curves, run:
2025-03-27 23:51:38.817 | INFO     | __main__:main:764 - tensorboard --logdir=runs/parallel_comparison/20250327-235135_d64_l2_n4
2025-03-27 23:52:34.061 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:52:34.061 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:52:34.061 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:52:34.061 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:52:34.062 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:52:34.062 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:52:34.323 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:52:34.324 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:52:34.324 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:52:34.324 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:52:34.324 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:52:34.325 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:52:36.915 | INFO     | __main__:main:675 - 
Final Comparison:
2025-03-27 23:52:36.916 | INFO     | __main__:main:676 - ==================================================
2025-03-27 23:52:36.916 | INFO     | __main__:main:682 - Training time: 1.57s
2025-03-27 23:52:36.916 | INFO     | __main__:main:683 - SimpleTransformer: 1.786141 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-27 23:52:36.916 | INFO     | __main__:main:686 - LatentTransformer: 1.743914 loss, 42.62% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-27 23:52:36.917 | INFO     | __main__:main:715 - 
Efficiency Metrics:
2025-03-27 23:52:36.917 | INFO     | __main__:main:730 - SimpleTransformer is 1.17x more parameter-efficient (loss*params)
2025-03-27 23:52:36.917 | INFO     | __main__:main:751 - SimpleTransformer is 1.15x more accuracy-per-parameter efficient
2025-03-27 23:52:36.917 | INFO     | __main__:main:763 - 
To view parallel training curves, run:
2025-03-27 23:52:36.918 | INFO     | __main__:main:764 - tensorboard --logdir=runs/parallel_comparison/20250327-235234_d64_l2_n4
2025-03-27 23:54:28.706 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:54:28.706 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:54:28.707 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:54:28.707 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:54:28.707 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:54:28.708 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:54:28.961 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:54:28.961 | INFO     | __main__:main:557 - SimpleTransformer: 236,556
2025-03-27 23:54:28.961 | INFO     | __main__:main:558 - LatentTransformer: 282,636
2025-03-27 23:54:28.962 | INFO     | __main__:main:559 - Parameter ratio: 1.19x
2025-03-27 23:54:28.962 | INFO     | __main__:main:560 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:54:28.962 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:54:48.018 | INFO     | __main__:main:675 - 
Final Comparison:
2025-03-27 23:54:48.018 | INFO     | __main__:main:676 - ==================================================
2025-03-27 23:54:48.019 | INFO     | __main__:main:682 - Training time: 18.07s
2025-03-27 23:54:48.019 | INFO     | __main__:main:683 - SimpleTransformer: 1.481389 loss, 57.38% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-27 23:54:48.019 | INFO     | __main__:main:686 - LatentTransformer: 1.425490 loss, 62.30% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-27 23:54:48.019 | INFO     | __main__:main:715 - 
Efficiency Metrics:
2025-03-27 23:54:48.020 | INFO     | __main__:main:730 - SimpleTransformer is 1.15x more parameter-efficient (loss*params)
2025-03-27 23:54:48.020 | INFO     | __main__:main:751 - SimpleTransformer is 1.10x more accuracy-per-parameter efficient
2025-03-27 23:54:48.020 | INFO     | __main__:main:763 - 
To view parallel training curves, run:
2025-03-27 23:54:48.020 | INFO     | __main__:main:764 - tensorboard --logdir=runs/parallel_comparison/20250327-235428_d64_l2_n4
2025-03-27 23:55:41.289 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:55:41.290 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:55:41.290 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:55:41.290 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250327-233408_d64_l2_n4
2025-03-27 23:55:41.291 | INFO     | __main__:main:256 - Found run: 20250327-233408_d64_l2_n4
2025-03-27 23:55:41.291 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-27 23:55:41.291 | INFO     | __main__:main:277 - Using d_model=320 from run config (override 384)
2025-03-27 23:55:41.292 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-27 23:55:41.292 | INFO     | __main__:main:289 - Using num_latent=10 from run config (override 8)
2025-03-27 23:55:41.292 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250327-233408_d64_l2_n4
2025-03-27 23:55:41.647 | INFO     | __main__:main:362 - Found d_model=320 in checkpoint config
2025-03-27 23:55:41.648 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-27 23:55:41.648 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-27 23:55:41.648 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-27 23:55:41.658 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-27 23:55:41.659 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:55:41.812 | INFO     | __main__:main:556 - 
Model Parameters:
2025-03-27 23:55:41.812 | INFO     | __main__:main:557 - SimpleTransformer: 5,770,252
2025-03-27 23:55:41.813 | INFO     | __main__:main:558 - LatentTransformer: 6,903,692
2025-03-27 23:55:41.813 | INFO     | __main__:main:559 - Parameter ratio: 1.20x
2025-03-27 23:55:41.813 | INFO     | __main__:main:560 - Difference: 1,133,440 parameters (19.6%)
2025-03-27 23:55:41.814 | INFO     | __main__:main:592 - 
Training both models in parallel...
2025-03-27 23:55:41.814 | INFO     | __main__:main:598 - Using consistent log directory for resumed training: runs/parallel_comparison/20250327-233408_d64_l2_n4
2025-03-27 23:55:41.815 | INFO     | __main__:main:636 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-27 23:58:47.640 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:58:47.641 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:58:47.641 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:58:47.641 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:58:47.642 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:58:47.642 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:59:20.621 | INFO     | __main__:main:225 - Using device: cuda
2025-03-27 23:59:20.622 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-27 23:59:20.622 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-27 23:59:20.622 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-27 23:59:20.622 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-27 23:59:20.623 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-27 23:59:22.890 | INFO     | __main__:main:585 - Models compiled with torch.compile()
2025-03-27 23:59:23.163 | INFO     | __main__:main:597 - 
Model Parameters:
2025-03-27 23:59:23.164 | INFO     | __main__:main:598 - SimpleTransformer: 236,556
2025-03-27 23:59:23.164 | INFO     | __main__:main:599 - LatentTransformer: 282,636
2025-03-27 23:59:23.164 | INFO     | __main__:main:600 - Parameter ratio: 1.19x
2025-03-27 23:59:23.164 | INFO     | __main__:main:601 - Difference: 46,080 parameters (19.5%)
2025-03-27 23:59:23.166 | INFO     | __main__:main:633 - 
Training both models in parallel...
2025-03-28 00:00:22.122 | INFO     | __main__:main:225 - Using device: cuda
2025-03-28 00:00:22.122 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:00:22.123 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-28 00:00:22.521 | INFO     | __main__:main:362 - Found d_model=320 in checkpoint config
2025-03-28 00:00:22.522 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-28 00:00:22.522 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-28 00:00:22.522 | INFO     | __main__:main:411 - Updating d_model from 384 to 320 to match checkpoint
2025-03-28 00:00:22.522 | INFO     | __main__:main:418 - Updating num_layers from 4 to 2 to match checkpoint
2025-03-28 00:00:22.523 | INFO     | __main__:main:439 - Updating num_latent from 8 to 10 to match checkpoint
2025-03-28 00:00:22.523 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-28 00:00:22.535 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-28 00:00:22.535 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-28 00:00:24.688 | INFO     | __main__:main:585 - Models compiled with torch.compile()
2025-03-28 00:00:24.726 | INFO     | __main__:main:597 - 
Model Parameters:
2025-03-28 00:00:24.726 | INFO     | __main__:main:598 - SimpleTransformer: 5,770,252
2025-03-28 00:00:24.726 | INFO     | __main__:main:599 - LatentTransformer: 6,903,692
2025-03-28 00:00:24.727 | INFO     | __main__:main:600 - Parameter ratio: 1.20x
2025-03-28 00:00:24.727 | INFO     | __main__:main:601 - Difference: 1,133,440 parameters (19.6%)
2025-03-28 00:00:24.728 | INFO     | __main__:main:633 - 
Training both models in parallel...
2025-03-28 00:00:24.729 | INFO     | __main__:main:677 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:00:24.803 | ERROR    | __main__:main:690 - Model dimension mismatch! Checkpoint has d_model=64 but created model with d_model=320
2025-03-28 00:00:24.804 | ERROR    | __main__:main:691 - This will cause size mismatch errors. Recreating the model with correct dimensions...
2025-03-28 00:00:24.817 | INFO     | __main__:main:709 - Loaded SimpleTransformer model weights
2025-03-28 00:00:24.817 | INFO     | __main__:main:717 - Loading LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-28 00:00:25.022 | ERROR    | __main__:main:752 - Error loading LatentTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.latent_tokens: copying a param with shape torch.Size([4, 64]) from checkpoint, the shape in current model is torch.Size([10, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_q.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_q.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_k.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_k.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_v.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_v.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_mlp.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.latent_mlp.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.latent_mlp.2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.latent_mlp.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:00:25.022 | ERROR    | __main__:main:753 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:04:44.912 | INFO     | __main__:main:225 - Using device: cuda
2025-03-28 00:04:44.913 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:04:44.913 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-28 00:04:44.913 | INFO     | __main__:main:465 - Using train dataset with range 1-9
2025-03-28 00:04:44.914 | INFO     | __main__:main:474 - Using val dataset with range 1-9
2025-03-28 00:04:44.914 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-28 00:04:46.993 | INFO     | __main__:main:585 - Models compiled with torch.compile()
2025-03-28 00:04:47.250 | INFO     | __main__:main:597 - 
Model Parameters:
2025-03-28 00:04:47.250 | INFO     | __main__:main:598 - SimpleTransformer: 236,556
2025-03-28 00:04:47.251 | INFO     | __main__:main:599 - LatentTransformer: 282,636
2025-03-28 00:04:47.251 | INFO     | __main__:main:600 - Parameter ratio: 1.19x
2025-03-28 00:04:47.251 | INFO     | __main__:main:601 - Difference: 46,080 parameters (19.5%)
2025-03-28 00:04:47.252 | INFO     | __main__:main:633 - 
Training both models in parallel...
2025-03-28 00:05:19.741 | INFO     | __main__:main:777 - 
Final Comparison:
2025-03-28 00:05:19.741 | INFO     | __main__:main:778 - ==================================================
2025-03-28 00:05:19.741 | INFO     | __main__:main:784 - Training time: 32.48s
2025-03-28 00:05:19.742 | INFO     | __main__:main:785 - SimpleTransformer: 1.784371 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-28 00:05:19.742 | INFO     | __main__:main:788 - LatentTransformer: 1.742133 loss, 42.62% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-28 00:05:19.742 | INFO     | __main__:main:817 - 
Efficiency Metrics:
2025-03-28 00:05:19.742 | INFO     | __main__:main:832 - SimpleTransformer is 1.17x more parameter-efficient (loss*params)
2025-03-28 00:05:19.743 | INFO     | __main__:main:853 - SimpleTransformer is 1.15x more accuracy-per-parameter efficient
2025-03-28 00:05:19.743 | INFO     | __main__:main:865 - 
To view parallel training curves, run:
2025-03-28 00:05:19.743 | INFO     | __main__:main:866 - tensorboard --logdir=runs/parallel_comparison/20250328-000447_d64_l2_n4
2025-03-28 00:06:24.752 | INFO     | __main__:main:225 - Using device: cuda
2025-03-28 00:06:24.752 | INFO     | __main__:main:229 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:06:24.753 | INFO     | __main__:main:230 - This reduces loss for correct token predictions during training
2025-03-28 00:06:24.753 | INFO     | __main__:main:252 - Attempting to resume from run ID: 20250328-000447_d64_l2_n4
2025-03-28 00:06:24.753 | INFO     | __main__:main:256 - Found run: 20250328-000447_d64_l2_n4
2025-03-28 00:06:24.754 | INFO     | __main__:main:268 - Using seed=42 from run config (override 42)
2025-03-28 00:06:24.754 | INFO     | __main__:main:277 - Using d_model=64 from run config (override 384)
2025-03-28 00:06:24.754 | INFO     | __main__:main:283 - Using num_layers=2 from run config (override 4)
2025-03-28 00:06:24.755 | INFO     | __main__:main:289 - Using num_latent=4 from run config (override 8)
2025-03-28 00:06:24.755 | INFO     | __main__:main:331 - Using checkpoint paths from run 20250328-000447_d64_l2_n4
2025-03-28 00:06:25.106 | INFO     | __main__:main:362 - Found d_model=320 in checkpoint config
2025-03-28 00:06:25.106 | INFO     | __main__:main:372 - Found vocab_size=12 in checkpoint state dict
2025-03-28 00:06:25.107 | INFO     | __main__:main:397 - Detected 2 layers from checkpoint state dict
2025-03-28 00:06:25.107 | INFO     | __main__:main:411 - Updating d_model from 64 to 320 to match checkpoint
2025-03-28 00:06:25.107 | INFO     | __main__:main:439 - Updating num_latent from 4 to 10 to match checkpoint
2025-03-28 00:06:25.107 | INFO     | __main__:main:465 - Using train dataset with range 1-99
2025-03-28 00:06:25.118 | INFO     | __main__:main:474 - Using val dataset with range 1-99
2025-03-28 00:06:25.118 | INFO     | __main__:main:531 - Using vocabulary size: 12
2025-03-28 00:06:27.115 | INFO     | __main__:main:585 - Models compiled with torch.compile()
2025-03-28 00:06:27.149 | INFO     | __main__:main:597 - 
Model Parameters:
2025-03-28 00:06:27.149 | INFO     | __main__:main:598 - SimpleTransformer: 5,770,252
2025-03-28 00:06:27.149 | INFO     | __main__:main:599 - LatentTransformer: 6,903,692
2025-03-28 00:06:27.150 | INFO     | __main__:main:600 - Parameter ratio: 1.20x
2025-03-28 00:06:27.150 | INFO     | __main__:main:601 - Difference: 1,133,440 parameters (19.6%)
2025-03-28 00:06:27.151 | INFO     | __main__:main:633 - 
Training both models in parallel...
2025-03-28 00:06:27.151 | INFO     | __main__:main:639 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-000447_d64_l2_n4
2025-03-28 00:06:27.152 | INFO     | __main__:main:677 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:06:27.219 | ERROR    | __main__:main:690 - Model dimension mismatch! Checkpoint has d_model=64 but created model with d_model=320
2025-03-28 00:06:27.220 | ERROR    | __main__:main:691 - This will cause size mismatch errors. Recreating the model with correct dimensions...
2025-03-28 00:06:27.232 | INFO     | __main__:main:709 - Loaded SimpleTransformer model weights
2025-03-28 00:06:27.233 | INFO     | __main__:main:717 - Loading LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-28 00:06:27.434 | ERROR    | __main__:main:752 - Error loading LatentTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.latent_tokens: copying a param with shape torch.Size([4, 64]) from checkpoint, the shape in current model is torch.Size([10, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_q.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_q.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_k.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_k.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_v.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_v.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_mlp.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.latent_mlp.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.latent_mlp.2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.latent_mlp.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:06:27.434 | ERROR    | __main__:main:753 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:18:13.381 | INFO     | __main__:main:294 - Using device: cuda
2025-03-28 00:18:13.382 | INFO     | __main__:main:298 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:18:13.382 | INFO     | __main__:main:299 - This reduces loss for correct token predictions during training
2025-03-28 00:18:13.382 | INFO     | __main__:main:469 - Using train dataset with range 1-9
2025-03-28 00:18:13.383 | INFO     | __main__:main:478 - Using val dataset with range 1-9
2025-03-28 00:18:13.383 | INFO     | __main__:main:535 - Using vocabulary size: 12
2025-03-28 00:18:15.381 | INFO     | __main__:main:589 - Models compiled with torch.compile()
2025-03-28 00:18:15.595 | INFO     | __main__:main:601 - 
Model Parameters:
2025-03-28 00:18:15.595 | INFO     | __main__:main:602 - SimpleTransformer: 236,556
2025-03-28 00:18:15.595 | INFO     | __main__:main:603 - LatentTransformer: 282,636
2025-03-28 00:18:15.596 | INFO     | __main__:main:604 - Parameter ratio: 1.19x
2025-03-28 00:18:15.596 | INFO     | __main__:main:605 - Difference: 46,080 parameters (19.5%)
2025-03-28 00:18:15.597 | INFO     | __main__:main:637 - 
Training both models in parallel...
2025-03-28 00:18:50.527 | INFO     | __main__:main:765 - 
Final Comparison:
2025-03-28 00:18:50.528 | INFO     | __main__:main:766 - ==================================================
2025-03-28 00:18:50.528 | INFO     | __main__:main:772 - Training time: 34.92s
2025-03-28 00:18:50.528 | INFO     | __main__:main:773 - SimpleTransformer: 1.784371 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-28 00:18:50.529 | INFO     | __main__:main:776 - LatentTransformer: 1.742133 loss, 42.62% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-28 00:18:50.529 | INFO     | __main__:main:805 - 
Efficiency Metrics:
2025-03-28 00:18:50.529 | INFO     | __main__:main:820 - SimpleTransformer is 1.17x more parameter-efficient (loss*params)
2025-03-28 00:18:50.529 | INFO     | __main__:main:841 - SimpleTransformer is 1.15x more accuracy-per-parameter efficient
2025-03-28 00:18:50.530 | INFO     | __main__:main:853 - 
To view parallel training curves, run:
2025-03-28 00:18:50.530 | INFO     | __main__:main:854 - tensorboard --logdir=runs/parallel_comparison/20250328-001815_d64_l2_n4
2025-03-28 00:19:18.102 | INFO     | __main__:main:294 - Using device: cuda
2025-03-28 00:19:18.102 | INFO     | __main__:main:298 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:19:18.102 | INFO     | __main__:main:299 - This reduces loss for correct token predictions during training
2025-03-28 00:19:18.103 | INFO     | __main__:main:321 - Attempting to resume from run ID: 20250328-001815_d64_l2_n4
2025-03-28 00:19:18.103 | INFO     | __main__:main:325 - Found run: 20250328-001815_d64_l2_n4
2025-03-28 00:19:18.103 | INFO     | __main__:main:337 - Using seed=42 from run config (override 42)
2025-03-28 00:19:18.104 | INFO     | __main__:main:346 - Using d_model=64 from run config (override 384)
2025-03-28 00:19:18.104 | INFO     | __main__:main:352 - Using num_layers=2 from run config (override 4)
2025-03-28 00:19:18.104 | INFO     | __main__:main:358 - Using num_latent=4 from run config (override 8)
2025-03-28 00:19:18.105 | INFO     | __main__:main:400 - Using checkpoint paths from run 20250328-001815_d64_l2_n4
2025-03-28 00:19:18.105 | INFO     | __main__:main:417 - Loading checkpoints to extract model dimensions
2025-03-28 00:19:18.444 | INFO     | __main__:main:426 - Dimensions from SimpleTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10}
2025-03-28 00:19:18.444 | INFO     | __main__:main:427 - Dimensions from LatentTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10}
2025-03-28 00:19:18.444 | INFO     | __main__:main:431 - Setting d_model to 320 from checkpoint
2025-03-28 00:19:18.445 | INFO     | __main__:main:435 - Setting num_layers to 5 from checkpoint
2025-03-28 00:19:18.445 | INFO     | __main__:main:439 - Setting num_latent to 10 from checkpoint
2025-03-28 00:19:18.445 | INFO     | __main__:main:446 - Using vocab_size=12 from checkpoint
2025-03-28 00:19:18.445 | INFO     | __main__:main:469 - Using train dataset with range 1-99
2025-03-28 00:19:18.456 | INFO     | __main__:main:478 - Using val dataset with range 1-99
2025-03-28 00:19:18.457 | INFO     | __main__:main:535 - Using vocabulary size: 12
2025-03-28 00:19:20.633 | INFO     | __main__:main:589 - Models compiled with torch.compile()
2025-03-28 00:19:20.690 | INFO     | __main__:main:601 - 
Model Parameters:
2025-03-28 00:19:20.691 | INFO     | __main__:main:602 - SimpleTransformer: 14,402,572
2025-03-28 00:19:20.691 | INFO     | __main__:main:603 - LatentTransformer: 15,536,012
2025-03-28 00:19:20.691 | INFO     | __main__:main:604 - Parameter ratio: 1.08x
2025-03-28 00:19:20.692 | INFO     | __main__:main:605 - Difference: 1,133,440 parameters (7.9%)
2025-03-28 00:19:20.693 | INFO     | __main__:main:637 - 
Training both models in parallel...
2025-03-28 00:19:20.693 | INFO     | __main__:main:643 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-001815_d64_l2_n4
2025-03-28 00:19:20.694 | INFO     | __main__:main:681 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:19:20.760 | ERROR    | __main__:main:689 - Error loading SimpleTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:19:20.761 | ERROR    | __main__:main:692 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:22:54.951 | INFO     | __main__:main:294 - Using device: cuda
2025-03-28 00:22:54.952 | INFO     | __main__:main:298 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:22:54.952 | INFO     | __main__:main:299 - This reduces loss for correct token predictions during training
2025-03-28 00:22:54.952 | INFO     | __main__:main:469 - Using train dataset with range 1-9
2025-03-28 00:22:54.952 | INFO     | __main__:main:478 - Using val dataset with range 1-9
2025-03-28 00:22:54.953 | INFO     | __main__:main:535 - Using vocabulary size: 12
2025-03-28 00:22:57.060 | INFO     | __main__:main:589 - Models compiled with torch.compile()
2025-03-28 00:22:57.330 | INFO     | __main__:main:601 - 
Model Parameters:
2025-03-28 00:22:57.331 | INFO     | __main__:main:602 - SimpleTransformer: 236,556
2025-03-28 00:22:57.331 | INFO     | __main__:main:603 - LatentTransformer: 282,636
2025-03-28 00:22:57.331 | INFO     | __main__:main:604 - Parameter ratio: 1.19x
2025-03-28 00:22:57.332 | INFO     | __main__:main:605 - Difference: 46,080 parameters (19.5%)
2025-03-28 00:22:57.333 | INFO     | __main__:main:637 - 
Training both models in parallel...
2025-03-28 00:23:41.761 | INFO     | __main__:main:765 - 
Final Comparison:
2025-03-28 00:23:41.762 | INFO     | __main__:main:766 - ==================================================
2025-03-28 00:23:41.762 | INFO     | __main__:main:772 - Training time: 44.42s
2025-03-28 00:23:41.762 | INFO     | __main__:main:773 - SimpleTransformer: 1.783839 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-28 00:23:41.762 | INFO     | __main__:main:776 - LatentTransformer: 1.741553 loss, 42.62% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-28 00:23:41.763 | INFO     | __main__:main:805 - 
Efficiency Metrics:
2025-03-28 00:23:41.763 | INFO     | __main__:main:820 - SimpleTransformer is 1.17x more parameter-efficient (loss*params)
2025-03-28 00:23:41.763 | INFO     | __main__:main:841 - SimpleTransformer is 1.15x more accuracy-per-parameter efficient
2025-03-28 00:23:41.764 | INFO     | __main__:main:853 - 
To view parallel training curves, run:
2025-03-28 00:23:41.764 | INFO     | __main__:main:854 - tensorboard --logdir=runs/parallel_comparison/20250328-002257_d64_l2_n4
2025-03-28 00:24:32.968 | INFO     | __main__:main:294 - Using device: cuda
2025-03-28 00:24:32.968 | INFO     | __main__:main:298 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:24:32.968 | INFO     | __main__:main:299 - This reduces loss for correct token predictions during training
2025-03-28 00:24:32.968 | INFO     | __main__:main:469 - Using train dataset with range 1-9
2025-03-28 00:24:32.969 | INFO     | __main__:main:478 - Using val dataset with range 1-9
2025-03-28 00:24:32.969 | INFO     | __main__:main:535 - Using vocabulary size: 12
2025-03-28 00:24:35.100 | INFO     | __main__:main:589 - Models compiled with torch.compile()
2025-03-28 00:24:35.369 | INFO     | __main__:main:601 - 
Model Parameters:
2025-03-28 00:24:35.370 | INFO     | __main__:main:602 - SimpleTransformer: 236,556
2025-03-28 00:24:35.370 | INFO     | __main__:main:603 - LatentTransformer: 282,636
2025-03-28 00:24:35.370 | INFO     | __main__:main:604 - Parameter ratio: 1.19x
2025-03-28 00:24:35.370 | INFO     | __main__:main:605 - Difference: 46,080 parameters (19.5%)
2025-03-28 00:24:35.371 | INFO     | __main__:main:637 - 
Training both models in parallel...
2025-03-28 00:26:33.125 | INFO     | __main__:main:294 - Using device: cuda
2025-03-28 00:26:33.125 | INFO     | __main__:main:298 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:26:33.125 | INFO     | __main__:main:299 - This reduces loss for correct token predictions during training
2025-03-28 00:26:33.125 | INFO     | __main__:main:469 - Using train dataset with range 1-9
2025-03-28 00:26:33.126 | INFO     | __main__:main:478 - Using val dataset with range 1-9
2025-03-28 00:26:33.126 | INFO     | __main__:main:535 - Using vocabulary size: 12
2025-03-28 00:26:35.309 | INFO     | __main__:main:589 - Models compiled with torch.compile()
2025-03-28 00:26:35.583 | INFO     | __main__:main:601 - 
Model Parameters:
2025-03-28 00:26:35.584 | INFO     | __main__:main:602 - SimpleTransformer: 236,556
2025-03-28 00:26:35.584 | INFO     | __main__:main:603 - LatentTransformer: 282,636
2025-03-28 00:26:35.584 | INFO     | __main__:main:604 - Parameter ratio: 1.19x
2025-03-28 00:26:35.584 | INFO     | __main__:main:605 - Difference: 46,080 parameters (19.5%)
2025-03-28 00:26:35.586 | INFO     | __main__:main:637 - 
Training both models in parallel...
2025-03-28 00:27:05.349 | INFO     | __main__:main:765 - 
Final Comparison:
2025-03-28 00:27:05.349 | INFO     | __main__:main:766 - ==================================================
2025-03-28 00:27:05.349 | INFO     | __main__:main:772 - Training time: 29.75s
2025-03-28 00:27:05.349 | INFO     | __main__:main:773 - SimpleTransformer: 1.781377 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-28 00:27:05.350 | INFO     | __main__:main:776 - LatentTransformer: 1.739121 loss, 42.62% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-28 00:27:05.350 | INFO     | __main__:main:805 - 
Efficiency Metrics:
2025-03-28 00:27:05.350 | INFO     | __main__:main:820 - SimpleTransformer is 1.17x more parameter-efficient (loss*params)
2025-03-28 00:27:05.350 | INFO     | __main__:main:841 - SimpleTransformer is 1.15x more accuracy-per-parameter efficient
2025-03-28 00:27:05.351 | INFO     | __main__:main:853 - 
To view parallel training curves, run:
2025-03-28 00:27:05.351 | INFO     | __main__:main:854 - tensorboard --logdir=runs/parallel_comparison/20250328-002635_d64_l2_n4
2025-03-28 00:27:10.213 | INFO     | __main__:main:294 - Using device: cuda
2025-03-28 00:27:10.213 | INFO     | __main__:main:298 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:27:10.214 | INFO     | __main__:main:299 - This reduces loss for correct token predictions during training
2025-03-28 00:27:10.214 | INFO     | __main__:main:321 - Attempting to resume from run ID: 20250328-002635_d64_l2_n4
2025-03-28 00:27:10.214 | INFO     | __main__:main:325 - Found run: 20250328-002635_d64_l2_n4
2025-03-28 00:27:10.215 | INFO     | __main__:main:337 - Using seed=42 from run config (override 42)
2025-03-28 00:27:10.215 | INFO     | __main__:main:346 - Using d_model=64 from run config (override 384)
2025-03-28 00:27:10.215 | INFO     | __main__:main:352 - Using num_layers=2 from run config (override 4)
2025-03-28 00:27:10.216 | INFO     | __main__:main:358 - Using num_latent=4 from run config (override 8)
2025-03-28 00:27:10.216 | INFO     | __main__:main:400 - Using checkpoint paths from run 20250328-002635_d64_l2_n4
2025-03-28 00:27:10.216 | INFO     | __main__:main:417 - Loading checkpoints to extract model dimensions
2025-03-28 00:27:10.632 | INFO     | __main__:main:426 - Dimensions from SimpleTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10}
2025-03-28 00:27:10.632 | INFO     | __main__:main:427 - Dimensions from LatentTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10}
2025-03-28 00:27:10.633 | INFO     | __main__:main:431 - Setting d_model to 320 from checkpoint
2025-03-28 00:27:10.633 | INFO     | __main__:main:435 - Setting num_layers to 5 from checkpoint
2025-03-28 00:27:10.633 | INFO     | __main__:main:439 - Setting num_latent to 10 from checkpoint
2025-03-28 00:27:10.633 | INFO     | __main__:main:446 - Using vocab_size=12 from checkpoint
2025-03-28 00:27:10.633 | INFO     | __main__:main:469 - Using train dataset with range 1-99
2025-03-28 00:27:10.646 | INFO     | __main__:main:478 - Using val dataset with range 1-99
2025-03-28 00:27:10.647 | INFO     | __main__:main:535 - Using vocabulary size: 12
2025-03-28 00:27:13.249 | INFO     | __main__:main:589 - Models compiled with torch.compile()
2025-03-28 00:27:13.326 | INFO     | __main__:main:601 - 
Model Parameters:
2025-03-28 00:27:13.326 | INFO     | __main__:main:602 - SimpleTransformer: 14,402,572
2025-03-28 00:27:13.326 | INFO     | __main__:main:603 - LatentTransformer: 15,536,012
2025-03-28 00:27:13.326 | INFO     | __main__:main:604 - Parameter ratio: 1.08x
2025-03-28 00:27:13.327 | INFO     | __main__:main:605 - Difference: 1,133,440 parameters (7.9%)
2025-03-28 00:27:13.328 | INFO     | __main__:main:637 - 
Training both models in parallel...
2025-03-28 00:27:13.328 | INFO     | __main__:main:643 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-002635_d64_l2_n4
2025-03-28 00:27:13.330 | INFO     | __main__:main:681 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:27:13.422 | ERROR    | __main__:main:689 - Error loading SimpleTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:27:13.423 | ERROR    | __main__:main:692 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:29:51.955 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:29:51.956 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:29:51.956 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:29:51.956 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:29:51.956 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:29:51.957 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:29:54.139 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:29:54.417 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:29:54.417 | INFO     | __main__:main:615 - SimpleTransformer: 236,556
2025-03-28 00:29:54.418 | INFO     | __main__:main:616 - LatentTransformer: 282,636
2025-03-28 00:29:54.418 | INFO     | __main__:main:617 - Parameter ratio: 1.19x
2025-03-28 00:29:54.418 | INFO     | __main__:main:618 - Difference: 46,080 parameters (19.5%)
2025-03-28 00:29:54.420 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:30:40.555 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:30:40.555 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:30:40.555 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:30:40.556 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:30:40.556 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:30:40.556 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:30:42.748 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:30:43.005 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:30:43.005 | INFO     | __main__:main:615 - SimpleTransformer: 31,244
2025-03-28 00:30:43.005 | INFO     | __main__:main:616 - LatentTransformer: 42,956
2025-03-28 00:30:43.005 | INFO     | __main__:main:617 - Parameter ratio: 1.37x
2025-03-28 00:30:43.005 | INFO     | __main__:main:618 - Difference: 11,712 parameters (37.5%)
2025-03-28 00:30:43.007 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:31:41.116 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:31:41.117 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:31:41.117 | INFO     | __main__:main:816 - Training time: 58.10s
2025-03-28 00:31:41.117 | INFO     | __main__:main:817 - SimpleTransformer: 1.760982 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-28 00:31:41.117 | INFO     | __main__:main:820 - LatentTransformer: 1.789597 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 42,956 parameters
2025-03-28 00:31:41.117 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:31:41.118 | INFO     | __main__:main:864 - SimpleTransformer is 1.40x more parameter-efficient (loss*params)
2025-03-28 00:31:41.118 | INFO     | __main__:main:885 - SimpleTransformer is 1.37x more accuracy-per-parameter efficient
2025-03-28 00:31:41.118 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:31:41.118 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-003043_d32_l1_n2
2025-03-28 00:31:47.005 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:31:47.006 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:31:47.006 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:31:47.006 | INFO     | __main__:main:334 - Attempting to resume from run ID: 20250328-003043_d32_l1_n2
2025-03-28 00:31:47.007 | INFO     | __main__:main:338 - Found run: 20250328-003043_d32_l1_n2
2025-03-28 00:31:47.007 | INFO     | __main__:main:350 - Using seed=42 from run config (override 42)
2025-03-28 00:31:47.008 | INFO     | __main__:main:359 - Using d_model=32 from run config (override 384)
2025-03-28 00:31:47.008 | INFO     | __main__:main:365 - Using num_layers=1 from run config (override 4)
2025-03-28 00:31:47.008 | INFO     | __main__:main:371 - Using num_latent=2 from run config (override 8)
2025-03-28 00:31:47.009 | INFO     | __main__:main:413 - Using checkpoint paths from run 20250328-003043_d32_l1_n2
2025-03-28 00:31:47.009 | INFO     | __main__:main:430 - Loading checkpoints to extract model dimensions
2025-03-28 00:31:47.366 | INFO     | __main__:main:439 - Dimensions from SimpleTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:31:47.367 | INFO     | __main__:main:440 - Dimensions from LatentTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:31:47.367 | INFO     | __main__:main:444 - Setting d_model to 320 from checkpoint
2025-03-28 00:31:47.368 | INFO     | __main__:main:448 - Setting num_layers to 5 from checkpoint
2025-03-28 00:31:47.368 | INFO     | __main__:main:452 - Setting num_latent to 10 from checkpoint
2025-03-28 00:31:47.368 | INFO     | __main__:main:459 - Using vocab_size=12 from checkpoint
2025-03-28 00:31:47.369 | INFO     | __main__:main:482 - Using train dataset with range 1-99
2025-03-28 00:31:47.386 | INFO     | __main__:main:491 - Using val dataset with range 1-99
2025-03-28 00:31:47.387 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:31:49.880 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:31:49.946 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:31:49.947 | INFO     | __main__:main:615 - SimpleTransformer: 14,402,572
2025-03-28 00:31:49.947 | INFO     | __main__:main:616 - LatentTransformer: 15,536,012
2025-03-28 00:31:49.947 | INFO     | __main__:main:617 - Parameter ratio: 1.08x
2025-03-28 00:31:49.947 | INFO     | __main__:main:618 - Difference: 1,133,440 parameters (7.9%)
2025-03-28 00:31:49.948 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:31:49.949 | INFO     | __main__:main:656 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-003043_d32_l1_n2
2025-03-28 00:31:49.950 | INFO     | __main__:main:694 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:31:49.992 | ERROR    | __main__:main:702 - Error loading SimpleTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 32]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:31:49.993 | ERROR    | __main__:main:705 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:31:49.993 | INFO     | __main__:main:744 - Loading LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-28 00:31:50.056 | ERROR    | __main__:main:752 - Error loading LatentTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 32]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.latent_tokens: copying a param with shape torch.Size([2, 32]) from checkpoint, the shape in current model is torch.Size([10, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_q.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_q.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_k.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_k.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_v.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_v.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_mlp.0.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.latent_mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.latent_mlp.2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.latent_mlp.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:32:42.059 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:32:42.059 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:32:42.059 | INFO     | __main__:main:816 - Training time: 51.99s
2025-03-28 00:32:42.060 | INFO     | __main__:main:817 - SimpleTransformer: 2.673311 loss, 4.08% sequence accuracy, 18.18% digit accuracy, 14,402,572 parameters
2025-03-28 00:32:42.060 | INFO     | __main__:main:820 - LatentTransformer: 2.723771 loss, 4.69% sequence accuracy, 9.09% digit accuracy, 15,536,012 parameters
2025-03-28 00:32:42.060 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:32:42.060 | INFO     | __main__:main:864 - SimpleTransformer is 1.10x more parameter-efficient (loss*params)
2025-03-28 00:32:42.060 | INFO     | __main__:main:880 - LatentTransformer is 1.07x more accuracy-per-parameter efficient
2025-03-28 00:32:42.061 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:32:42.061 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-003043_d32_l1_n2
2025-03-28 00:33:18.173 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:33:18.173 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:33:18.174 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:33:18.174 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:33:18.174 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:33:18.175 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:33:20.375 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:33:20.632 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:33:20.633 | INFO     | __main__:main:615 - SimpleTransformer: 31,244
2025-03-28 00:33:20.633 | INFO     | __main__:main:616 - LatentTransformer: 42,956
2025-03-28 00:33:20.633 | INFO     | __main__:main:617 - Parameter ratio: 1.37x
2025-03-28 00:33:20.633 | INFO     | __main__:main:618 - Difference: 11,712 parameters (37.5%)
2025-03-28 00:33:20.635 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:33:45.416 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:33:45.416 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:33:45.416 | INFO     | __main__:main:816 - Training time: 24.77s
2025-03-28 00:33:45.416 | INFO     | __main__:main:817 - SimpleTransformer: 1.760982 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-28 00:33:45.417 | INFO     | __main__:main:820 - LatentTransformer: 1.789597 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 42,956 parameters
2025-03-28 00:33:45.417 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:33:45.417 | INFO     | __main__:main:864 - SimpleTransformer is 1.40x more parameter-efficient (loss*params)
2025-03-28 00:33:45.417 | INFO     | __main__:main:885 - SimpleTransformer is 1.37x more accuracy-per-parameter efficient
2025-03-28 00:33:45.418 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:33:45.418 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-003320_d32_l1_n2
2025-03-28 00:33:50.305 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:33:50.305 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:33:50.306 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:33:50.306 | INFO     | __main__:main:334 - Attempting to resume from run ID: 20250328-003320_d32_l1_n2
2025-03-28 00:33:50.306 | INFO     | __main__:main:338 - Found run: 20250328-003320_d32_l1_n2
2025-03-28 00:33:50.306 | INFO     | __main__:main:350 - Using seed=42 from run config (override 42)
2025-03-28 00:33:50.307 | INFO     | __main__:main:359 - Using d_model=32 from run config (override 384)
2025-03-28 00:33:50.307 | INFO     | __main__:main:365 - Using num_layers=1 from run config (override 4)
2025-03-28 00:33:50.307 | INFO     | __main__:main:371 - Using num_latent=2 from run config (override 8)
2025-03-28 00:33:50.308 | INFO     | __main__:main:413 - Using checkpoint paths from run 20250328-003320_d32_l1_n2
2025-03-28 00:33:50.308 | INFO     | __main__:main:430 - Loading checkpoints to extract model dimensions
2025-03-28 00:33:50.647 | INFO     | __main__:main:439 - Dimensions from SimpleTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:33:50.648 | INFO     | __main__:main:440 - Dimensions from LatentTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:33:50.648 | INFO     | __main__:main:444 - Setting d_model to 320 from checkpoint
2025-03-28 00:33:50.648 | INFO     | __main__:main:448 - Setting num_layers to 5 from checkpoint
2025-03-28 00:33:50.649 | INFO     | __main__:main:452 - Setting num_latent to 10 from checkpoint
2025-03-28 00:33:50.649 | INFO     | __main__:main:459 - Using vocab_size=12 from checkpoint
2025-03-28 00:33:50.649 | INFO     | __main__:main:482 - Using train dataset with range 1-99
2025-03-28 00:33:50.664 | INFO     | __main__:main:491 - Using val dataset with range 1-99
2025-03-28 00:33:50.665 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:33:53.081 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:33:53.156 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:33:53.156 | INFO     | __main__:main:615 - SimpleTransformer: 14,402,572
2025-03-28 00:33:53.156 | INFO     | __main__:main:616 - LatentTransformer: 15,536,012
2025-03-28 00:33:53.156 | INFO     | __main__:main:617 - Parameter ratio: 1.08x
2025-03-28 00:33:53.156 | INFO     | __main__:main:618 - Difference: 1,133,440 parameters (7.9%)
2025-03-28 00:33:53.158 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:33:53.158 | INFO     | __main__:main:656 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-003320_d32_l1_n2
2025-03-28 00:33:53.159 | INFO     | __main__:main:694 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:33:53.206 | ERROR    | __main__:main:702 - Error loading SimpleTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 32]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:33:53.206 | ERROR    | __main__:main:705 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:33:53.206 | INFO     | __main__:main:744 - Loading LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-28 00:33:53.266 | ERROR    | __main__:main:752 - Error loading LatentTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 32]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.latent_tokens: copying a param with shape torch.Size([2, 32]) from checkpoint, the shape in current model is torch.Size([10, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_q.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_q.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_k.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_k.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_v.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_v.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_mlp.0.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.latent_mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.latent_mlp.2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.latent_mlp.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:34:17.179 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:34:17.179 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:34:17.180 | INFO     | __main__:main:816 - Training time: 23.90s
2025-03-28 00:34:17.180 | INFO     | __main__:main:817 - SimpleTransformer: 2.673311 loss, 4.08% sequence accuracy, 18.18% digit accuracy, 14,402,572 parameters
2025-03-28 00:34:17.180 | INFO     | __main__:main:820 - LatentTransformer: 2.723771 loss, 4.69% sequence accuracy, 9.09% digit accuracy, 15,536,012 parameters
2025-03-28 00:34:17.180 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:34:17.181 | INFO     | __main__:main:864 - SimpleTransformer is 1.10x more parameter-efficient (loss*params)
2025-03-28 00:34:17.181 | INFO     | __main__:main:880 - LatentTransformer is 1.07x more accuracy-per-parameter efficient
2025-03-28 00:34:17.181 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:34:17.181 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-003320_d32_l1_n2
2025-03-28 00:41:02.933 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:41:02.934 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:41:02.934 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:41:02.934 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:41:02.935 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:41:02.935 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:41:35.344 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:41:35.344 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:41:35.345 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:41:35.345 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:41:35.345 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:41:35.345 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:41:37.483 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:41:37.731 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:41:37.732 | INFO     | __main__:main:615 - SimpleTransformer: 31,244
2025-03-28 00:41:37.732 | INFO     | __main__:main:616 - LatentTransformer: 42,956
2025-03-28 00:41:37.732 | INFO     | __main__:main:617 - Parameter ratio: 1.37x
2025-03-28 00:41:37.732 | INFO     | __main__:main:618 - Difference: 11,712 parameters (37.5%)
2025-03-28 00:41:37.735 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:42:02.946 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:42:02.947 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:42:02.947 | INFO     | __main__:main:816 - Training time: 25.20s
2025-03-28 00:42:02.947 | INFO     | __main__:main:817 - SimpleTransformer: 1.760982 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-28 00:42:02.947 | INFO     | __main__:main:820 - LatentTransformer: 1.789597 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 42,956 parameters
2025-03-28 00:42:02.947 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:42:02.948 | INFO     | __main__:main:864 - SimpleTransformer is 1.40x more parameter-efficient (loss*params)
2025-03-28 00:42:02.948 | INFO     | __main__:main:885 - SimpleTransformer is 1.37x more accuracy-per-parameter efficient
2025-03-28 00:42:02.948 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:42:02.948 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-004137_d32_l1_n2
2025-03-28 00:42:07.768 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:42:07.768 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:42:07.768 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:42:07.768 | INFO     | __main__:main:334 - Attempting to resume from run ID: 20250328-004137_d32_l1_n2
2025-03-28 00:42:07.769 | INFO     | __main__:main:338 - Found run: 20250328-004137_d32_l1_n2
2025-03-28 00:42:07.769 | INFO     | __main__:main:350 - Using seed=42 from run config (override 42)
2025-03-28 00:42:07.769 | INFO     | __main__:main:359 - Using d_model=32 from run config (override 384)
2025-03-28 00:42:07.770 | INFO     | __main__:main:365 - Using num_layers=1 from run config (override 4)
2025-03-28 00:42:07.770 | INFO     | __main__:main:371 - Using num_latent=2 from run config (override 8)
2025-03-28 00:42:07.770 | INFO     | __main__:main:413 - Using checkpoint paths from run 20250328-004137_d32_l1_n2
2025-03-28 00:42:07.770 | INFO     | __main__:main:430 - Loading checkpoints to extract model dimensions
2025-03-28 00:42:08.175 | INFO     | __main__:main:439 - Dimensions from SimpleTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:42:08.175 | INFO     | __main__:main:440 - Dimensions from LatentTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:42:08.176 | INFO     | __main__:main:444 - Setting d_model to 320 from checkpoint
2025-03-28 00:42:08.176 | INFO     | __main__:main:448 - Setting num_layers to 5 from checkpoint
2025-03-28 00:42:08.176 | INFO     | __main__:main:452 - Setting num_latent to 10 from checkpoint
2025-03-28 00:42:08.176 | INFO     | __main__:main:459 - Using vocab_size=12 from checkpoint
2025-03-28 00:42:08.176 | INFO     | __main__:main:482 - Using train dataset with range 1-99
2025-03-28 00:42:08.187 | INFO     | __main__:main:491 - Using val dataset with range 1-99
2025-03-28 00:42:08.188 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:42:10.925 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:42:11.000 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:42:11.000 | INFO     | __main__:main:615 - SimpleTransformer: 14,402,572
2025-03-28 00:42:11.001 | INFO     | __main__:main:616 - LatentTransformer: 15,536,012
2025-03-28 00:42:11.001 | INFO     | __main__:main:617 - Parameter ratio: 1.08x
2025-03-28 00:42:11.001 | INFO     | __main__:main:618 - Difference: 1,133,440 parameters (7.9%)
2025-03-28 00:42:11.002 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:42:11.003 | INFO     | __main__:main:656 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-004137_d32_l1_n2
2025-03-28 00:42:11.004 | INFO     | __main__:main:694 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:42:11.053 | ERROR    | __main__:main:702 - Error loading SimpleTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 32]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:42:11.053 | ERROR    | __main__:main:705 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:42:11.054 | INFO     | __main__:main:744 - Loading LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-28 00:42:11.121 | ERROR    | __main__:main:752 - Error loading LatentTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 32]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.latent_tokens: copying a param with shape torch.Size([2, 32]) from checkpoint, the shape in current model is torch.Size([10, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_q.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_q.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_k.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_k.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_v.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_v.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_mlp.0.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.latent_mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.latent_mlp.2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.latent_mlp.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([96, 32]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 32]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:50:14.275 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:50:14.275 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:50:14.276 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:50:14.276 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:50:14.276 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:50:14.277 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:50:16.355 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:50:16.604 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:50:16.605 | INFO     | __main__:main:615 - SimpleTransformer: 31,244
2025-03-28 00:50:16.605 | INFO     | __main__:main:616 - LatentTransformer: 42,956
2025-03-28 00:50:16.605 | INFO     | __main__:main:617 - Parameter ratio: 1.37x
2025-03-28 00:50:16.605 | INFO     | __main__:main:618 - Difference: 11,712 parameters (37.5%)
2025-03-28 00:50:16.608 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:50:59.340 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:50:59.341 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:50:59.341 | INFO     | __main__:main:816 - Training time: 42.72s
2025-03-28 00:50:59.341 | INFO     | __main__:main:817 - SimpleTransformer: 1.756700 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-28 00:50:59.342 | INFO     | __main__:main:820 - LatentTransformer: 1.785492 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 42,956 parameters
2025-03-28 00:50:59.342 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:50:59.342 | INFO     | __main__:main:864 - SimpleTransformer is 1.40x more parameter-efficient (loss*params)
2025-03-28 00:50:59.342 | INFO     | __main__:main:885 - SimpleTransformer is 1.37x more accuracy-per-parameter efficient
2025-03-28 00:50:59.343 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:50:59.343 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-005016_d32_l1_n2
2025-03-28 00:51:57.358 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:51:57.359 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:51:57.359 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:51:57.359 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:51:57.359 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:51:57.360 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:51:59.528 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:51:59.774 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:51:59.774 | INFO     | __main__:main:615 - SimpleTransformer: 31,244
2025-03-28 00:51:59.774 | INFO     | __main__:main:616 - LatentTransformer: 42,956
2025-03-28 00:51:59.774 | INFO     | __main__:main:617 - Parameter ratio: 1.37x
2025-03-28 00:51:59.775 | INFO     | __main__:main:618 - Difference: 11,712 parameters (37.5%)
2025-03-28 00:51:59.776 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:52:29.278 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:52:29.278 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:52:29.279 | INFO     | __main__:main:816 - Training time: 29.49s
2025-03-28 00:52:29.279 | INFO     | __main__:main:817 - SimpleTransformer: 1.751567 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-28 00:52:29.279 | INFO     | __main__:main:820 - LatentTransformer: 1.780566 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 42,956 parameters
2025-03-28 00:52:29.279 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:52:29.280 | INFO     | __main__:main:864 - SimpleTransformer is 1.40x more parameter-efficient (loss*params)
2025-03-28 00:52:29.280 | INFO     | __main__:main:885 - SimpleTransformer is 1.37x more accuracy-per-parameter efficient
2025-03-28 00:52:29.280 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:52:29.280 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-005159_d32_l1_n2
2025-03-28 00:55:01.759 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:55:01.760 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:55:01.760 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:55:01.760 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:55:01.760 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:55:01.761 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:55:03.777 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:55:04.043 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:55:04.043 | INFO     | __main__:main:615 - SimpleTransformer: 31,244
2025-03-28 00:55:04.043 | INFO     | __main__:main:616 - LatentTransformer: 42,956
2025-03-28 00:55:04.043 | INFO     | __main__:main:617 - Parameter ratio: 1.37x
2025-03-28 00:55:04.044 | INFO     | __main__:main:618 - Difference: 11,712 parameters (37.5%)
2025-03-28 00:55:04.046 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:55:32.856 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:55:32.856 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:55:32.857 | INFO     | __main__:main:816 - Training time: 28.80s
2025-03-28 00:55:32.857 | INFO     | __main__:main:817 - SimpleTransformer: 1.724015 loss, 44.26% sequence accuracy, 9.09% digit accuracy, 31,244 parameters
2025-03-28 00:55:32.857 | INFO     | __main__:main:820 - LatentTransformer: 1.773087 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 42,956 parameters
2025-03-28 00:55:32.857 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:55:32.858 | INFO     | __main__:main:864 - SimpleTransformer is 1.41x more parameter-efficient (loss*params)
2025-03-28 00:55:32.858 | INFO     | __main__:main:885 - SimpleTransformer is 1.48x more accuracy-per-parameter efficient
2025-03-28 00:55:32.858 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:55:32.858 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-005504_d32_l1_n2
2025-03-28 00:56:18.233 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:56:18.233 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:56:18.234 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:56:18.234 | INFO     | __main__:main:482 - Using train dataset with range 1-9
2025-03-28 00:56:18.234 | INFO     | __main__:main:491 - Using val dataset with range 1-9
2025-03-28 00:56:18.235 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:56:20.242 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:56:20.485 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:56:20.485 | INFO     | __main__:main:615 - SimpleTransformer: 236,556
2025-03-28 00:56:20.485 | INFO     | __main__:main:616 - LatentTransformer: 282,636
2025-03-28 00:56:20.486 | INFO     | __main__:main:617 - Parameter ratio: 1.19x
2025-03-28 00:56:20.486 | INFO     | __main__:main:618 - Difference: 46,080 parameters (19.5%)
2025-03-28 00:56:20.488 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:56:46.040 | INFO     | __main__:main:809 - 
Final Comparison:
2025-03-28 00:56:46.040 | INFO     | __main__:main:810 - ==================================================
2025-03-28 00:56:46.041 | INFO     | __main__:main:816 - Training time: 25.54s
2025-03-28 00:56:46.041 | INFO     | __main__:main:817 - SimpleTransformer: 1.784371 loss, 40.98% sequence accuracy, 9.09% digit accuracy, 236,556 parameters
2025-03-28 00:56:46.041 | INFO     | __main__:main:820 - LatentTransformer: 1.742133 loss, 42.62% sequence accuracy, 0.00% digit accuracy, 282,636 parameters
2025-03-28 00:56:46.041 | INFO     | __main__:main:849 - 
Efficiency Metrics:
2025-03-28 00:56:46.042 | INFO     | __main__:main:864 - SimpleTransformer is 1.17x more parameter-efficient (loss*params)
2025-03-28 00:56:46.042 | INFO     | __main__:main:885 - SimpleTransformer is 1.15x more accuracy-per-parameter efficient
2025-03-28 00:56:46.042 | INFO     | __main__:main:897 - 
To view parallel training curves, run:
2025-03-28 00:56:46.042 | INFO     | __main__:main:898 - tensorboard --logdir=runs/parallel_comparison/20250328-005620_d64_l2_n4
2025-03-28 00:57:08.604 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:57:08.604 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:57:08.605 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:57:08.605 | INFO     | __main__:main:334 - Attempting to resume from run ID: 20250328-005620_d64_l2_n4
2025-03-28 00:57:08.605 | INFO     | __main__:main:338 - Found run: 20250328-005620_d64_l2_n4
2025-03-28 00:57:08.606 | INFO     | __main__:main:350 - Using seed=42 from run config (override 42)
2025-03-28 00:57:08.606 | INFO     | __main__:main:359 - Using d_model=64 from run config (override 384)
2025-03-28 00:57:08.606 | INFO     | __main__:main:365 - Using num_layers=2 from run config (override 4)
2025-03-28 00:57:08.607 | INFO     | __main__:main:371 - Using num_latent=4 from run config (override 8)
2025-03-28 00:57:08.607 | INFO     | __main__:main:413 - Using checkpoint paths from run 20250328-005620_d64_l2_n4
2025-03-28 00:57:08.607 | INFO     | __main__:main:430 - Loading checkpoints to extract model dimensions
2025-03-28 00:57:08.974 | INFO     | __main__:main:439 - Dimensions from SimpleTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:57:08.975 | INFO     | __main__:main:440 - Dimensions from LatentTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:57:08.975 | INFO     | __main__:main:444 - Setting d_model to 320 from checkpoint
2025-03-28 00:57:08.975 | INFO     | __main__:main:448 - Setting num_layers to 5 from checkpoint
2025-03-28 00:57:08.975 | INFO     | __main__:main:452 - Setting num_latent to 10 from checkpoint
2025-03-28 00:57:08.975 | INFO     | __main__:main:459 - Using vocab_size=12 from checkpoint
2025-03-28 00:57:08.976 | INFO     | __main__:main:482 - Using train dataset with range 1-99
2025-03-28 00:57:08.986 | INFO     | __main__:main:491 - Using val dataset with range 1-99
2025-03-28 00:57:08.987 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:57:11.136 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:57:11.192 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:57:11.193 | INFO     | __main__:main:615 - SimpleTransformer: 14,402,572
2025-03-28 00:57:11.193 | INFO     | __main__:main:616 - LatentTransformer: 15,536,012
2025-03-28 00:57:11.193 | INFO     | __main__:main:617 - Parameter ratio: 1.08x
2025-03-28 00:57:11.194 | INFO     | __main__:main:618 - Difference: 1,133,440 parameters (7.9%)
2025-03-28 00:57:11.195 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:57:11.195 | INFO     | __main__:main:656 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-005620_d64_l2_n4
2025-03-28 00:57:11.197 | INFO     | __main__:main:694 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:57:11.264 | ERROR    | __main__:main:702 - Error loading SimpleTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:57:11.265 | ERROR    | __main__:main:705 - This might be due to dimension mismatch. Check model configuration.
2025-03-28 00:57:11.265 | INFO     | __main__:main:744 - Loading LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-28 00:57:11.345 | ERROR    | __main__:main:752 - Error loading LatentTransformer weights: Error(s) in loading state_dict for OptimizedModule:
	size mismatch for _orig_mod.pos_encoder: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 320]).
	size mismatch for _orig_mod.latent_tokens: copying a param with shape torch.Size([4, 64]) from checkpoint, the shape in current model is torch.Size([10, 320]).
	size mismatch for _orig_mod.embed.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.encoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.encoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_q.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_q.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_k.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_k.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_proj_v.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.latent_proj_v.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.latent_mlp.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.latent_mlp.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.latent_mlp.2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.latent_mlp.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.0.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.0.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.0.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.0.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_weight: copying a param with shape torch.Size([192, 64]) from checkpoint, the shape in current model is torch.Size([960, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.in_proj_bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([320, 320]).
	size mismatch for _orig_mod.decoder.layers.1.multihead_attn.out_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1280, 320]).
	size mismatch for _orig_mod.decoder.layers.1.linear1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([320, 1280]).
	size mismatch for _orig_mod.decoder.layers.1.linear2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder.layers.1.norm3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.output_proj.weight: copying a param with shape torch.Size([12, 64]) from checkpoint, the shape in current model is torch.Size([12, 320]).
	size mismatch for _orig_mod.encoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.encoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
	size mismatch for _orig_mod.decoder_norm.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([320]).
2025-03-28 00:59:09.520 | INFO     | __main__:main:307 - Using device: cuda
2025-03-28 00:59:09.520 | INFO     | __main__:main:311 - Using accuracy-aware loss with weight: 0.5
2025-03-28 00:59:09.520 | INFO     | __main__:main:312 - This reduces loss for correct token predictions during training
2025-03-28 00:59:09.521 | INFO     | __main__:main:334 - Attempting to resume from run ID: 20250328-005620_d64_l2_n4
2025-03-28 00:59:09.521 | INFO     | __main__:main:338 - Found run: 20250328-005620_d64_l2_n4
2025-03-28 00:59:09.521 | INFO     | __main__:main:350 - Using seed=42 from run config (override 42)
2025-03-28 00:59:09.522 | INFO     | __main__:main:359 - Using d_model=320 from run config (override 384)
2025-03-28 00:59:09.522 | INFO     | __main__:main:365 - Using num_layers=5 from run config (override 4)
2025-03-28 00:59:09.522 | INFO     | __main__:main:371 - Using num_latent=10 from run config (override 8)
2025-03-28 00:59:09.523 | INFO     | __main__:main:413 - Using checkpoint paths from run 20250328-005620_d64_l2_n4
2025-03-28 00:59:09.523 | INFO     | __main__:main:430 - Loading checkpoints to extract model dimensions
2025-03-28 00:59:10.274 | INFO     | __main__:main:439 - Dimensions from SimpleTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:59:10.274 | INFO     | __main__:main:440 - Dimensions from LatentTransformer checkpoint: {'d_model': 320, 'num_layers': 5, 'vocab_size': 12, 'num_latent': 10, 'max_len': 20}
2025-03-28 00:59:10.274 | INFO     | __main__:main:444 - Setting d_model to 320 from checkpoint
2025-03-28 00:59:10.274 | INFO     | __main__:main:448 - Setting num_layers to 5 from checkpoint
2025-03-28 00:59:10.275 | INFO     | __main__:main:452 - Setting num_latent to 10 from checkpoint
2025-03-28 00:59:10.275 | INFO     | __main__:main:459 - Using vocab_size=12 from checkpoint
2025-03-28 00:59:10.275 | INFO     | __main__:main:482 - Using train dataset with range 1-99
2025-03-28 00:59:10.286 | INFO     | __main__:main:491 - Using val dataset with range 1-99
2025-03-28 00:59:10.287 | INFO     | __main__:main:548 - Using vocabulary size: 12
2025-03-28 00:59:12.756 | INFO     | __main__:main:602 - Models compiled with torch.compile()
2025-03-28 00:59:12.818 | INFO     | __main__:main:614 - 
Model Parameters:
2025-03-28 00:59:12.818 | INFO     | __main__:main:615 - SimpleTransformer: 14,402,572
2025-03-28 00:59:12.819 | INFO     | __main__:main:616 - LatentTransformer: 15,536,012
2025-03-28 00:59:12.819 | INFO     | __main__:main:617 - Parameter ratio: 1.08x
2025-03-28 00:59:12.819 | INFO     | __main__:main:618 - Difference: 1,133,440 parameters (7.9%)
2025-03-28 00:59:12.821 | INFO     | __main__:main:650 - 
Training both models in parallel...
2025-03-28 00:59:12.821 | INFO     | __main__:main:656 - Using consistent log directory for resumed training: runs/parallel_comparison/20250328-005620_d64_l2_n4
2025-03-28 00:59:12.822 | INFO     | __main__:main:694 - Loading SimpleTransformer checkpoint from checkpoints/simpletransformer/simpletransformer_latest.pt
2025-03-28 00:59:13.028 | INFO     | __main__:main:700 - Loaded SimpleTransformer model weights
2025-03-28 00:59:13.029 | INFO     | __main__:main:744 - Loading LatentTransformer checkpoint from checkpoints/latenttransformer/latenttransformer_latest.pt
2025-03-28 00:59:13.240 | INFO     | __main__:main:750 - Loaded LatentTransformer model weights
